<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>YOLO系列</title>
    <link href="/2024/05/20/Yolo/"/>
    <url>/2024/05/20/Yolo/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Object Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PaddlePaddle训练CPPD文字识别模型</title>
    <link href="/2024/05/19/PaddlePaddle_CPPD/"/>
    <url>/2024/05/19/PaddlePaddle_CPPD/</url>
    
    <content type="html"><![CDATA[<ul><li><h4 id="准备好训练数据集"><a href="#准备好训练数据集" class="headerlink" title="准备好训练数据集"></a>准备好训练数据集</h4><p>以PARSeq（lmdb数据格式）为例，在项目文件中如下：</p><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519204701863.png" alt="image-20240519204701863"></p></li><li><h4 id="报错解决"><a href="#报错解决" class="headerlink" title="报错解决"></a>报错解决</h4><ol><li><p>CUDA和CUDNN的配置问题</p><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519174249876.png" alt="image-20240519174249876"></p><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519202939423.png" alt="image-20240519202939423">解决办法：</p><blockquote><ol><li>下载正确CUDA版本的CUDA Toolkit</li><li>下载正确CUDA版本的cuDNN，将dll动态链接库文件复制到CUDA Toolkit中</li></ol></blockquote></li></ol></li></ul><p>​</p><ul><li><h4 id="成功训练"><a href="#成功训练" class="headerlink" title="成功训练"></a>成功训练</h4><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519204959939.png" alt="image-20240519204959939"></li></ul>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Optical Character Recognition</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CPPD</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R-CNN系列</title>
    <link href="/2024/05/15/RCNN/"/>
    <url>/2024/05/15/RCNN/</url>
    
    <content type="html"><![CDATA[<h3 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h3><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs arcade">R-CNN源于<span class="hljs-number">2014</span>年伯克利大学的这篇论文<br>《Rich <span class="hljs-built_in">feature</span> hierarchies <span class="hljs-keyword">for</span> accurate object detection and semantic segmentation》<br>其架构和模型训练参数等借鉴了AlexNet，也和同时期的Overfeat也有很多共同之处。成为目标检测领域尤其是two stage模式的开山鼻祖。<br></code></pre></td></tr></table></figure><hr><p><img src="/2024/05/15/RCNN/R-CNN.png" alt="R-CNN网络结构"></p><ul><li><h4 id="R-CNN-算法流程分四个步骤："><a href="#R-CNN-算法流程分四个步骤：" class="headerlink" title="R-CNN 算法流程分四个步骤："></a>R-CNN 算法流程分四个步骤：</h4><ol><li><p>一张图像生成1k～2k个候选区域（使用 <strong><u>Selective Search</u></strong> 方法)[<a href="https://zhuanlan.zhihu.com/p/485727819]">https://zhuanlan.zhihu.com/p/485727819]</a></p><blockquote><p>候选区域生成 (Selective Search) 的主要思想：图像中物体可能存在的区域应该是有某些相似性或者连续性区域的。</p><ol><li>首先，对输入图像进行<strong>分割算法</strong>产生许多小的子区域。</li><li>其次，根据这些子区域之间相似性(相似性标准主要有颜色、纹理、大小等等)进行<strong>区域合并</strong>，不断的进行区域迭代合并。每次迭代过程中对这些合并的子区域做bounding boxes(外切矩形)，这些子区域外切矩形就是通常所说的候选框。</li></ol><p><img src="/2024/05/15/RCNN/SS%E7%AE%97%E6%B3%95.png" alt="SS算法"></p></blockquote></li><li><p>对每个候选区域，使用深度网络（图片分类网络）提取特征</p><blockquote><ol><li>通过SS算法可以在一张图片中生成大概2000个候选区域，将候选区域送到CNN网络之前先进行<strong>resize处理</strong>，将2000候选区域缩放到 227 × 227 (原文是不管候选框多大都resize到 227 × 227)</li><li>接着将候选区域输入事先训练好的AlexNet &#x2F; VGG CNN网络<strong>获取4096维的特征</strong>&#x3D;&#x3D;，得到2000×4096维矩阵。</li></ol></blockquote></li><li><p>特征送入每一类SVM分类器，判断是否属于该类</p><blockquote><ol><li><p>将<code>2000×4096</code>维特征与<code>20</code>个<strong>SVM</strong>组成的权值矩阵<code>4096×20</code>相乘，获得<code>2000×20</code>维矩阵表示每个建议框是某个目标类别的得分</p><p><img src="/2024/05/15/RCNN/SVM.png" alt="SVM分类器计算矩阵"></p></li><li><p>分别对上述<code>2000×20</code>维矩阵中每一列即每一类进行**NSM(非极大值抑制)**剔除重叠建议框，得到该列即该类中得分最高的一些建议框。</p></li></ol></blockquote></li><li><p>使用回归器精细修正候选框位置。（使用 Selective Search 算法得到的候选框并不是框得那么准）</p><blockquote><ol><li>对NMS处理后剩余的建议框进一步筛选</li><li>分别用20个<strong>回归器</strong>对上述20个类别中剩余的建议框进行回归操作，最终得到每个类别的修正后的得分最高的bounding box</li></ol><p>(原文)：</p><ol><li>保留与真实目标比IoU大于某一阈值的预测框，不满足的直接删除</li><li>接着再分别使用20个回归器对剩余的预测框进行回归操作，最终得到每个类别的修正后得分最高的预测框。这里的实现方法跟上面的SVM分类差不多，依旧是对卷积神经网络输出的特征向量进行预测，利用每个边界框得到4096维特征向量来预测的。通过回归分类器之后会得到四个参数分别对应着目标建议框的中心点的x,y偏移量和目标边界框的宽高缩放因子。通过预测的四个值对得到的建议框进行调整得到最终的预测边界框。</li></ol></blockquote></li></ol></li><li><h4 id="RCNN存在的问题"><a href="#RCNN存在的问题" class="headerlink" title="RCNN存在的问题"></a>RCNN存在的问题</h4><ol><li>检测速度慢，测试一张图片约53s (CPU)。用Selective Search算法提取候选框用时约2秒，一张图像内候选框之间存在大量重叠，提取特征操作冗余。</li><li>训练速度慢，并且训练过程极其复杂。</li><li>训练所需空间大，对于SVM和bbox回归训练，需要从每个图像中的每个目标候选框提取特征，并写入磁盘。对于非常深的网络，如VGG16，从VOC07训练集上的5k图像上提取的特征需要数百GB的存储空间。</li></ol></li></ul><h3 id="SPPNet"><a href="#SPPNet" class="headerlink" title="SPPNet"></a>SPPNet</h3><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mathematica">由提出<span class="hljs-variable">ResNet</span>的何凯明在论文《<span class="hljs-variable">Spatial</span> <span class="hljs-built_in">Pyramid</span> <span class="hljs-variable">Pooling</span> <span class="hljs-variable">in</span> <span class="hljs-variable">Deep</span> <span class="hljs-variable">Convolutional</span> <span class="hljs-variable">Networks</span> <span class="hljs-variable">for</span> <span class="hljs-variable">Visual</span> <span class="hljs-variable">Recognition</span>》中提出<br>主要就是可以解决<span class="hljs-variable">CNN</span>输入需要固定尺寸的问题，而且在分类和目标检测中都可以得到比较好的效果<br></code></pre></td></tr></table></figure><hr><p><img src="/2024/05/15/RCNN/SPPNet.png" alt="SPPNet网络结构"></p><ul><li><h4 id="针对R-CNN的缺点："><a href="#针对R-CNN的缺点：" class="headerlink" title="针对R-CNN的缺点："></a>针对R-CNN的缺点：</h4><p>1).对每个候选区域提取特征。2).输入CNN的候选区域大小固定，要经过Resize。SPPNet做出了以下改进，<strong>具体内容看表格</strong>：</p><ol><li><p>SPPNet让SS算法得到<strong>候选区域与feature map直接映射</strong>，得到候选区域的映射特征向量（这是映射来的，不需要每个候选区域都再经过CNN的计算，极大的减少了计算量）。</p></li><li><p>SPPNet引入一种空间<u><strong>金字塔池化( spatial pyramid pooling，SPP)层</strong></u>以移除网络对固定尺寸的限制（不需要候选区域经过crop&#x2F;wrap等操作变换成固定大小的图像）。</p><p><img src="/2024/05/15/RCNN/feature_map_regions.png" alt="image regions vs feature map regions"></p><table><thead><tr><th>R-CNN模型</th><th>SPPNet模型</th></tr></thead><tbody><tr><td>1.R-CNN让每个候选区域经过crop&#x2F;wrap等操作变换成固定大小的图像.  2. 固定大小的每个候选区域塞给CNN 传给后面的层做训练回归、分类操作</td><td>1.SPPNet把全图塞给CNN得到全图的feature map.  2.让SS算法得到候选区域与feature map直接映射，得到候选区域的映射特征向量(这是映射来的，不需要过CNN). 3.映射过来的特征向量大小不固定，所以这些特征向量塞给SPP层(空间金字塔变换层)，SPP层接收任何大小的输入，输出固定大小的特征向量，再塞给FC层. 4.经过映射+SPP转换，简化了计算，速度&#x2F;精确度也上去了</td></tr></tbody></table></li></ol></li><li><h4 id="两个关键问题："><a href="#两个关键问题：" class="headerlink" title="两个关键问题："></a>两个关键问题：</h4><ul><li><p><input checked disabled type="checkbox"> <strong>SPP层怎么可以接收任意大小的输入，输出固定的向量？</strong></p><p>spp layer会将<strong>每个候选区域分成1x1，2x2，4x4三张子图</strong>，对每个子图的每个区域作<strong>max pooling</strong>，得出的特征再<strong>连接</strong>到一起就是(16+4+1)x256&#x3D;21x256&#x3D;5376维向量，接着给全连接层做进一步处理。</p></li></ul><ul><li><p><input checked disabled type="checkbox"> <strong>SPPNet怎么就能把候选区域从全图的feature map 直接得到特征向量？</strong></p><p><img src="/2024/05/15/RCNN/Feature_map.png" alt="feature map">整个映射过程有具体的公式：$(x,y)&#x3D;(S<em>x’,S</em>y’)$ $(x’,y’)&#x3D;([x&#x2F;S]+1,[y&#x2F;S]+1)$（左上角+，右下角-)</p><p>其中 S 就是CNN中<strong>所有的strides的乘积</strong>，包含了池化、卷积的stride。论文中使用S的计算出来为2x2x2x2&#x3D;16,在ZF-5结构中。</p></li></ul></li></ul><h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs objectivec">Fast R-<span class="hljs-built_in">CNN</span> 是作者Ross Girshick继 R-<span class="hljs-built_in">CNN</span> 后的又一力作，论文名就叫做 Fast R-<span class="hljs-built_in">CNN</span>，<span class="hljs-number">2015</span>年发表。<br>同样使用VGG16作为网络的backbone，与 R-<span class="hljs-built_in">CNN</span> 相比训练时间快了 <span class="hljs-number">9</span> 倍，测试推理时间快了 <span class="hljs-number">213</span> 倍，准确率从 <span class="hljs-number">62</span>% 提升至了 <span class="hljs-number">66</span>%（在 Pascal VOC 数据集上）<br></code></pre></td></tr></table></figure><hr><p><img src="/2024/05/15/RCNN/Fast_R-CNN.png" alt="Fast R-CNN网络结构"></p><ul><li><h4 id="Fast-R-CNN-算法流程分四个步骤："><a href="#Fast-R-CNN-算法流程分四个步骤：" class="headerlink" title="Fast R-CNN 算法流程分四个步骤："></a>Fast R-CNN 算法流程分四个步骤：</h4><ol><li><p>一张图像生成1k～2k个候选区域（使用 Selective Search 方法）</p></li><li><p>将图像输入网络得到相应的特征图，将 Selective Search 算法生成的候选框投影到特征图上获得相应的特征矩阵</p></li><li><p>将每个特征矩阵通过 ROI pooling层缩放为$ 7 \times 7$大小的特征图  </p><p><a href="https://www.cnblogs.com/yymn/articles/13629478.html">https://www.cnblogs.com/yymn/articles/13629478.html</a></p><p><a href="https://zhuanlan.zhihu.com/p/165324194">https://zhuanlan.zhihu.com/p/165324194</a></p><p><a href="https://www.jianshu.com/p/670a3e42107d">https://www.jianshu.com/p/670a3e42107d</a></p><blockquote><p>ROI「region of interests」：指的是矩形框框出的区域，可能是有目标的也可能没目标，概念上等价于proposal region。</p><p>ROI Pooling层的具体做法是：</p><p>对候选框所对应的特征矩阵，将其划分为7*7，也就是49等份。划分之后，对每一个区域做一个最大池化下采样操作，也就是MaxPooling操作。如此对49等分的候选区域操作，便得到了一个7*7的特征矩阵。</p><p>也就是说，无论候选框的特征矩阵是怎么样的尺寸，都被缩放到一个7*7的大小，这样就可以不去限制输入图像的尺寸了。</p></blockquote></li><li><p>接着将特征图展平通过一系列全连接层获得预测结果</p><blockquote><p>最后并联了两个全连接层分别对分类和bbox进行预测。</p><p>分类结点数为 N+1，因为需要增加上背景。bbox预测的全连接层则是$4*(N+1)$个结点，对每一类都要预测出来边界框参数。</p><p><img src="/2024/05/15/RCNN/%E8%BE%B9%E7%95%8C%E6%A1%86%E5%9B%9E%E5%BD%92%E5%99%A8.png" alt="边界框回归器"></p><p><img src="/2024/05/15/RCNN/image-20240519120214206.png" alt="边界框回归器"></p></blockquote></li></ol></li><li><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>分类损失和回归损失</p></li></ul><h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs objectivec">Faster R-<span class="hljs-built_in">CNN</span> 是作者 Ross Girshick 继 Fast R-<span class="hljs-built_in">CNN</span> 后的又一力作，<br>同样使用 VGG16 作为 backbone，推理速度在 GPU 上达到 <span class="hljs-number">5</span>fps（每秒检测五张图，包括候选区域生成），准确度也有一定的进步。核心在于 RPN 区域生成网络（Region Proposal Network）。<br></code></pre></td></tr></table></figure><hr><p><img src="/2024/05/15/RCNN/ff2cd606a307b927701694ec05d0f599.png" alt="点击查看图片来源"></p><ul><li><h4 id="Faster-R-CNN-算法流程分三个步骤："><a href="#Faster-R-CNN-算法流程分三个步骤：" class="headerlink" title="Faster R-CNN 算法流程分三个步骤："></a>Faster R-CNN 算法流程分三个步骤：</h4><ol><li>将图像输入网络得到相应的特征图-feature map</li><li>使用RPN网络（Region Proposal Network）生成候选框，将 RPN 生成的候选框投影到特征图上获得相应的特征矩阵</li><li>将每个特征矩阵通过 ROI pooling 层缩放为$7 \times 7$大小的特征图，接着将特征图展平通过一系列全连接层获得预测结果</li></ol></li><li><h4 id="RPN-网络结构"><a href="#RPN-网络结构" class="headerlink" title="RPN 网络结构"></a>RPN 网络结构</h4><h3 id><a href="#" class="headerlink" title></a></h3></li></ul>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Object Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RCNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker入门</title>
    <link href="/2024/05/15/Docker/"/>
    <url>/2024/05/15/Docker/</url>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><hr><p>Docker是一个用于<strong>构建(build)</strong>,<strong>运行(run)</strong>,<strong>传送(share)</strong> 应用程序的平台</p><ol><li><strong>将应用程序打包为一个个的集装箱</strong>，小鲸鱼(Docker)就会帮我们将它们运送到任何需要的地方</li></ol><p><img src="/2024/05/15/Docker/docker.png" alt="集装箱"></p><ol start="2"><li><strong>每个集装箱将下列文件打包在一起</strong>（应用程序和它运行时所需要的各种依赖包、第三方软件库、配置文件等），以便在任何环境中都可以正确的运行</li></ol><p><img src="/2024/05/15/Docker/image-20240515112551349.png" alt="集装箱内文件"></p><h3 id="为什么要使用Docker"><a href="#为什么要使用Docker" class="headerlink" title="为什么要使用Docker"></a>为什么要使用Docker</h3><hr><p>比如我们写了一个网站：</p><ol><li><p>前端使用Vue搭建界面</p></li><li><p>后端使用SpringBoot微服务框架来提供各种服务和接口</p></li><li><p>使用MySQL数据库来存储数据</p></li></ol><ul><li><strong>如果没有使用Docker</strong>，我们在生产环境和测试环境中都需要进行各种配置：</li></ul><p><img src="/2024/05/15/Docker/image-20240515113511454.png" alt="开发环境和测试环境"></p><ul><li><strong>如果有了Docker</strong>，我们可以将这些（前端、后端、数据库等）打包成一个个的集装箱，只要在开发环境中运行成功了，在其他环境中也一定可以成功。</li></ul><p><img src="/2024/05/15/Docker/image-20240515113744151.png" alt="开发环境和测试环境"></p><h3 id="Docker和虚拟机的区别"><a href="#Docker和虚拟机的区别" class="headerlink" title="Docker和虚拟机的区别"></a>Docker和虚拟机的区别</h3><hr><ol><li>架构差异：虚拟机是基于<strong>虚拟化技术</strong>（<strong>hypervisor</strong>）实现的，创建一个完整的虚拟硬件环境，模拟一台计算机，包括处理器、内存、硬盘等设备。而Docker则是基于<strong>容器化技术</strong>（<strong>Containerization</strong>），使用Docker引擎访问宿主机操作系统，将应用程序打包到容器中。因此，Docker的架构更加轻量级，启动速度也更快。</li><li>隔离原理：虚拟机通常隔离整个操作系统，进程无法直接访问宿主机资源和数据，需要通过网络或共享文件夹等方式交互。Docker使用Linux内核的namespace和cgroups功能，实现对不同容器中进程的隔离，允许它们共享宿主机资源同时独立运行。</li></ol><h3 id="基本原理和概念"><a href="#基本原理和概念" class="headerlink" title="基本原理和概念"></a>基本原理和概念</h3><hr><p><strong>Docker中的镜像、容器和仓库</strong></p><ul><li><p>镜像和容器的关系就像Java中的类和实例的关系一样：</p><ol><li><strong>镜像是一个只读的模版</strong>，它可以用来创建容器</li><li><strong>容器是Docker的运行实例</strong>，它提供了一个独立的可移植的环境，可以在这个环境中运行应用程序</li></ol></li><li><p>Docker仓库是用来存储Docker镜像的地方，最流行和最常用的仓库就是Dockerhub，实现镜像的共享和复用</p></li></ul><h3 id="Docker的安装"><a href="#Docker的安装" class="headerlink" title="Docker的安装"></a>Docker的安装</h3><hr><p><img src="/2024/05/15/Docker/image-20240515122544372.png" alt="Docker Daemon"></p><ol><li><p>Docker采用Client-Server架构模式</p><ul><li>Docker Client和Docker Daemon之间通过Socket或者RESTful API进行通信</li><li>Docker Daemon就是服务端的守护进程，他负责管理Docker的各种资源</li><li>Docker Client负责向Docker Daemon发送请求，Docker Daemon接收到请求后进行处理，然后将结果返回给Client。因此我们在终端中输入的各种命令，都是Client发送给Docker Daemon的</li></ul></li><li><p>容器化和Dockerfile</p><p><strong>容器化</strong>：顾名思义就是将应用程序打包为容器，在容器中运行应用程序的过程</p><p><strong>Dockerfile</strong>：是一个文本文件，里面包含了一条条的指令，用来告诉Docker如何来构建镜像，这个镜像中包含了我们应用程序执行的所有命令，也就是上边提到的依赖、第三方软件包、配置文件等</p><p>这个过程简单来说可以分成三个步骤:</p><ul><li>首先需要创建一个Dockerfile，来告诉Docker构建应用程序镜像所需要的步骤和配置</li><li>使用Dockerfile来构建镜像</li><li>使用镜像创建和运行容器</li></ul></li></ol><h3 id="实践环节"><a href="#实践环节" class="headerlink" title="实践环节"></a>实践环节</h3><hr><p><img src="/2024/05/15/Docker/image-20240515164517046.png" alt="测试程序_python: 在这里使用默认的ENTRYPOINT[&quot;top&quot;, &quot;-b&quot;]在build时会报错，先删除做测试"></p><hr><p><img src="/2024/05/15/Docker/image-20240515164536314.png" alt="打包为hello-docker镜像"></p><hr><p><img src="/2024/05/15/Docker/image-20240515164551800.png" alt="docker 镜像创建成功"></p>]]></content>
    
    
    <categories>
      
      <category>Develop</category>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
