<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Reinforcement-Learning</title>
    <link href="/2024/07/18/ReinforcementLearning/"/>
    <url>/2024/07/18/ReinforcementLearning/</url>
    
    <content type="html"><![CDATA[<h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><h3 id="1-什么是强化学习"><a href="#1-什么是强化学习" class="headerlink" title="1.什么是强化学习"></a>1.什么是强化学习</h3><p>强化学习（Reinforcement Learning）是一种机器学习方法，旨在通过与环境的交互来学习最优策略，从而最大化累积奖励。它通常包括以下几个核心概念，强化学习任务通常用马尔可夫决策过程（Markov Decision Process，简称MDP）来描述，是一种描述机器与环境交互的框架。</p><ol><li><p><strong>代理（Agent）</strong>：进行决策的主体，例如一个机器人、游戏玩家或自动驾驶汽车。</p></li><li><p><strong>环境（Environment）</strong>：代理与之交互的外部世界，例如一个迷宫、游戏世界或道路交通系统。</p></li><li><p><strong>状态（State, s）</strong>：环境在某一时刻的具体情况，是对当前情景的描述。</p></li><li><p><strong>动作（Action, a）</strong>：代理在某一状态下可以采取的行为。</p></li><li><p><strong>奖励（Reward, r）</strong>：代理在采取某一动作后从环境中获得的反馈信号，用来指导代理学习。</p></li><li><p><strong>策略（Policy, π）</strong>：代理选择动作的规则或方法，通常表示为从状态到动作的映射。</p></li><li><p><strong>价值函数（Value Function）</strong>：评估某一状态或状态-动作对的好坏，通常包括状态价值函数 (V(s)) 和状态-动作价值函数 (Q(s, a))。</p></li></ol><p><img src="/2024/07/18/ReinforcementLearning/v2-de28587d31566e2973a2383918255197_b.jpg" alt="强化学习的马尔可夫决策过程"></p><p>强化学习在游戏、机器人控制、资源管理等领域有广泛应用。例如，AlphaGo使用强化学习战胜了世界顶级围棋选手，OpenAI的Dota 2 AI在复杂的团队游戏中表现出色。强化学习在开放世界游戏中的NPC自主导航、任务完成和路径规划等方面有广泛应用。以下是详细介绍：</p><ul><li>自主导航</li></ul><blockquote><p><strong>自主导航</strong>是指NPC能够在游戏世界中自主移动，从一个地点到达另一个地点，避开障碍物和敌人。强化学习可以帮助NPC实现这一目标：</p><ol><li><strong>环境建模</strong>：将游戏世界建模为一个网格或连续的状态空间，状态包括NPC的当前位置、周围的障碍物和目标位置等。</li><li><strong>动作选择</strong>：定义NPC可以执行的动作，如前进、后退、左转、右转等。</li><li><strong>奖励函数</strong>：设计奖励函数以引导NPC学会导航。例如，到达目标位置给予高奖励，碰到障碍物或偏离路径给予惩罚。</li><li><strong>训练过程</strong>：通过强化学习算法（如Q学习或深度Q网络DQN），NPC逐渐学会在复杂环境中自主导航，找到最优路径到达目标。</li></ol></blockquote><ul><li>任务完成</li></ul><blockquote><p><strong>任务完成</strong>涉及NPC根据预定目标执行一系列动作，可能包括导航、交互和战斗等。强化学习在这一方面的应用步骤如下：</p><ol><li><strong>任务分解</strong>：将复杂任务分解为多个子任务，每个子任务可以定义一个独立的状态空间和动作集。</li><li><strong>多任务学习</strong>：使用强化学习算法（如策略梯度方法、演员-评论家方法）来训练NPC完成每个子任务，并学会在不同任务间切换。</li><li><strong>层次化强化学习</strong>：引入层次化策略（hierarchical policies），高层策略决定任务分配和切换，低层策略负责具体的任务执行。</li><li><strong>任务规划与执行</strong>：结合路径规划和任务完成，使NPC能够自主决定行动策略，完成复杂任务。例如，NPC需要先导航到特定地点，再与特定角色交互，最后返回起点。</li></ol></blockquote><ul><li>路径规划</li></ul><blockquote><p><strong>路径规划</strong>是指在复杂环境中找到从起点到终点的最优路径。强化学习在路径规划中的应用包括：</p><ol><li><strong>环境建模</strong>：将环境建模为一个图或网格，每个节点代表一个位置，边表示相邻位置之间的连接。</li><li><strong>动作选择</strong>：定义在每个节点上可以执行的动作，如移动到相邻节点。</li><li><strong>奖励函数</strong>：设计奖励函数以引导NPC找到最优路径。例如，靠近目标位置给予正奖励，增加路径长度给予负奖励。</li><li><strong>训练过程</strong>：使用强化学习算法（如A3C、DQN），让NPC通过多次尝试逐渐学会在不同环境中找到最优路径。</li><li><strong>动态路径规划</strong>：强化学习可以帮助NPC在动态环境中实时调整路径，避开突然出现的障碍物或追击敌人。</li></ol></blockquote><h3 id="2-强化学习的框架"><a href="#2-强化学习的框架" class="headerlink" title="2.强化学习的框架"></a>2.强化学习的框架</h3><p>强化学习问题通常可以用<strong>马尔可夫决策过程</strong>（Markov Decision Process, MDP）来建模，MDP由以下组成：</p><ol><li><p>**状态空间 (S)**：所有可能状态的集合。</p></li><li><p>**动作空间 (A)**：所有可能动作的集合。</p></li><li><p>**状态转移概率 (P(s’|s,a))**：从状态 (s) 执行动作 (a) 后转移到状态 (s’) 的概率。</p></li><li><p>**奖励函数 (R(s,a,s’))**：从状态 (s) 执行动作 (a) 后转移到状态 (s’) 所获得的即时奖励。</p></li></ol><h3 id="3-强化学习的目标"><a href="#3-强化学习的目标" class="headerlink" title="3.强化学习的目标"></a>3.强化学习的目标</h3><p>强化学习的目标是找到一个策略 ($\pi$)，使得在该策略下的累积奖励期望值最大。累积奖励通常定义为折扣回报 ($G_t$)：</p><p>$$<br> G_t &#x3D; R_{t+1} + \gamma R_{t+2} + \gamma^2 R_{t+3} + \ldots &#x3D; \sum_{k&#x3D;0}^{\infty} \gamma^k R_{t+k+1}<br>$$<br>其中，($\gamma \in [0, 1]$) 是折扣因子，表示未来奖励的重要性。</p><h3 id="4-强化学习方法"><a href="#4-强化学习方法" class="headerlink" title="4.强化学习方法"></a>4.强化学习方法</h3><p>强化学习的目标是找到一种策略，使得在长时间内获得的总奖励最大化。常见的强化学习算法主要分为以下几类：</p><pre><code class="hljs">1.值迭代方法（Value Iteration Methods）：直接估计价值函数，包括动态规划方法。2.策略迭代方法（Policy Iteration Methods）：直接优化策略，包括策略梯度方法。3.值策略结合方法（Actor-Critic Methods）：同时估计价值函数和优化策略。</code></pre><p>主要算法：</p><ol><li>   Q-Learning：<br>离线学习方法，不依赖具体策略。<br>更新公式： $Q(s,a) \leftarrow Q(s,a) + \alpha \left[ r + \gamma \max_{a{\prime}} Q(s{\prime},a{\prime}) - Q(s,a) \right]$<br>目标是找到最优状态-动作价值函数 $Q^*(s, a)$。</li><li>   SARSA（State-Action-Reward-State-Action）：<br>在线学习方法，依赖具体策略。<br>更新公式： $Q(s,a) \leftarrow Q(s,a) + \alpha \left[ r + \gamma Q(s{\prime},a{\prime}) - Q(s,a) \right] $<br>使用当前策略估计Q值。</li><li>   DQN（Deep Q-Networks）：<br>使用神经网络近似Q值函数。<br>经验回放（Experience Replay）和目标网络（Target Network）用于提高训练稳定性和效率。</li><li>   策略梯度方法（Policy Gradient Methods）：<br>直接优化策略，使得累积奖励期望值最大化。<br>REINFORCE算法：使用蒙特卡罗方法估计梯度并更新策略参数。<br>更新公式： $\theta \leftarrow \theta + \alpha \nabla_\theta \log \pi_\theta(a|s) G_t $</li><li>   Actor-Critic Methods：<br>结合策略梯度和价值函数估计方法。<br>Actor更新策略参数，Critic更新价值函数。<br>更新公式：<br>Actor： $\theta \leftarrow \theta + \alpha \nabla_\theta \log \pi_\theta(a|s) \delta $<br>Critic： $w \leftarrow w + \beta \delta \nabla_w V_w(s) $<br>其中 $\delta &#x3D; r + \gamma V_w(s{\prime}) - V_w(s) $是TD误差。</li></ol>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Reinforcement Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Reinforcement Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Algorithm-Sort</title>
    <link href="/2024/07/07/Algorithm/"/>
    <url>/2024/07/07/Algorithm/</url>
    
    <content type="html"><![CDATA[<h2 id="Algorithm-Sort"><a href="#Algorithm-Sort" class="headerlink" title="Algorithm-Sort"></a>Algorithm-Sort</h2><h3 id="排序算法总结"><a href="#排序算法总结" class="headerlink" title="排序算法总结"></a>排序算法总结</h3><p><img src="/2024/07/07/Algorithm/v2-519970e854c90f9b901947963316dd64_1440w-20240707192544329.png" alt="排序算法基础总结"></p><p><img src="/2024/07/07/Algorithm/0.png" alt="复杂度和稳定性"></p><hr><h4 id="1-冒泡排序"><a href="#1-冒泡排序" class="headerlink" title="1.冒泡排序"></a>1.冒泡排序</h4><p>时间复杂度$O(N^2)$空间复杂度$O(1)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数组后面的数为排好序的数，一直交换直到把当前最大的数交换到最后</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bubble_sort</span>(<span class="hljs-params">nums</span>):<br>    n = <span class="hljs-built_in">len</span>(nums)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>      <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>:n-<span class="hljs-number">1</span>-i):<br>        <span class="hljs-keyword">if</span> nums[j] &gt; nums[j+<span class="hljs-number">1</span>]:<br>          <span class="hljs-comment"># 交换</span><br>          nums[j],num[j+<span class="hljs-number">1</span>] = nums[j+<span class="hljs-number">1</span>],nums[j]<br>    <span class="hljs-keyword">return</span> nums<br></code></pre></td></tr></table></figure><h4 id="2-选择排序"><a href="#2-选择排序" class="headerlink" title="2.选择排序"></a>2.选择排序</h4><h4 id="3-插入排序"><a href="#3-插入排序" class="headerlink" title="3.插入排序"></a>3.插入排序</h4><p>时间复杂度$O(N^2)$空间复杂度$O(1)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数组前面的数为排好序的，每次在前面不断交换直到找到当前数的位置</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">insertion_sort</span>(<span class="hljs-params">nums</span>):<br>    n = <span class="hljs-built_in">len</span>(nums)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n):<br>        j = i<br>        <span class="hljs-keyword">while</span> j &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums[j - <span class="hljs-number">1</span>] &gt; nums[j]:<br>            nums[j], nums[j - <span class="hljs-number">1</span>] = nums[j - <span class="hljs-number">1</span>], nums[j]<br>            j -= <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> nums<br></code></pre></td></tr></table></figure><h4 id="4-希尔排序"><a href="#4-希尔排序" class="headerlink" title="4.希尔排序"></a>4.希尔排序</h4><h4 id="5-归并排序"><a href="#5-归并排序" class="headerlink" title="5.归并排序"></a>5.归并排序</h4><h4 id="6-快速排序"><a href="#6-快速排序" class="headerlink" title="6.快速排序"></a>6.快速排序</h4><blockquote><p>下面的实现使用额外的数组来存储分区结果，因此空间复杂度除了递归调用栈的空间外，还包括分区数组的空间:</p><p>空间复杂度为 O(n)（额外数组）+ O(log n)（递归调用栈）&#x3D; O(n)。</p><p>时间复杂度为 O(log n) （分区操作树的高度）*  O(n)（每层的分区操作）&#x3D;  O(nlog n)</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">quick_sort</span>(<span class="hljs-params">nums</span>):<br>    <span class="hljs-comment"># 实现快排</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(nums) &lt;= <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> nums<br>    <span class="hljs-comment"># 选取基准数</span><br>    pivot = nums[<span class="hljs-built_in">len</span>(nums)//<span class="hljs-number">2</span>]<br>    <span class="hljs-comment"># 实现分区</span><br>    left = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> nums <span class="hljs-keyword">if</span> x &lt; pivot]<br>    middle = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> nums <span class="hljs-keyword">if</span> x == pivot]<br>    right = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> nums <span class="hljs-keyword">if</span> x &gt; pivot]<br>    <span class="hljs-comment"># 将左右半区递归进行排序</span><br>    <span class="hljs-keyword">return</span> quick_sort(left) + middle + quick_sort(right)<br></code></pre></td></tr></table></figure><blockquote><p>使用原地分区的快速排序实现，避免了使用额外的数组，从而优化了空间复杂度：</p><p>空间复杂度为 O(log n)（递归调用栈）。</p><p>时间复杂度为 O(log n) （分区操作树的高度）*  O(n)（每层的分区操作）&#x3D;  O(nlog n)</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">quick_sort</span>(<span class="hljs-params">nums, low, high</span>):<br>  <span class="hljs-keyword">if</span> low &lt; high:<br>    pi = partition(nums, low, high)<br>    <span class="hljs-comment"># 递归实现左右分区快排</span><br>    quick_sort(nums, low, pi-<span class="hljs-number">1</span>)<br>    quick_sort(nums, pi+<span class="hljs-number">1</span>, high)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">partition</span>(<span class="hljs-params">nums, low, high</span>):<br>  <span class="hljs-comment"># 选取基准数</span><br>  pivot = nums[high]<br>  i = low<br>  <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(low,high):<br>    <span class="hljs-keyword">if</span> nums[j] &lt; pivot:<br>      nums[i],nums[j] = nums[j],nums[i]<br>      i += <span class="hljs-number">1</span><br>  nums[i],nums[high] = nums[high],nums[i]<br>  <span class="hljs-keyword">return</span> i<br></code></pre></td></tr></table></figure><h4 id="7-堆排序"><a href="#7-堆排序" class="headerlink" title="7.堆排序"></a>7.堆排序</h4><blockquote><p>堆排序的主要思想是将数组转化为一个大顶堆，然后通过不断将堆顶（最大值）与<strong>未排序部分</strong>的最后一个元素交换并重新调整堆来实现排序。</p><p>从小到大排序，建立大根堆；从大到小排序，建立小根堆。</p><p>大根堆：每个结点的值都大于等于其孩子结点的值；小根堆：每个结点的值都小于等于其孩子结点的值。</p></blockquote><p>排序过程：</p><blockquote><p><strong>1.构建大顶堆</strong>：将数组转化为一个大顶堆。</p><p><strong>2.交换堆顶元素和末尾元素</strong>：将堆顶（最大元素）与未排序部分的最后一个元素交换，并缩小堆的范围。</p><p><strong>3.调整堆</strong>：调整交换后的堆，使其重新成为大顶堆。</p><p><strong>4.重复步骤2和步骤3</strong>，直到堆的范围缩小到1。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">heapify</span>(<span class="hljs-params">arr, h_size, h_index</span>):<br>  <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    调整堆，使其满足大顶堆的性质</span><br><span class="hljs-string">    :param arr: 数组</span><br><span class="hljs-string">    :param h_size: 堆的大小</span><br><span class="hljs-string">    :param h_index: 要调整的节点索引</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 左右结点的索引值</span><br>    left = <span class="hljs-number">2</span>*(h_index) + <span class="hljs-number">1</span><br>    right = <span class="hljs-number">2</span>*(h_index) + <span class="hljs-number">2</span><br>    <span class="hljs-comment"># 先设置最大值为当前结点值</span><br>    maxIndex = h_index<br>    <span class="hljs-comment"># 判断左右结点值是否大于它，进行交换调整</span><br>    <span class="hljs-keyword">if</span> left &lt; h_size <span class="hljs-keyword">and</span> arr[left] &gt; arr[maxIndex]:<br>        maxIndex = left<br>    <span class="hljs-keyword">if</span> right &lt; h_size <span class="hljs-keyword">and</span> arr[right] &gt; arr[maxIndex]:<br>        maxIndex = right<br>    <span class="hljs-keyword">if</span> maxIndex != h_index:<br>        arr[h_index], arr[maxIndex] = arr[maxIndex], arr[h_index]<br>        <span class="hljs-comment"># 递归调整被交换的子树</span><br>        heapify(arr, h_size, maxIndex)<br>        <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">heap_sort</span>(<span class="hljs-params">arr</span>):<br>    <span class="hljs-comment"># 创建大根堆</span><br>    n = <span class="hljs-built_in">len</span>(arr)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n//<span class="hljs-number">2</span>-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):<br>        heapify(arr,n,i)<br><br>    <span class="hljs-comment"># 逐步将最大值交换末尾，然后动态调整剩余堆，使其保持大根堆的性质</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n-<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,-<span class="hljs-number">1</span>):<br>        <span class="hljs-comment"># 将最大值交换到末尾</span><br>        arr[i],arr[<span class="hljs-number">0</span>] = arr[<span class="hljs-number">0</span>],arr[i]<br>        <span class="hljs-comment"># 调整剩余大根堆</span><br>        heapify(arr,i,<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>使用迭代方法来避免递归调用栈，使其空间复杂度保持$O(1)$，迭代方法并不会造成时间复杂度的增加，是因为迭代深度还是类似于堆的高度，所以为$O(\log n)$：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">heapify</span>(<span class="hljs-params">arr, n, i</span>):<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        largest = i  <span class="hljs-comment"># 初始化最大值为当前节点</span><br>        left = <span class="hljs-number">2</span> * i + <span class="hljs-number">1</span>  <span class="hljs-comment"># 左子节点</span><br>        right = <span class="hljs-number">2</span> * i + <span class="hljs-number">2</span>  <span class="hljs-comment"># 右子节点</span><br><br>        <span class="hljs-comment"># 如果左子节点存在且大于当前最大值，则更新最大值为左子节点</span><br>        <span class="hljs-keyword">if</span> left &lt; n <span class="hljs-keyword">and</span> arr[left] &gt; arr[largest]:<br>            largest = left<br>        <span class="hljs-comment"># 如果右子节点存在且大于当前最大值，则更新最大值为右子节点</span><br>        <span class="hljs-keyword">if</span> right &lt; n <span class="hljs-keyword">and</span> arr[right] &gt; arr[largest]:<br>            largest = right<br>        <span class="hljs-comment"># 如果最大值不是当前节点，则交换并继续调整子树</span><br>        <span class="hljs-keyword">if</span> largest != i:<br>            arr[i], arr[largest] = arr[largest], arr[i]<br>            i = largest<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">break</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
      <category>Basic</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLM-Transformer</title>
    <link href="/2024/07/04/LLM-Transformer/"/>
    <url>/2024/07/04/LLM-Transformer/</url>
    
    <content type="html"><![CDATA[<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>Transformer 模型是由谷歌在2017 年提出并首先应用于机器翻译的神经网络模型结构。Transformer 结构完全通过注意力机制完成对源语言序列和目标语言序列全局依赖的建模。</p><p><strong>参考文章：</strong></p><p>本文只是做一些学习记录总结，内容全部来源于作者<a href="https://www.zhihu.com/people/lemonround">猛猿</a>以下文章，写的非常详细：</p><p><a href="https://zhuanlan.zhihu.com/p/454482273%E3%80%81https://zhuanlan.zhihu.com/p/456863215%E7%AD%89">https://zhuanlan.zhihu.com/p/454482273、https://zhuanlan.zhihu.com/p/456863215等</a></p><p><strong>结构图：</strong></p><p><img src="/2024/07/04/LLM-Transformer/1740792-20200714150528222-1369583497.png" alt="Transformer结构"></p><h3 id="1-位置编码"><a href="#1-位置编码" class="headerlink" title="1. 位置编码"></a>1. 位置编码</h3><hr><p>在Transformer的encoder和decoder的输入层中，使用了Positional Encoding，使得最终的输入满足：</p><p>$input &#x3D; Input\ Embedding + Positional\ Encoding$</p><h4 id="1-1-为什么需要位置编码："><a href="#1-1-为什么需要位置编码：" class="headerlink" title="1.1 为什么需要位置编码："></a>1.1 为什么需要位置编码：</h4><p>在self-attention模型中，输入是一整排的tokens，对于人来说，我们很容易观察到tokens的位置信息，但是因为self-attention的运算是无向的，无法分辩tokens位置信息，因此我们要想办法，把tokens的位置信息，喂给模型。</p><h4 id="1-2-如何构造位置编码"><a href="#1-2-如何构造位置编码" class="headerlink" title="1.2 如何构造位置编码"></a>1.2 如何构造位置编码</h4><p>一些方法，比如 用整型值标记位置 &#x2F; 用[0,1]范围标记位置 &#x2F; 用二进制向量标记 &#x2F; 用周期函数sin表示….等，都有其不足之处和局限性。</p><p>但我们有一些希望实现的目标：</p><blockquote><ul><li>位置的表示应该是有界的；</li><li>模型可以处理在训练时没见过的句子长度；</li><li>序列长度不同时，tokens的相对位置应该保持一致；</li><li>希望位置编码在连续空间内而不是离散的；</li><li>不同的位置向量是可以通过线性转换得到的。</li></ul></blockquote><h5 id="1-2-1用周期函数-Sin-表示Position-Encoding"><a href="#1-2-1用周期函数-Sin-表示Position-Encoding" class="headerlink" title="1.2.1用周期函数 Sin 表示Position Encoding:"></a>1.2.1<strong>用周期函数 Sin 表示Position Encoding:</strong></h5><p>我们把位置向量当中的每一个元素都用一个sin函数来表示，则第t个token的位置向量可以表示为：<br>$$<br>PE_t &#x3D; [\sin(\frac{1}{2^0}t), \sin(\frac{1}{2^1}t),\cdots,\sin(\frac{1}{2^{i-1}}t),\cdots,\sin(\frac{1}{2^{d_{model}-1}}t)]<br>$$<br>结合下图，来理解一下这样设计的含义，图中每一行表示一个$PE_t$ ，每一列表示$PE_t$ 中的第<code>i</code>个元素。<code>d_model</code>表示token的维度。</p><blockquote><p>旋钮用于调整精度，越往右边的旋钮，需要调整的精度越大，因此指针移动的步伐越小。每一排的旋钮都在上一排的基础上进行调整（函数中 t 的作用）。通过频率$\frac{1}{2^{i-1}}$来控制sin函数的波长，频率不断减小，则波长不断变大，此时sin函数对t的变动越不敏感，以此来达到越向右的旋钮，指针移动步伐越小的目的。 这也类似于二进制编码，每一位上都是0和1的交互，越往低位走（越往左边走），交互的频率越慢。</p></blockquote><p><img src="/2024/07/04/LLM-Transformer/v2-eb3d818037adb892dafcf26a6ef433cc_1440w.webp" alt="用周期函数Sin表示位置编码"></p><p>由于sin是周期函数，因此从纵向来看，如果函数的频率偏大，引起波长偏短，则不同t下的位置向量可能出现重合的情况。比如在下图中(d_model &#x3D; 3），图中的点表示每个token的位置向量，颜色越深，token的位置越往后，在频率偏大的情况下，位置响亮点连成了一个闭环，靠前位置（黄色）和靠后位置（棕黑色）竟然靠得非常近：</p><p><img src="/2024/07/04/LLM-Transformer/v2-a76698f2225c5ed7bc49b2259548cf2a_1440w.webp" alt="d_model = 3下的sin函数"></p><p>为了避免这种情况，我们尽量将函数的波长拉长。一种简单的解决办法是同一把所有的频率都设成一个非常小的值。因此在transformer的论文中，采用了$\frac{1}{10000^{i&#x2F;{d_{model}-1}}}$这个频率（这里 i 其实不是表示第 i 个位置，但是大致意思差不多，下面会细说） </p><p>总结一下，到这里我们把位置向量表示为：其中$w_i$等于$\frac{1}{10000^{i&#x2F;{d_{model}-1}}}$<br>$$<br>PE_t &#x3D; [\sin(w_0t), \sin(w_1t),\cdots,\sin(w_{i-1}t),\cdots,\sin(w_{d_{model}-1}t)]<br>$$</p><h5 id="1-2-2-用sin和cos交替来表示位置"><a href="#1-2-2-用sin和cos交替来表示位置" class="headerlink" title="1.2.2 用sin和cos交替来表示位置"></a>1.2.2 用sin和cos交替来表示位置</h5><p>目前为止，我们的位置向量实现了如下功能： </p><blockquote><ul><li>每个token的向量唯一（每个sin函数的频率足够小）；</li><li>位置向量的值是有界的，且位于连续空间中。模型在处理位置向量时更容易泛化，即更好处理长度和训练数据分布不一致的序列（sin函数本身的性质）。</li></ul></blockquote><p>那现在我们对位置向量再提出一个要求：<strong>不同的位置向量是可以通过线性转换得到的</strong>。这样，我们不仅能表示一个token的绝对位置，还可以表示一个token的相对位置，即我们想要：<br>$$<br>PE_{t+\triangle{t}}&#x3D;T_{\triangle{t}}*PE_t<br>$$<br>这里，$T$ 表示一个线性变换矩阵。观察这个目标式子，联想到在向量空间中一种常用的线形变换—旋转。在这里，我们将t想象为一个角度，那么$\triangle{t}$就是其旋转的角度，则上面的式子可以进一步写成：</p><p><img src="/2024/07/04/LLM-Transformer/image-20240704221004298.png" alt="向量空间-旋转"></p><p>有了这个构想，我们就可以把原来元素全都是sin函数的 做一个替换，我们让位置两两一组，分别用sin和cos的函数对来表示它们，则现在我们有：<br>$$<br>PE_t &#x3D; \sin(w_0t),\cos(w_0t),\sin(w_1t),\cos(w_1t)\cdots,\sin(w_{i-1}t),\cos(w_{i-1}t),\cdots,\sin(w_{d_{model}-1}t)\cos(w_{d_{model}-1}t)<br>$$<br>在这样的表示下，我们可以很容易用一个线性变换，把$PE_t$转变为$PE_{t+\Delta t}$ ，具体公式<a href="https://zhuanlan.zhihu.com/p/454482273">参考文章</a>。</p><h4 id="1-3-Transformer中位置编码方法：Sinusoidal-functions"><a href="#1-3-Transformer中位置编码方法：Sinusoidal-functions" class="headerlink" title="1.3 Transformer中位置编码方法：Sinusoidal functions"></a>1.3 Transformer中位置编码方法：Sinusoidal functions</h4><p>定义： </p><ul><li><code>t</code> 是这个token在序列中的实际位置（例如第一个token为1，第二个token为2…） </li><li>$PE_t\in\mathbb{R^d}$是这个token的位置向量， $PE_t^{(i)}$表示这个位置向量里的第<code>i</code>个元素 </li><li>$d_{model}$是这个token的维度（在论文中，是512)</li></ul><p>$PE_t^{(i)}$则可以如下表示，这里$w_k&#x3D;\frac{1}{10000^{2k&#x2F;{d_{model}-1}}}$，$k&#x3D;0,1,2,3,\dots,\frac{d_{model}}{2}-1$<br>$$<br>PE_t^{(i)} &#x3D; \begin{cases}<br>\sin(w_kt) &amp; \text{if } i &#x3D; 2k \<br>\cos(w_kt) &amp; \text{if } i &#x3D; 2k+1<br>\end{cases}<br>$$<br>这个意思和式子(5)中的意思是一模一样的，把512维的向量两两一组，每组都是一个sin和一个cos，这两个函数共享同一个频率$w_i$ ，一共有256组，由于我们从0开始编号，所以最后一组编号是255。sin&#x2F;cos函数的波长（由$w_i$决定）则从$2\pi$增长到 $2\pi*10000$</p><h4 id="1-4-Transformer位置编码可视化"><a href="#1-4-Transformer位置编码可视化" class="headerlink" title="1.4 Transformer位置编码可视化"></a>1.4 Transformer位置编码可视化</h4><p>下图是一串序列长度为50，位置编码维度为128的位置编码可视化结果：</p><blockquote><p>可以发现，由于sin&#x2F;cos函数的性质，位置向量的每一个值都位于[-1, 1]之间。同时，纵向来看，图的右半边几乎都是蓝色的，这是因为越往后的位置，频率越小，波长越长，所以不同的t对最终的结果影响不大。而越往左边走，颜色交替的频率越频繁。</p></blockquote><p><img src="/2024/07/04/LLM-Transformer/v2-b6c64586260ebed24339052adec7bca8_1440w.webp" alt="img"></p><h4 id="1-5-Transformer位置编码的重要性质"><a href="#1-5-Transformer位置编码的重要性质" class="headerlink" title="1.5 Transformer位置编码的重要性质"></a>1.5 Transformer位置编码的重要性质</h4><ol><li><p>两个位置编码的点积(dot product)仅取决于偏移量$\Delta t$ ，即两个位置编码的点积可以反应出两个位置编码间的距离。</p><p><img src="/2024/07/04/LLM-Transformer/image-20240707215149249.png" alt="两个位置编码的点积仅取决于偏移量证明公式"></p></li><li><p>位置向量的点积可以用于表示<strong>距离</strong>(distance-aware)，但是它却不能用来表示位置的<strong>方向性</strong>(lack-of-directionality)。</p></li><li><p>在Transformer的论文中，比较了用positional encoding和learnable position embedding(让模型自己学位置参数）两种方法，得到的结论是两种方法对模型最终的衡量指标差别不大。不过在后面的BERT中，已经改成用learnable position embedding的方法了，也许是因为positional encoding在进attention层后一些优异性质消失的原因（猜想）。Positional encoding有一些想象+实验+论证的意味，而编码的方式也不只这一种，比如把sin和cos换个位置，依然可以用来编码。</p></li></ol><h3 id="2-Self-Attention（自注意力机制）"><a href="#2-Self-Attention（自注意力机制）" class="headerlink" title="2.Self-Attention（自注意力机制）"></a>2.Self-Attention（自注意力机制）</h3><hr><h4 id="2-1-Attention构造"><a href="#2-1-Attention构造" class="headerlink" title="2.1 Attention构造"></a>2.1 Attention构造</h4><p>在RNN当中，tokens是一个一个被喂给模型的。比如在x3的位置，模型要等x1和x2的信息都处理完成后，才可以处理x3。</p><p><img src="/2024/07/04/LLM-Transformer/u=3242639576,199183504&fm=253&fmt=auto&app=138&f=JPEG.jpeg" alt="RNN"></p><p>这种构造造成的缺点：</p><ol><li><p><strong>Sequential operations的复杂度随着序列长度的增加而增加。</strong><br>这是指模型下一步计算的等待时间，在RNN中为O(N)。该复杂度越大，模型并行计算的能力越差，反之则反。</p></li><li><p><strong>Maximum Path length的复杂度随着序列长度的增加而增加。</strong><br>这是指信息从一个数据点传送到另一个数据点所需要的距离，在RNN中同样为O(N)，距离越大，则在传送的过程中越容易出现信息缺失的情况，即数据点对于远距离处的信息，是很难“看见”的。</p></li></ol><p>那么，在处理序列化数据的时候，是否有办法，在提升模型的并行运算能力的同时，对于序列中的每个token，也能让它不损失信息地看见序列里的其他tokens呢？ Attention就作为一种很好的改进办法出现了。每个token生成其对应的输出的过程是同时进行的，计算不需要等待。</p><p><img src="/2024/07/04/LLM-Transformer/v2-9b6041b7d63b4e73325ed34898b9d5fd_r.jpg" alt="Self Attention"></p><h4 id="2-2-Attention计算过程图解"><a href="#2-2-Attention计算过程图解" class="headerlink" title="2.2 Attention计算过程图解"></a>2.2 Attention计算过程图解</h4><p><strong>query，key，value的产生：</strong></p><p>假设batch_size&#x3D;1，输入序列X的形状为(seq_len &#x3D; 4, d_model &#x3D; 6)，则对于这串序列，我们产生三个参数矩阵：$W^Q、W^K、W^V$ 。通过上述的矩阵乘法，我们可以得到最终的结果Q，K，V。如下图所示：</p><p><img src="/2024/07/04/LLM-Transformer/v2-ab15fd18a31f3a63ef100688e9a5747f_1440w.webp" alt="query，key，value的产生"></p><p>一般来说， $W^Q$和$W^K$都同样使用$k_{dim}$， $W^V$使用$v_{dim}$。$k_{dim}$和$v_{dim}$不一定要相等，但在transformer的原始论文中，采用的策略是：$K_{dim}&#x3D;V_{dim}&#x3D;d_{model}&#x2F;&#x2F;n_{heads}$，其中$n_{heads}$为self-attention的头数。</p><p><strong>query，key，value的意义：</strong> </p><ul><li><p>query向量类比于询问。某个token问：“其余的token都和我有多大程度的相关呀？” </p><blockquote><p>Query用于与Key矩阵进行点积操作，以计算当前输入与所有输入之间的相似度或关联程度。这个相似度决定了当前输入关注其他输入的程度。</p></blockquote></li><li><p>key向量类比于索引。某个token说：“我把每个询问内容的回答都压缩了下装在我的key里” </p><blockquote><p>Key矩阵代表所有输入中每个单词（或输入）的特征，用于匹配Query以计算相似度。通过点积操作，Key帮助Query找到相关性高的输入。</p></blockquote></li><li><p>value向量类比于回答。某个token说：“我把我自身涵盖的信息又抽取了一层装在我的value里” </p><blockquote><p>Value矩阵代表所有输入中每个单词（或输入）的实际信息值，它是最终的加权结果。Value提供实际的信息内容，它会根据计算得到的注意力分数进行加权平均，从而得到每个输入的最终表示。这些加权后的值将被用于后续的层或输出。</p></blockquote></li></ul><p><img src="/2024/07/04/LLM-Transformer/v2-980e1c0abb79f7d16785a59d55618991_r.jpg" alt="Attention计算过程"></p><p>以图中的token a2为例： </p><ul><li>它产生一个query，每个query都去和别的token的key做“<strong>某种方式</strong>”的计算，得到的结果我们称为attention score（即为图中的$\alpha_{2,i}’$）。则一共得到四个attention score（attention score又可以被称为attention weight）。 </li><li>将这四个score再分别乘上每个token的value，我们会得到四个抽取信息完毕的向量。 </li><li>将这四个向量相加，就是最终a2过attention模型后所产生的结果b2。</li></ul><h4 id="2-3-Attention-Score-计算"><a href="#2-3-Attention-Score-计算" class="headerlink" title="2.3 Attention Score 计算"></a>2.3 Attention Score 计算</h4><p>$$<br>Attention(Q,K,V)&#x3D;softmax(\frac{QK^T}{\sqrt{d_k}})V<br>$$</p><p>其中$d_k$就是$k_{dim}$，而$softmax(\frac{QK^T}{\sqrt{d_k}})$就是Attention Score矩阵，我们来详细看下这个矩阵的计算过程:</p><p><img src="/2024/07/04/LLM-Transformer/v2-a5856289c63896fbb4dd9e7151bbde67_1440w.webp" alt="Attention Score矩阵"></p><p><strong>（勘误：紫色方框中的下标有误 )</strong></p><p>在softmax之后，attention score矩阵的<strong>每一行表示一个token</strong>，<strong>每一列表示该token和对应位置token的$\alpha$值</strong>，因为进行了softmax，每一行的$\alpha$值相加等于1。</p><p>论文中所采用的是scaled dot-product，因为乘上了因子$1&#x2F;\sqrt{d_k}$​ ，<font color="red">乘因子$1&#x2F;\sqrt{d_k}$ 的原因</font><strong>是为了使得在softmax的过程中，梯度下降得更加稳定，避免因为梯度过小而造成模型参数更新的停滞</strong>。下面我们通过数学证明，来解释这个结论：</p><hr><p>假设输入向量 ( q ) 和 ( k ) 的各个分量是独立同分布的随机变量，均值为0，方差为1，则q、k的点积的期望值和方差为：</p><p>期望：$\mathbb{E}[q \cdot k] &#x3D; 0$；方差：$\text{Var}(q \cdot k) &#x3D; d_k$</p><p>如果不进行缩放，点积的方差为 ( $d_k$ )，随着 ( $d_k$ ) 增大，点积的值会变得越来越大，这会导致Softmax函数的输入值也变大，从而使得Softmax函数的梯度变得很小，如下所示。通过乘以 ($ \frac{1}{\sqrt{d_k}}$ )，点积的方差变为1，这样可以使得点积的值在一个较小的范围内波动，保持数值稳定性，避免梯度消失问题。加上下图进行理解：</p><p><img src="/2024/07/04/LLM-Transformer/image-20240707231309184.png" alt="对于第i个token的j和j‘处的梯度计算"></p><hr>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLM-BERT</title>
    <link href="/2024/07/03/LLM-BERT/"/>
    <url>/2024/07/03/LLM-BERT/</url>
    
    <content type="html"><![CDATA[<h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BERT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLM-CLIP</title>
    <link href="/2024/07/03/LLM-CLIP/"/>
    <url>/2024/07/03/LLM-CLIP/</url>
    
    <content type="html"><![CDATA[<h3 id="CLIP"><a href="#CLIP" class="headerlink" title="## CLIP"></a>## CLIP</h3>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CLIP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLM-GPT</title>
    <link href="/2024/07/03/LLM-GPT/"/>
    <url>/2024/07/03/LLM-GPT/</url>
    
    <content type="html"><![CDATA[<h2 id="GPT"><a href="#GPT" class="headerlink" title="GPT"></a>GPT</h2>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLM-LangChain</title>
    <link href="/2024/07/03/LLM-LangChain/"/>
    <url>/2024/07/03/LLM-LangChain/</url>
    
    <content type="html"><![CDATA[<h2 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h2>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LangChain</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLM-T5</title>
    <link href="/2024/07/03/LLM-T5/"/>
    <url>/2024/07/03/LLM-T5/</url>
    
    <content type="html"><![CDATA[<h2 id="T5"><a href="#T5" class="headerlink" title="T5"></a>T5</h2>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>T5</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AIGC-StableDiffusion</title>
    <link href="/2024/06/28/AIGC-StableDiffusion/"/>
    <url>/2024/06/28/AIGC-StableDiffusion/</url>
    
    <content type="html"><![CDATA[<h2 id="AIGC–Stable-Diffusion"><a href="#AIGC–Stable-Diffusion" class="headerlink" title="AIGC–Stable Diffusion"></a>AIGC–Stable Diffusion</h2><p><strong>Stable Diffusion</strong>是一个基于Latent Diffusion Model（LDM）的文转图AI模型，其使用了<strong>CLIP ViT-L&#x2F;14的文本编码器</strong>，能够通过文本提示调整图像。它在运行时将成像过程分离成“<strong>扩散 （diffusion）</strong>”的过程，从有噪声的情况开始，逐渐改善图像，直到完全没有噪声，逐步接近所提供的文本描述。</p><p><strong>参考文章：</strong></p><blockquote><ol><li><p>在文章写完去扣源码时候才找到这两篇文章，写的非常牛逼，非常细节！！文章中许多图、想法来源于它：</p><p><a href="https://zhuanlan.zhihu.com/p/613337342%E3%80%81https://zhuanlan.zhihu.com/p/615310965">https://zhuanlan.zhihu.com/p/613337342、https://zhuanlan.zhihu.com/p/615310965</a></p></li><li><p>这三篇文章介绍DM模型还有其他内容等非常深入浅出，难以理解的数学公式介绍的非常详细，非常牛逼！！</p><p><a href="https://zhuanlan.zhihu.com/p/637815071%E3%80%81https://zhuanlan.zhihu.com/p/650394311%E3%80%81https://zhuanlan.zhihu.com/p/655568910">https://zhuanlan.zhihu.com/p/637815071、https://zhuanlan.zhihu.com/p/650394311、https://zhuanlan.zhihu.com/p/655568910</a></p></li><li><p>其他文章：</p><p><a href="http://shiyanjun.cn/archives/2212.html%E3%80%81https://jalammar.github.io/illustrated-stable-diffusion/">http://shiyanjun.cn/archives/2212.html、https://jalammar.github.io/illustrated-stable-diffusion/</a></p></li></ol></blockquote><p><strong>Latent Diffusion Model文章摘要：</strong></p><p><img src="/2024/06/28/AIGC-StableDiffusion/image-20240630102333319.png" alt="Latent Diffusion Model Abstract"></p><h3 id="1-模型结构"><a href="#1-模型结构" class="headerlink" title="1. 模型结构"></a>1. 模型结构</h3><hr><p><strong>结构图：</strong></p><p><img src="/2024/06/28/AIGC-StableDiffusion/s.png" alt="Stable Diffusion文生图模型简单框架"></p><p><img src="/2024/06/28/AIGC-StableDiffusion/image-20240630195921339.png" alt="Stable Diffusion文生图模型框架"></p><p><strong>模块</strong>：</p><blockquote><p><strong>CLIP Text Encoder</strong> : 提取输入的text的embedding , <font color="red">通过 cross attention 方式</font>送入扩散模型的 UNet 中作为 condition，注入语义信息，在训练时以context作为condition，使用cross attention机制来更好的学习文本与图像的匹配关系；</p><p><strong>Image Information Creator</strong></p><ul><li><p><strong>Image Encoder</strong> : 基于 VAE Eecoder 将图像压缩到 latent 空间，用向量表示；</p></li><li><p><strong>UNet+Scheduler</strong> : 扩散模型的主体，用来实现文本引导下的 latent 去噪生成；</p></li></ul><p><strong>Image Decode</strong> : 根据得到的 Latent Image，基于 VAE Decoder 生成最终的图像。。</p></blockquote><p><strong>过程：</strong></p><blockquote><p><strong>首先</strong>，输入 Prompt 提示词 “paradise, cosmic, beach”，经过 <strong>CLIP Text Encoder</strong> 组件的处理，将输入的 Prompt 提示词转换成 77×768 的 Token Embeddings，<code>该 Embeddings 输入到 Image Information Creator 组件</code>；</p><p><font color="green">这里如果有别的输入信息，比如Semantic Map（语义图）、Text（文本）、Representations（表示）、Images（图像）等，经过不同组件的处理，然后通过 cross attention 方式送入扩散模型的 UNet 中作为 condition。</font></p><p><strong>然后</strong>，Random image information tensor 是由一个 Latent Seed（Gaussian noise ~ N(0, 1)） 随机生成的 64×64 大小的图片表示，它表示一个完全的噪声图片，<code>作为 Image Information Creator 组件的另一个初始输入</code>；</p><p><strong>接着</strong>，通过 Image Information Creator 组件的处理（该过程称为 Diffusion），<code>生成一个包含图片信息的 64×64 的 Latent Image</code>，该输出包含了前面输入 Prompt 提示词所具有的语义信息的图片的信息；</p><p><strong>最后</strong>，上一步生成的 Latent Image 经过 Image Decoder 组件处理后<code>生成最终的和输入 Prompt 提示词相关的 512×512 大小的图片输出</code>。</p></blockquote><h3 id="2-具体实现"><a href="#2-具体实现" class="headerlink" title="2. 具体实现"></a>2. 具体实现</h3><hr><h4 id="2-0-到底什么是扩散-Diffusion-？"><a href="#2-0-到底什么是扩散-Diffusion-？" class="headerlink" title="2.0 到底什么是扩散(Diffusion)？"></a>2.0 <strong>到底什么是扩散(Diffusion)？</strong></h4><p>扩散是发生在“<strong>Image Information Creator</strong>”组件内部的过程。有了表示输入文本的标记嵌入「<strong>Token embeddings</strong>」和随机起始图像信息数组「<strong>Random image information tensor</strong>」，该过程会生成图像解码器用来绘制最终图像的信息数组。</p><h4 id="2-1-CLIP-Text-Encoder"><a href="#2-1-CLIP-Text-Encoder" class="headerlink" title="2.1 CLIP Text Encoder"></a>2.1 CLIP Text Encoder</h4><p>Stable Diffusion所使用的是OpenAI的CLIP的预训练模型，CLIP 「Contrastive Language-Image Pretraining」是一个多模态模型，能够同时理解和生成图像和文本。它可以将图像和文本进行对比学习，从而在各种多模态任务中表现出色。</p><p>CLIP需要的数据为图像及其描述，数据集中大约包含4亿张图像及其描述。CLIP整体模型如下所示：</p><p><img src="/2024/06/28/AIGC-StableDiffusion/image-20240628165159974.png" alt="CLIP模型"></p><ul><li><p>(1). <strong>对比预训练</strong> 「Contrastive pre-training」</p><blockquote><p>CLIP 是图像编码器和文本编码器的组合，使用两个编码器对数据分别进行编码。然后使用余弦距离比较结果嵌入，刚开始训练时，即使文本描述与图像是相匹配的，它们之间的相似性肯定也是很低的。随着模型的不断更新，在整个数据集中重复该过程，编码器对图像和文本编码得到的嵌入会逐渐相似。</p></blockquote></li><li><p>(2). <strong>从标签文本创建数据集分类器</strong> 「Create dataset classifier from label text」</p><blockquote><p><strong>作用</strong>：</p><ol><li><p><strong>构建分类器</strong>：在传统的图像分类任务中，通常需要为每个类别训练一个专门的分类器。<font color="red">CLIP 通过文本编码器将标签转换为描述性文本，并进一步转换为特征向量，从而构建一个零样本分类器。这些特征向量可以看作是每个类别的“代表”，可以直接用于分类任务。</font></p></li><li><p><strong>零样本学习</strong>：通过这种方式，CLIP 可以在没有看到任何特定类别的训练样本的情况下，依靠标签文本的描述来进行分类。这种能力被称为“零样本学习”，即模型可以识别从未见过的类别。</p></li></ol><p><strong>为什么需要这一步</strong>：</p><ol><li><p><strong>减少数据依赖</strong>：在实际应用中，获取每个类别的大量标注数据是非常困难的。通过从标签文本创建分类器，CLIP 能够在没有特定训练数据的情况下，利用现有的文本描述来实现分类。</p></li><li><p><strong>提高模型泛化能力</strong>：传统分类器只能处理训练时见过的类别，而 CLIP 的这种方法使其能够处理新类别，提高模型的泛化能力和适用范围。</p></li></ol></blockquote></li><li><p>(3). <strong>用于零样本预测</strong> 「Use for zero-shot prediction」</p><blockquote><p><strong>作用：</strong></p><ol><li><p><strong>实际应用</strong>：在实际应用中，将待分类的图像输入图像编码器，得到图像的特征向量，然后将这个特征向量与之前生成的类别特征向量进行匹配，找到最接近的类别。这一过程就是零样本预测的核心。</p></li><li><p><strong>扩展性</strong>：这一过程使得 CLIP 可以处理任意数量和类型的类别，只需提供相应的文本描述即可，无需重新训练模型。</p></li></ol><p><strong>为什么需要这一步</strong>：</p><ol><li><p><strong>实现分类任务</strong>：这一步是将 CLIP 应用于实际分类任务的关键，通过匹配图像和文本特征向量，实现图像分类。</p></li><li><p><strong>灵活性和扩展性</strong>：这种方法使得模型可以处理新出现的类别和变化多端的任务，只需要相应的文本描述即可，无需重新训练。这大大提高了模型的灵活性和扩展性。</p></li></ol></blockquote></li></ul><h4 id="2-2-Image-Information-Creator"><a href="#2-2-Image-Information-Creator" class="headerlink" title="2.2 Image Information Creator"></a>2.2 <strong>Image Information Creator</strong></h4><h5 id="2-2-1-Image-Encoder「VQ-VAE中的编码器部分」"><a href="#2-2-1-Image-Encoder「VQ-VAE中的编码器部分」" class="headerlink" title="2.2.1 Image Encoder「VQ-VAE中的编码器部分」"></a>2.2.1 Image Encoder「<strong>VQ-VAE</strong>中的编码器部分」</h5><p>在Stable Diffusion模型中，Image Encoder（图像编码器）是一个关键组件，用于将图像转换为潜在空间（latent space）中的表示，实现信息的有效压缩和重构。这些表示之后用于生成高质量的图像。</p><ul><li><p>架构</p><blockquote><ol><li><strong>卷积层</strong>：一系列的卷积层，用于逐步提取图像的局部特征。</li><li><strong>池化层</strong>：减少特征图的空间维度，从而降低计算复杂度。</li><li><strong>编码层</strong>：将提取到的特征转换为潜在向量表示。</li></ol></blockquote></li><li><p>工作流程</p><blockquote><ol><li><strong>输入图像</strong>：输入图像首先经过预处理步骤，例如归一化和大小调整。</li><li><strong>卷积层处理</strong>：经过多个卷积层和池化层，提取图像的特征并逐步降低空间维度。</li><li><strong>潜在表示生成</strong>：通过编码层，将提取的特征转换为潜在空间中的向量表示。</li></ol></blockquote></li></ul><p>这些潜在向量表示是扩散模型操作的核心，它们在扩散过程中逐步反向扩散（denoising），最终生成高质量的图像。Image Encoder在这个过程中扮演了至关重要的角色，确保输入图像能够被有效地压缩和表示，从而使得扩散过程能够生成准确且高质量的图像。</p><h5 id="2-2-2-UNet-Scheduler"><a href="#2-2-2-UNet-Scheduler" class="headerlink" title="2.2.2 UNet+Scheduler"></a>2.2.2 UNet+Scheduler</h5><p>当输入的图像、 文本提示词等信息经过不同组件分别被转换成 Image Embeddings、Token Embeddings… 之后，后续的操作就开始进入 Latent Space 中，通过向量来表示并进行各种处理操作，得到了包含 “原始图像 + 提示词” 信息的图像向量数据信息（Latent Image）。</p><p>下图中前向过程（$\varepsilon$为VAE的编码器）<strong>是我们生成数据以训练噪声预测器的方式</strong>。训练完成后，我们可以通过运行反向过程（$\mathbf{D}$为VAE的解码器）来生成图像。</p><p><img src="/2024/06/28/AIGC-StableDiffusion/image-20240629232700236.png" alt="图2"></p><p> Image Embeddings、Token Embeddings 等是如何在 UNet 网络中整合在一起的：</p><p><img src="/2024/06/28/AIGC-StableDiffusion/image-20240630110811534.png" alt="Image Embeddings、Token Embeddings 如何在UNet网络中整合在一起"></p><p>UNet网络具体结构如下：</p><p><img src="/2024/06/28/AIGC-StableDiffusion/v2-1a60fadfd1b8cb1b41bad5f7deddf526_1440w.webp" alt="UNet网络"></p><p>ResBlock+SpatialTransformer具体结构示意图：</p><p><img src="/2024/06/28/AIGC-StableDiffusion/v2-11ab7515941c3b343b28488d89b59ed0_r.jpg" alt="ResBlock+SpatialTransformer"></p><p><strong>相关组件解释：</strong></p><ol><li><p><code>time step embedding</code>是由<u>时间步信息</u>编码成的一个高维向量，以便与其他特征进行结合和处理。以下是详细解释：</p><p>这种嵌入方法的目的是将时间步长信息注入到模型中，使模型能够在生成过程中考虑时间维度上的变化。这种方法在稳定扩散模型中非常重要，因为它能够帮助模型在每个时间步长上进行准确的预测和生成。</p><p>生成 <code>timestep_embedding</code> 的方法如下：</p><ol><li><p><strong>Sine 和 Cosine 位置编码</strong>：</p><p>这种方法类似于 Transformer 模型中使用的位置编码。它使用正弦和余弦函数将时间步长嵌入到一个高维空间中。具体步骤如下：对每个时间步长 ( t ) 生成一个向量，其中每个维度对应一个特定的频率。使用正弦和余弦函数对这些频率进行编码。</p><p>具体公式如下：其中( t ) 是时间步长；( i ) 是向量的维度索引；( d ) 是向量的维度。</p><p>$\text{PE}_{(t, 2i)} &#x3D; \sin \left( \frac{t}{10000^{2i&#x2F;d}} \right) $</p><p>$\text{PE}_{(t, 2i+1)} &#x3D; \cos \left( \frac{t}{10000^{2i&#x2F;d}} \right) $</p></li><li><p><strong>线性变换</strong>：<br>生成的正弦和余弦位置编码向量通常会通过一个线性变换层，以适应模型的输入维度。</p></li><li><p><strong>结合噪声预测</strong>：<br>在噪声预测模型中，时间步长嵌入有助于模型理解不同时间步长下的噪声分布，从而更好地进行预测和生成。</p></li></ol></li></ol><h4 id="2-3-Image-Decoder「VQ-VAE中的解码器部分」"><a href="#2-3-Image-Decoder「VQ-VAE中的解码器部分」" class="headerlink" title="2.3 Image Decoder「VQ-VAE中的解码器部分」"></a>2.3 Image Decoder「<strong>VQ-VAE</strong>中的解码器部分」</h4><p>最后要把这个Latent Image，基于 VAE Decoder 从 Latent Space 再映射到 Pixel Space，得到我们最终需要生成的视觉图像。</p><h3 id="3-DDPM、DDIM、PLMS"><a href="#3-DDPM、DDIM、PLMS" class="headerlink" title="3. DDPM、DDIM、PLMS"></a>3. DDPM、DDIM、PLMS</h3><hr><h4 id="3-1-DDPM-denoising-diffusion-probabilistic-models"><a href="#3-1-DDPM-denoising-diffusion-probabilistic-models" class="headerlink" title="3.1 DDPM (denoising diffusion probabilistic models)"></a>3.1 DDPM (denoising diffusion probabilistic models)</h4><p>在上面所说的几个博客中已经介绍的非常详细了，而且其中的数学公式在大牛的博客中介绍的也非常详细了，但是推导过程依然有些懵懂，常看常新叭。主要解释了以下几个问题：</p><ol><li><p>最大似然估计</p><p>最大似然估计（Maximum Likelihood Estimation, MLE）是一种统计方法，用于估计模型参数，使得在给定观察数据的情况下，模型生成这些数据的概率最大。简单来说，<strong>MLE 通过最大化似然函数来找到最符合已知数据的模型参数</strong>。</p><p><strong>基本思想:</strong></p><p>假设我们有一个数据集 ${x_1, x_2, …, x_m}$，这些数据点是从某个概率分布 $P_{\text{data}}(x)$中抽取出来的。我们想要用一个参数化的模型 $P_\theta(x)$来近似这个分布，其中 ( $\theta$ ) 是模型的参数。</p><blockquote><p>最大似然估计的目标函数是对数似然函数的和，即：$\sum_{i&#x3D;1}^{m} \log P_\theta(x_i) $</p></blockquote><p><strong>在DDPM中公式推导步骤:</strong></p><p><img src="/2024/06/28/AIGC-StableDiffusion/image-20240704113802655.png" alt="最小化KL散度"></p><p>第一步：$[ \arg\max_\theta \int P_{\text{data}}(x) \log P_\theta(x) , dx ]$，这个积分表示在整个数据分布上的<strong>对数似然函数「$\log P_{\theta}(x)$」的期望</strong>。</p><p>第二步：$[\arg\max_\theta E_{x \sim P_{\text{data}}}[\log P_\theta(x)]]$，利用期望的定义，我们可以<strong>把积分表示成期望的形式</strong>。</p><blockquote><p>这里， $( E_{x \sim P_{\text{data}}} )$ 表示根据数据分布 $( P_{\text{data}}(x) )$ 的期望。</p></blockquote><p>第三步：$[ \arg\max_\theta \sum_{i&#x3D;1}^{m} \log P_\theta(x_i) ]$，在实际操作中，我们没有 $P_{\text{data}} $ 的精确形式，而是只有一个有限的数据样本 ${x_1, x_2, …, x_m}$。因此，我们<strong>使用样本均值来近似期望</strong>，这一步的近似就是在数据样本上的对数似然的求和。通过最大化这个和，我们就可以找到最符合数据的模型参数 $( \theta )$。</p></li><li><p>ELBO「Evidence Lower Bound」</p><p>$argmax_{\theta}\prod_{i&#x3D;1}^{m}P_\theta(x_i)$ 的本质就是要使得连乘中的每一项最大，也等同于使得$\log P_{\theta}(x)$最大。所以我们进一步来拆解 。</p><p><img src="/2024/06/28/AIGC-StableDiffusion/image-20240704122722262.png" alt="ELBO"></p></li><li><p>重参数「Reparamterization」技术</p><p>解决“从一个带参数的分布中进行采样”转变到“从一个确定的分布中进行采样”，以解决梯度无法传递的问题。</p></li></ol><h3 id="4-补充知识"><a href="#4-补充知识" class="headerlink" title="4. 补充知识"></a>4. 补充知识</h3><hr><h4 id="4-1-VQ-VAE（Vector-Quantized-Variational-Autoencoder）"><a href="#4-1-VQ-VAE（Vector-Quantized-Variational-Autoencoder）" class="headerlink" title="4.1 VQ-VAE（Vector Quantized Variational Autoencoder）"></a>4.1 VQ-VAE（Vector Quantized Variational Autoencoder）</h4><p>关于 VQ-VAE「Vector Quantized Variational Autoencoder，VQ-VAE」，是一种将离散表示学习引入自编码器框架的模型。它结合了传统变分自编码器（VAE）和向量量化技术，使模型能够在离散的潜在空间中进行编码和解码。这张图描述了向量量化变分自编码器的工作原理:</p><p><img src="/2024/06/28/AIGC-StableDiffusion/image-20240701164621499.png" alt="VQ-VAE"></p><p><strong>左侧部分：</strong></p><blockquote><ul><li><strong>输入图像</strong>：首先输入的是一张狗的图像。</li><li><strong>编码器（Encoder）</strong>：输入图像经过卷积神经网络（CNN）编码器，生成编码表示$ z_e(x) $。</li><li><strong>离散化（Discretization）</strong>：编码表示$z_e(x) $被映射到最近的嵌入点$ e_2 $，形成离散表示$z_q(x) $。</li><li><strong>量化（Quantization）</strong>：离散表示$z_q(x)$通过查找表将编码表示映射到最近的嵌入向量，形成量化表示。</li></ul></blockquote><p><strong>右侧部分:</strong></p><blockquote><ul><li><strong>嵌入空间（Embedding Space）</strong>：展示了嵌入空间的可视化。在这个空间中，编码器输出$ z_e(x) $被映射到最近的嵌入点$e_2$。</li><li><strong>梯度更新（Gradient Update）</strong>：红色箭头表示梯度$\nabla_{z}L$的方向，嵌入空间中的点通过梯度更新，推动编码器改变输出，从而优化整个模型。</li></ul></blockquote><p>其中，Encoder 能够将一个图像压缩到低维空间表示，在 Stable Diffusion 模型中，将原始输入图像通过 Encode 转换成 Latent Space 中的向量表示 Latent Image；</p><p>Decoder 能够将一个压缩表示的图像向量数据转换成高维空间表示，在 Stable Diffusion 模型中将 Latent Space 中图像的向量表示 Latent Image 通过 Decode 转换成 Pixel Space 中的视觉图像。</p><h4 id="4-2-什么叫做转换为潜在空间中的向量表示，它和提取的图像特征不是一回事吗？"><a href="#4-2-什么叫做转换为潜在空间中的向量表示，它和提取的图像特征不是一回事吗？" class="headerlink" title="4.2 什么叫做转换为潜在空间中的向量表示，它和提取的图像特征不是一回事吗？"></a>4.2 什么叫做转换为潜在空间中的向量表示，它和提取的图像特征不是一回事吗？</h4><p>将图像转换为潜在空间中的向量表示是特征提取的进一步抽象和压缩过程。这一过程的主要目的是将高维的、冗长的特征图压缩为低维的紧凑表示，同时保留图像的核心信息，便于后续的生成和操作。</p><ul><li><p>图像特征提取</p><blockquote><p>图像特征提取是指从输入图像中提取出能够代表图像内容的重要信息。这通常是通过一系列的卷积操作和其他神经网络层来实现的。特征提取的主要目标是捕捉图像的局部和全局信息，包括颜色、纹理、形状等。</p></blockquote></li><li><p><strong>潜在空间中的向量表示</strong></p><blockquote><p>潜在空间中的向量表示是<font color="red"><strong>通过对图像特征进一步处理</strong></font>得到的。这些表示通常是低维的紧凑向量，包含了图像的高层次抽象信息。潜在空间中的向量表示的主要目的是将图像数据压缩到一个更易处理和操作的形式，同时保留图像的关键信息。</p></blockquote></li><li><p>例子</p><blockquote><p>假设我们有一张猫的图像：</p><ol><li><strong>特征提取</strong>：卷积神经网络提取出猫的边缘、纹理、耳朵形状等特征，形成一个高维的特征图。</li><li><strong>潜在表示</strong>：特征图通过编码器压缩为一个低维向量。这个向量可能表示为[0.8, -1.2, 0.3, …]，其中的每个值都对应着图像的一些高层次特征，例如猫的种类、颜色、姿态等。</li></ol></blockquote></li></ul><h4 id="4-3-时间步骤（timestep）和条件信息（context-embedding）"><a href="#4-3-时间步骤（timestep）和条件信息（context-embedding）" class="headerlink" title="4.3 时间步骤（timestep）和条件信息（context embedding）"></a>4.3 时间步骤（timestep）和条件信息（context embedding）</h4><p>在 Stable Diffusion 模型中，时间步骤（timestep）和条件信息（如文本嵌入）被注入到不同的网络组件中，这是为了最大化它们在生成过程中的作用和效率。</p><ul><li>时间步骤加入到 ResBlock:</li></ul><blockquote><p>时间步骤通常通过时间嵌入的形式加入到残差块（ResBlock）中。通俗点来说，由于模型每一步的去噪都用的是同一个模型，所以我们必须告诉模型，现在进行的是哪一步去噪。因此我们要引入timestep，允许模型在每一层都根据当前的时间步骤调整其处理方式。timestep的表达方法类似于Transformer中的位置编码，将一个常数转换为一个向量，再和我们的输入图片进行相加。</p></blockquote><ul><li>条件信息加入到 Spatial Transformer:</li></ul><blockquote><p>条件信息，如文本嵌入，通常通过空间变换器（Spatial Transformer），也就是交叉注意力机制，加入到模型中。<font color="red">Spatial Transformer允许模型在图像特征和条件信息之间建立复杂的对应关系。通过使用交叉注意力，模型可以根据图像的每个部分和条件信息之间的关系来动态调整图像特征</font>。这种方式特别适合处理与空间位置相关的信息，因为它可以让模型关注条件信息中与当前正在生成的图像区域最相关的部分。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>AIGC</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Stable Diffusion</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Interview Direction Series</title>
    <link href="/2024/06/28/interview/"/>
    <url>/2024/06/28/interview/</url>
    
    <content type="html"><![CDATA[<h3 id="在当前的AIGC（AI-generated-content）领域，在各个领域中领先的模型："><a href="#在当前的AIGC（AI-generated-content）领域，在各个领域中领先的模型：" class="headerlink" title="在当前的AIGC（AI-generated content）领域，在各个领域中领先的模型："></a>在当前的AIGC（AI-generated content）领域，在各个领域中领先的模型：</h3><h4 id="1-文本生成"><a href="#1-文本生成" class="headerlink" title="1. 文本生成"></a>1. 文本生成</h4><ul><li><p><strong>GPT-4（OpenAI）</strong>：GPT-4 是 OpenAI 发布的最新版本的生成预训练变换模型，以其生成高质量的自然语言文本而闻名。它在各种自然语言处理任务中表现出色，包括对话生成、文本补全和内容创作。</p></li><li><p><strong>BERT（Google）</strong>：虽然BERT主要用于自然语言理解任务，但其衍生版本，如T5（Text-To-Text Transfer Transformer），在生成任务上表现也非常出色。</p></li><li><p><strong>T5（Google）</strong>：T5模型可以将各种NLP任务统一为文本到文本的问题，通过预训练和微调，在文本生成和转换任务中表现出色。</p></li></ul><h4 id="2-图像生成"><a href="#2-图像生成" class="headerlink" title="2. 图像生成"></a>2. 图像生成</h4><ul><li><p><strong>DALL-E 2（OpenAI）</strong>：DALL-E 2 是 OpenAI 开发的文本到图像生成模型，可以根据文本描述生成高度逼真的图像。它展示了AI在多模态生成任务中的强大能力。</p></li><li><p><strong>Stable Diffusion（Stability AI）</strong>：这是一个高效的扩散模型，能够在潜在空间中进行图像生成，从而大幅减少计算资源消耗，同时保持高质量的图像生成。</p></li><li><p><strong>Imagen（Google Research）</strong>：Imagen 是一个由 Google Research 开发的强大图像生成模型，通过结合大型语言模型和扩散模型，实现了高质量的文本到图像生成。</p></li></ul><h4 id="3-音频生成"><a href="#3-音频生成" class="headerlink" title="3. 音频生成"></a>3. 音频生成</h4><ul><li><p><strong>WaveNet（DeepMind）</strong>：WaveNet 是由 DeepMind 开发的生成模型，能够生成高保真的语音和音乐。它在语音合成任务上表现出色，被广泛应用于Google Assistant等产品中。</p></li><li><p><strong>Jukebox（OpenAI）</strong>：Jukebox 是 OpenAI 开发的音乐生成模型，可以生成不同风格和艺术家的音乐。它通过一个VAE-GAN架构实现了长时间的音乐生成。</p></li></ul><h4 id="4-视频生成"><a href="#4-视频生成" class="headerlink" title="4. 视频生成"></a>4. 视频生成</h4><ul><li><p><strong>MoCoGAN（Motion and Content Generative Adversarial Network）</strong>：MoCoGAN 是一种用于视频生成的生成对抗网络（GAN），能够同时生成视频的运动和内容。</p></li><li><p><strong>VideoGPT（OpenAI）</strong>：VideoGPT 是一种将GPT架构应用于视频生成任务的模型，利用自回归方式生成视频帧，展示了在视频生成任务上的潜力。</p></li></ul><h4 id="5-多模态生成"><a href="#5-多模态生成" class="headerlink" title="5. 多模态生成"></a>5. 多模态生成</h4><ul><li><p><strong>CLIP（Contrastive Language-Image Pretraining，OpenAI）</strong>：CLIP 是一个多模态模型，能够同时理解和生成图像和文本。它可以将图像和文本进行对比学习，从而在各种多模态任务中表现出色。</p></li><li><p><strong>ALIGN（Google Research）</strong>：ALIGN 是 Google 开发的多模态对比学习模型，能够在大规模数据上进行图像和文本的对比学习，在图像分类、检索等任务上取得了显著效果。</p></li></ul><p>这些模型在AIGC领域的进展展示了人工智能在生成内容方面的巨大潜力和多样性。随着技术的不断进步，这些模型在各自的应用领域中将继续推动创新和发展。</p><h3 id="视觉基础模型等领域（类似于SAM、SEEM、Grounding-DINO、LISA等工作）"><a href="#视觉基础模型等领域（类似于SAM、SEEM、Grounding-DINO、LISA等工作）" class="headerlink" title="视觉基础模型等领域（类似于SAM、SEEM、Grounding-DINO、LISA等工作）"></a>视觉基础模型等领域（类似于SAM、SEEM、Grounding-DINO、LISA等工作）</h3><ol><li><p><strong>SAM（Segment Anything Model）</strong>：</p><ul><li><strong>简介</strong>：SAM 是由 Meta AI 研究团队开发的一种<font color="red"><strong>图像分割模型</strong></font>，其设计目标是能够对任意图像进行任意物体的分割。</li><li><strong>特点</strong>：SAM 使用了一种新的分割技术，可以通过给定的提示（例如点击、框选或文本描述）来分割图像中的对象。这使得它在处理不同类型的图像和场景时具有很高的灵活性。</li><li><strong>应用</strong>：适用于需要精确分割的任务，如医学图像分析、自动驾驶、图像编辑等。</li></ul></li><li><p><strong>SEEM（Semantic Enhanced Efficient Model）</strong>：</p><ul><li><strong>简介</strong>：SEEM 是一种旨在提高图像识别和分割效率的模型，结合了<font color="red"><strong>语义信息增强和高效计算架构</strong></font>。</li><li><strong>特点</strong>：SEEM 利用语义增强技术，使得模型能够更好地理解图像中的内容，从而提高分割的准确性和效率。此外，模型架构设计也注重计算效率，适合在资源受限的环境中使用。</li><li><strong>应用</strong>：广泛应用于需要高效处理的任务，如移动设备上的图像处理、实时视频分析等。</li></ul></li><li><p><strong>Grounding-DINO</strong>：</p><ul><li><strong>简介</strong>：Grounding-DINO 是一个结合了<font color="red"><strong>语义理解和目标检测</strong></font>的模型，基于 DINO（DETR with Improved Non-Autoregressive Object Detection）的架构。</li><li><strong>特点</strong>：通过结合目标检测和语义理解，Grounding-DINO 可以实现更精确的目标检测，并能够在复杂场景中识别和定位多种对象。其非自回归设计使得检测速度更快。</li><li><strong>应用</strong>：适用于需要高精度和高效目标检测的应用，如自动驾驶、智能监控、无人机导航等。</li></ul></li><li><p><strong>LISA（Language-Image Semantic Alignment）</strong>：</p><ul><li><strong>简介</strong>：LISA 是一种用于图像和语言对齐的模型，旨在通过联合学习图像和文本的语义信息来提高多模态任务的性能。</li><li><strong>特点</strong>：LISA 利用一种对比学习的方法，使得模型能够更好地理解和关联图像和文本的语义信息，从而在图像标注、图像生成和图像搜索等任务中表现出色。</li><li><strong>应用</strong>：适用于多模态任务，如图像描述生成、视觉问答、跨模态检索等。</li></ul></li></ol><p>这些模型各有特点，适用于不同的视觉任务，通过结合不同的技术和架构，推动了计算机视觉领域的进步。</p><h3 id="Bilibili视觉算法实习生：多模态大模型理解、图像和视频分类、图片和视频描述生成、多模态融合、检索等"><a href="#Bilibili视觉算法实习生：多模态大模型理解、图像和视频分类、图片和视频描述生成、多模态融合、检索等" class="headerlink" title="Bilibili视觉算法实习生：多模态大模型理解、图像和视频分类、图片和视频描述生成、多模态融合、检索等"></a>Bilibili视觉算法实习生：多模态大模型理解、图像和视频分类、图片和视频描述生成、多模态融合、检索等</h3><h3 id="快手视觉算法实习生：视频内容理解算法"><a href="#快手视觉算法实习生：视频内容理解算法" class="headerlink" title="快手视觉算法实习生：视频内容理解算法"></a>快手视觉算法实习生：视频内容理解算法</h3>]]></content>
    
    
    <categories>
      
      <category>Interview</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Interview</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LeetCode</title>
    <link href="/2024/06/28/LeetCode/"/>
    <url>/2024/06/28/LeetCode/</url>
    
    <content type="html"><![CDATA[<h3 id="LeetCode-热题100"><a href="#LeetCode-热题100" class="headerlink" title="LeetCode 热题100"></a>LeetCode 热题100</h3><hr><h4 id="1-1-两数之和"><a href="#1-1-两数之和" class="headerlink" title="1. 1:两数之和"></a>1. 1:两数之和</h4><p># Hash表# 数组</p><blockquote><p>给定一个整数数组 <code>nums</code> 和一个整数目标值 <code>target</code>，请你在该数组中找出 <strong>和为目标值</strong> <code>target</code> 的那 <strong>两个</strong> 整数，并返回它们的数组下标。</p></blockquote><p><strong>解决：</strong></p><ul><li><p>暴力枚举法空间复杂度$O(1)$时间复杂度$O(N^2)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">twoSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        n = <span class="hljs-built_in">len</span>(nums)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i + <span class="hljs-number">1</span>, n):<br>                <span class="hljs-keyword">if</span> nums[i] + nums[j] == target:<br>                    <span class="hljs-keyword">return</span> [i, j]        <br>        <span class="hljs-keyword">return</span> []<br><br></code></pre></td></tr></table></figure></li><li><p>Hash法空间复杂度$O(N)$时间复杂度$O(N)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">twoSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>):<br>        hashtable = <span class="hljs-built_in">dict</span>()<br>        <span class="hljs-keyword">for</span> i, num <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(nums):<br>            <span class="hljs-keyword">if</span> target - num <span class="hljs-keyword">in</span> hashtable:<br>                <span class="hljs-keyword">return</span> [hashtable[target-num], i]<br>            hashtable[nums[i]] = i<br>        <span class="hljs-keyword">return</span> []<br></code></pre></td></tr></table></figure></li></ul><p><strong>总结：</strong></p><ol><li><p><code>enumerate()</code>是python的内置函数，用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">enumerate</span>(sequence, [start=<span class="hljs-number">0</span>])<br>* sequence: 一个序列、迭代器或其他支持迭代对象。<br>* start: 下标起始位置。<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">seasons = [<span class="hljs-string">&#x27;Spring&#x27;</span>, <span class="hljs-string">&#x27;Summer&#x27;</span>, <span class="hljs-string">&#x27;Fall&#x27;</span>, <span class="hljs-string">&#x27;Winter&#x27;</span>]<br><br><span class="hljs-built_in">list</span>(<span class="hljs-built_in">enumerate</span>(seasons))<br>[(<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;Spring&#x27;</span>), (<span class="hljs-number">1</span>, <span class="hljs-string">&#x27;Summer&#x27;</span>), (<span class="hljs-number">2</span>, <span class="hljs-string">&#x27;Fall&#x27;</span>), (<span class="hljs-number">3</span>, <span class="hljs-string">&#x27;Winter&#x27;</span>)]<br><span class="hljs-built_in">list</span>(<span class="hljs-built_in">enumerate</span>(seasons, start=<span class="hljs-number">1</span>))       <span class="hljs-comment"># 下标从 1 开始</span><br>[(<span class="hljs-number">1</span>, <span class="hljs-string">&#x27;Spring&#x27;</span>), (<span class="hljs-number">2</span>, <span class="hljs-string">&#x27;Summer&#x27;</span>), (<span class="hljs-number">3</span>, <span class="hljs-string">&#x27;Fall&#x27;</span>), (<span class="hljs-number">4</span>, <span class="hljs-string">&#x27;Winter&#x27;</span>)]<br></code></pre></td></tr></table></figure></li></ol><h4 id="2-149-字母异位词分组"><a href="#2-149-字母异位词分组" class="headerlink" title="2. 149:字母异位词分组"></a>2. 149:字母异位词分组</h4><p># Hash表# 数组# 字符串</p><blockquote><p>给你一个字符串数组，请你将 <strong>字母异位词</strong> 组合在一起。可以按任意顺序返回结果列表。</p><p><strong>字母异位词</strong> 是由重新排列源单词的所有字母得到的一个新单词。</p></blockquote><p><strong>解决：</strong></p><ul><li><p>Hash表时间复杂度$O(nk\log{k})$空间复杂度$O(nk)$</p><p>其中 <em>n</em> 是 <em>strs</em> 中的字符串的数量，<em>k</em> 是 <em>strs</em> 中的字符串的的最大长度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">groupAnagrams</span>(<span class="hljs-params">self, strs: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>):<br>        hashtable = collections.defaultdict(<span class="hljs-built_in">list</span>)<br>        <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> strs:<br>            key = <span class="hljs-string">&quot;&quot;</span>.join(<span class="hljs-built_in">sorted</span>(s))<br>            hashtable[key].append(s)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">list</span>(hashtable.values())<br><br></code></pre></td></tr></table></figure></li><li><p>计数时间复杂度$O(n(k+26)$空间复杂度$O(n(k+26))$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">groupAnagrams</span>(<span class="hljs-params">self, strs</span>):<br>        hashtable = collections.defaultdict(<span class="hljs-built_in">list</span>)<br>        <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> strs:<br>            count = [<span class="hljs-number">0</span>] * <span class="hljs-number">26</span><br>            <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> s:<br>                count[<span class="hljs-built_in">ord</span>(c)-<span class="hljs-built_in">ord</span>(<span class="hljs-string">&quot;a&quot;</span>)] += <span class="hljs-number">1</span><br>            hashtable[<span class="hljs-built_in">tuple</span>(count)].append(s)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">list</span>(hashtable.values())<br></code></pre></td></tr></table></figure></li></ul><p><strong>总结：</strong></p><ol><li><p>在这里使用<code>hashtable=&#123;&#125;</code>可能会有一些keyError等问题，需要我们多写一些代码，而使用<code>defaultdict</code>可以避免 ：</p><p><code>defaultdict</code> 的构造函数接受一个工厂函数作为参数，这个工厂函数<strong>在访问不存在的键时</strong>会被调用生成默认值。例如，<code>defaultdict(list) </code>表示当访问的键不存在时，会自动生成一个空列表作为默认值。</p></li><li><p>Map、HashTable、Dict等的区别和联系</p></li></ol><h4 id="3-128-最长连续序列"><a href="#3-128-最长连续序列" class="headerlink" title="3. 128:最长连续序列"></a>3. 128:最长连续序列</h4><p># Hash表# 数组</p><blockquote><p>给定一个未排序的整数数组 <code>nums</code> ，找出数字连续的最长序列（不要求序列元素在原数组中连续）的长度。</p><p>请你设计并实现时间复杂度为 <code>O(n)</code> 的算法解决此问题。</p></blockquote><p><strong>解决：</strong></p><ul><li><p>数组排序时间复杂度$O(n\log{n})$空间复杂度$O(1)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">longestConsecutive</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>)-&gt;<span class="hljs-built_in">int</span>:<br>        <span class="hljs-keyword">if</span> nums == []:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        nums_sorted = <span class="hljs-built_in">sorted</span>(nums)<br>        max_length = <span class="hljs-number">1</span><br>        tmp = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums_sorted) - <span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> nums_sorted[i+<span class="hljs-number">1</span>] == nums_sorted[i]+<span class="hljs-number">1</span>:<br>                tmp += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> nums_sorted[i+<span class="hljs-number">1</span>] == nums_sorted[i]:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">else</span>:<br>                tmp=<span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> tmp&gt;max_length:<br>                max_length = tmp<br>        <span class="hljs-keyword">return</span> max_length<br></code></pre></td></tr></table></figure></li><li><p>Hash表时间复杂度$O(N)$空间复杂度$O(N)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">longestConsecutive</span>(<span class="hljs-params">self, nums</span>):<br>        nums_set = <span class="hljs-built_in">set</span>(nums)<br>        longest_streak = <span class="hljs-number">0</span><br><br>        <span class="hljs-comment"># 非常聪明的将时间复杂度高的‘排序’替换为‘查找’</span><br>        <span class="hljs-keyword">for</span> n <span class="hljs-keyword">in</span> nums_set:<br>            <span class="hljs-keyword">if</span> n-<span class="hljs-number">1</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> nums_set:<br>                current_num = n<br>                current_streak = <span class="hljs-number">1</span><br><br>                <span class="hljs-keyword">while</span> current_num+<span class="hljs-number">1</span> <span class="hljs-keyword">in</span> nums_set:<br>                    current_num += <span class="hljs-number">1</span><br>                    current_streak += <span class="hljs-number">1</span><br>                <br>                longest_streak = <span class="hljs-built_in">max</span>(current_streak, longest_streak)<br>        <span class="hljs-keyword">return</span> longest_streak<br></code></pre></td></tr></table></figure></li></ul><p><strong>总结：</strong></p><ol><li><p>在Python中，<code>set()</code> 是一种数据结构，用于存储不重复的元素集合。</p><p>集合（set）是一种无序的数据结构，不支持通过索引来访问元素。集合中的元素是无序的，因此没有像列表那样的索引机制。</p><pre><code class="hljs">集合（Set）在底层是通过哈希表实现的。哈希表通过哈希函数将元素映射到一个存储桶，理论上可以在常数时间内完成插入、删除和查找操作。因此，查找一个元素是否在集合中，平均时间复杂度是 O(1)。</code></pre><p>列表（List）</p><pre><code class="hljs">列表（List）是一个有序集合，元素按顺序存储。为了查找一个元素是否在列表中，最坏情况下需要遍历整个列表，检查每个元素。因此，查找操作的时间复杂度是 O(n)，其中 n 是列表中的元素数量。</code></pre></li></ol><h4 id="4-283-移动零"><a href="#4-283-移动零" class="headerlink" title="4. 283:移动零"></a>4. 283:移动零</h4><p># 数组# 双指针</p><blockquote><p>给定一个数组 <code>nums</code>，编写一个函数将所有 <code>0</code> 移动到数组的末尾，同时保持非零元素的相对顺序。</p></blockquote><p><strong>解决：</strong></p><ul><li>双指针时间复杂度$O(N)$空间复杂度$O(1)$</li></ul><p></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">moveZeroes</span>(<span class="hljs-params">self, nums</span>):<br>        left = right = <span class="hljs-number">0</span><br>        num_len = <span class="hljs-built_in">len</span>(nums) <br><span class="hljs-comment"># right指针遍历整个列表</span><br>        <span class="hljs-keyword">while</span> right &lt; num_len:<br>          <span class="hljs-comment"># right指针的目标就是寻找非零值与left指针交换，当找到则两个指针同时右移</span><br>            <span class="hljs-keyword">if</span> nums[right] != <span class="hljs-number">0</span>:<br>                nums[left], nums[right] = nums[right], nums[left]<br>                left += <span class="hljs-number">1</span><br>            right += <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>总结：</strong></p><ol><li><p>这道题的难度被归为简单，解决方法标签为双指针。但是我很疑惑python中如何实现C++中传统的指针功能，ChatGPT回答如下：</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">在 Python 中，虽然没有直接的指针概念，但你可以通过几种方式实现类似于 C</span><span class="hljs-literal">++</span> <span class="hljs-comment">中指针的功能。主要方法包括使用对象的引用、可变数据类型以及通过封装类来模拟指针行为。</span><br><span class="hljs-comment">1</span><span class="hljs-string">.</span><span class="hljs-comment">在 Python 中，所有变量实际上都是对象的引用（类似于指针）。通过传递对象的引用，可以实现类似指针的功能。</span><br><span class="hljs-comment">2</span><span class="hljs-string">.</span><span class="hljs-comment">Python 的可变数据类型（如列表、字典和自定义对象）可以用于模拟指针的行为，因为它们可以在函数调用中被修改。</span><br><span class="hljs-comment">3</span><span class="hljs-string">.</span><span class="hljs-string">.</span><span class="hljs-string">.</span><span class="hljs-string">.</span><br></code></pre></td></tr></table></figure></li><li><p>这道题其实还有一些解决办法，比如找到<code>0</code>后面的数都往前移动、或者暴力对列表remove&#x2F;append等，但是时间复杂度会很高。</p><p>这个双指针的解决办法说实话很巧妙，但是理解起来有点复杂，评论区说可以按<u>快排的原理</u>去理解，在这里梳理一下：</p><ul><li>当L和R指针指向同一个位置的时候，此时还没有遇到<code>0</code>，交换位置无所谓；</li><li>当L和R指针不指向同一个位置的时候，就一定是遇到了<code>0</code>，此后，L指针一定是指向<code>0</code>，它的左边是处理好的数据。</li></ul></li></ol><h4 id="5-11-盛最多水的容器"><a href="#5-11-盛最多水的容器" class="headerlink" title="5. 11:盛最多水的容器"></a>5. 11:盛最多水的容器</h4><p># 贪心# 双指针# 数组 </p><blockquote><p>给定一个长度为 <code>n</code> 的整数数组 <code>height</code> 。有 <code>n</code> 条垂线，第 <code>i</code> 条线的两个端点是 <code>(i, 0)</code> 和 <code>(i, height[i])</code> 。</p><p>找出其中的两条线，使得它们与 <code>x</code> 轴共同构成的容器可以容纳最多的水。返回容器可以储存的最大水量。</p><p><strong>说明：</strong>你不能倾斜容器。</p></blockquote><p><strong>解决：</strong></p><ul><li>双指针时间复杂度$O(N)$空间复杂度$O(1)$</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">maxArea</span>(<span class="hljs-params">self, height</span>):<br>        lens = <span class="hljs-built_in">len</span>(height)<br>        left = <span class="hljs-number">0</span><br>        right = lens-<span class="hljs-number">1</span><br><br>        maxArea = <span class="hljs-number">0</span><br>        curArea = <span class="hljs-number">0</span><br>        <br>        <span class="hljs-keyword">while</span> left != right:<br>            <span class="hljs-keyword">if</span> height[left] &lt;= height[right]:<br>                curArea = height[left] * (right-left)<br>                left += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                curArea = height[right] * (right-left)<br>                right -=<span class="hljs-number">1</span><br>            <br>            maxArea = <span class="hljs-built_in">max</span>(maxArea,curArea)<br>        <span class="hljs-keyword">return</span> maxArea<br></code></pre></td></tr></table></figure><p><strong>总结：</strong></p><ol><li>这道题也可以用暴力解法，双层循环遍历两次列表，判断每一组值，但是时间复杂度为$O(N^2)$。</li><li>一开始两个指针一个指向开头一个指向结尾，此时容器的底是最大的，接下来随着指针向内移动，会造成容器的底变小，这种情况下我们想要让指针移动后的容器面积增大，就要使移动后的容器的高尽量大，所以我们选择指针所指的高较小的那个指针进行移动，这样我们就保留了容器较高的那条边，放弃了较小的那条边，以获得有更高的边的机会。</li></ol><h4 id="6-15-三数之和"><a href="#6-15-三数之和" class="headerlink" title="6. 15:三数之和"></a>6. 15:三数之和</h4><p># 排序# 双指针# 数组</p><blockquote><p>给你一个整数数组 <code>nums</code> ，判断是否存在三元组 <code>[nums[i], nums[j], nums[k]]</code> 满足 <code>i != j</code>、<code>i != k</code> 且 <code>j != k</code> ，同时还满足 <code>nums[i] + nums[j] + nums[k] == 0</code> 。请你返回所有和为 <code>0</code> 且不重复的三元组。</p><p><strong>注意：</strong>答案中不可以包含重复的三元组。</p></blockquote><p><strong>解决：</strong></p><ul><li><p>双指针时间复杂度$O(N^2)$空间复杂度$O(1)$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">threeSum</span>(<span class="hljs-params">self, nums</span>):<br>        nums_sort = <span class="hljs-built_in">sorted</span>(nums)<br>        res = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(nums_sort)):<br>            <span class="hljs-keyword">if</span> nums_sort[i] &gt; <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-comment"># 去重</span><br>            <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums_sort[i] == nums_sort[i-<span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-comment"># 双指针</span><br>            l = i+<span class="hljs-number">1</span><br>            r = <span class="hljs-built_in">len</span>(nums_sort)-<span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> l &lt; r:<br>                s = nums_sort[l] + nums_sort[r] + nums_sort[i]<br>                <span class="hljs-keyword">if</span> s == <span class="hljs-number">0</span>:<br>                    res.append([nums_sort[i],nums_sort[l],nums_sort[r]])<br>                    r -= <span class="hljs-number">1</span><br>                    <span class="hljs-comment"># 去重</span><br>                    <span class="hljs-keyword">while</span> l&lt;r <span class="hljs-keyword">and</span> nums_sort[r]== nums_sort[r+<span class="hljs-number">1</span>]:r -= <span class="hljs-number">1</span><br>                    l += <span class="hljs-number">1</span><br>                    <span class="hljs-comment"># 去重</span><br>                    <span class="hljs-keyword">while</span> l&lt;r <span class="hljs-keyword">and</span> nums_sort[l]== nums_sort[l-<span class="hljs-number">1</span>]:l += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">elif</span> s &gt; <span class="hljs-number">0</span>:<br>                    r -= <span class="hljs-number">1</span><br>                    <span class="hljs-comment"># 去重</span><br>                    <span class="hljs-keyword">while</span> l&lt;r <span class="hljs-keyword">and</span> nums_sort[r]== nums_sort[r+<span class="hljs-number">1</span>]:r -= <span class="hljs-number">1</span> <br>                <span class="hljs-keyword">elif</span> s &lt; <span class="hljs-number">0</span>:<br>                    l += <span class="hljs-number">1</span><br>                    <span class="hljs-comment"># 去重</span><br>                    <span class="hljs-keyword">while</span> l&lt;r <span class="hljs-keyword">and</span> nums_sort[l]== nums_sort[l-<span class="hljs-number">1</span>]:l += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></table></figure></li></ul><p><strong>总结：</strong></p><ol><li>双指针解法中 <code>l = i+1</code> 而不是 <code>l = 0</code> 的原因是，如果每次从0开始会造成重复解，<code>for</code>循环遍历每个数，与每个数有关的解都已经被列出，遍历到其他数时，不应该再包含之前已经处理好的值。</li><li>为什么不能用set方法先直接去掉重复的数字？因为像<code>[-1,-1,2]</code>这样的例子就不可行。</li></ol><h4 id="7-42-接雨水"><a href="#7-42-接雨水" class="headerlink" title="7. 42:接雨水"></a>7. <font color="red">42:接雨水</font></h4><p># 栈# 数组# 双指针# 动态规划#单调栈</p><blockquote><p>给定 <code>n</code> 个非负整数表示每个宽度为 <code>1</code> 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。</p></blockquote><p><img src="/2024/06/28/LeetCode/image-20240706170317206.png" alt="接雨水示例1"></p><p><strong>解决：</strong></p><ul><li><p>动态规划「按列」时间复杂度$O(N)$空间复杂度$O(N)$</p><p>对于下标<code> i</code>，下雨后水能到达的最大高度等于下标<code>i</code>两边的最大高度的最小值，下标 <code>i </code>处能接的雨水量等于下标 <code>i </code>处的水能到达的最大高度减去<code> height[i]</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">朴素的做法是对于数组 height 中的每个元素，分别向左和向右扫描并记录左边和右边的最大高度，然后计算每个下标位置能接的雨水量。该做法需要对每个下标位置使用 O(n) 的时间向两边扫描并得到最大高度，因此总时间复杂度是 O(n^2)。</span><br><span class="hljs-string">使用动态规划的方法，可以在 O(n) 的时间内预处理得到每个位置两边的最大高度:</span><br><span class="hljs-string">leftMax[i] = max(leftMax[i-1], height[i])</span><br><span class="hljs-string">rightMax[i] = max(rightMax[i+1], height[i])</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">trap</span>(<span class="hljs-params">self, height</span>):<br>        n = <span class="hljs-built_in">len</span>(height)<br>        ans = <span class="hljs-number">0</span><br>        leftMax = [height[<span class="hljs-number">0</span>]] + [<span class="hljs-number">0</span>] * (n-<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n):<br>            leftMax[i] = <span class="hljs-built_in">max</span>(leftMax[i-<span class="hljs-number">1</span>], height[i])<br><br>        rightMax = [<span class="hljs-number">0</span>] * (n-<span class="hljs-number">1</span>) + [height[n-<span class="hljs-number">1</span>]]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):<br>            rightMax[i] = <span class="hljs-built_in">max</span>(rightMax[i+<span class="hljs-number">1</span>], height[i])<br>        <br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            ans += <span class="hljs-built_in">min</span>(leftMax[i], rightMax[i]) - height[i]<br>        <br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure></li><li><p>单调栈「按行」时间复杂度$O(N)$空间复杂度$O(N)$</p><p>维护一个单调栈，单调栈存储的是下标，满足从栈底到栈顶的下标对应的数组 height 中的元素递减。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">1. 从左到右遍历数组，遍历到下标 i 时，如果栈内至少有两个元素，记栈顶元素为 top，top 的下面一个元素是 left，则一定有 height[left]≥height[top]。如果height[i]&gt;height[top]，则得到一个可以接雨水的区域，该区域的宽度是i−left−1，高度是min(height[left],height[i])−height[top]，根据宽度和高度即可计算得到该区域能接的雨水量。</span><br><span class="hljs-string">2. 为了得到 left，需要将 top 出栈。在对 top 计算能接的雨水量之后，left 变成新的 top，重复上述操作，直到栈变为空，或者栈顶下标对应的 height 中的元素大于或等于 height[i]。</span><br><span class="hljs-string">3. 在对下标 i 处计算能接的雨水量之后，将 i 入栈，继续遍历后面的下标，计算能接的雨水量。遍历结束之后即可得到能接的雨水总量。</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">trap</span>(<span class="hljs-params">self, height</span>):<br>        ans = <span class="hljs-number">0</span><br>        stack = <span class="hljs-built_in">list</span>()<br>        n = <span class="hljs-built_in">len</span>(height)<br><br>        <span class="hljs-keyword">for</span> i, h <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span> (height):<br>            <span class="hljs-keyword">while</span> stack <span class="hljs-keyword">and</span> h &gt; height[stack[-<span class="hljs-number">1</span>]]:<br>                top = stack.pop()<br>                <span class="hljs-comment"># 左边界构不成存储雨水的条件，直接退出</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> stack:<br>                    <span class="hljs-keyword">break</span><br>                <span class="hljs-comment"># 构成存储雨水的条件</span><br>                left = stack[-<span class="hljs-number">1</span>]<br>                curWidth = i - left - <span class="hljs-number">1</span><br>                curHeight = <span class="hljs-built_in">min</span>(height[left], height[i]) - height[top]<br>                ans += curWidth * curHeight<br>            stack.append(i)<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure></li><li><p><strong>双指针「按列」</strong>时间复杂度$O(N)$空间复杂度$O(1)$</p><p>解决动态规划的空间复杂度问题</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">trap</span>(<span class="hljs-params">self, height</span>):<br>        ans = <span class="hljs-number">0</span><br>        n = <span class="hljs-built_in">len</span>(height)<br>        l = <span class="hljs-number">0</span><br>        r = n-<span class="hljs-number">1</span><br>        lmax = rmax = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span> l &lt; r:<br>            lmax = <span class="hljs-built_in">max</span>(lmax, height[l])<br>            rmax = <span class="hljs-built_in">max</span>(rmax, height[r])<br>            <span class="hljs-keyword">if</span> height[l]&lt;height[r]:<br>                ans += lmax - height[l]<br>                l += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                ans += rmax - height[r]<br>                r -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></td></tr></table></figure></li></ul><p><strong>总结：</strong></p>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
      <category>LeetCode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LeetCode</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>BasicKnowledge</title>
    <link href="/2024/06/13/DeepLearningBasicKnowledge/"/>
    <url>/2024/06/13/DeepLearningBasicKnowledge/</url>
    
    <content type="html"><![CDATA[<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><blockquote><p>Batch Normalization (BN) 是一种深度学习技术，用于在训练过程中标准化神经网络的输入。其主要目的是加速训练过程并提高模型的稳定性和性能。</p></blockquote><hr><h4 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h4><p>假设我们有一个图像分类任务，输入图像的像素值在 0 到 255 之间。我们将像素值缩放到 0 到 1 之间，但不同批次的数据分布可能不同。例如，一个批次的图像可能大部分像素值集中在 0.1 到 0.3 之间，而另一个批次的图像像素值集中在 0.7 到 0.9 之间。这种输入数据分布的变化会导致模型训练不稳定。</p><p>通过使用 Batch Normalization，我们可以在每层网络中对输入进行标准化，使得每层的输入在训练过程中保持均值为 0、方差为 1 的分布，从而加快收敛速度并提高模型的稳定性和性能。</p><h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><ol><li><p><strong>计算批次均值和方差</strong>： 对于一个批次的输入 $x&#x3D;&lt;!–swig￼1–&gt;<br>$$</p></li><li><p>引入两个可训练参数 $\gamma$ 和 $\beta$，分别用于缩放和平移标准化后的输入，以保证模型的表达能力，其中，$\gamma$ 和 $\beta$ 是与输入维度相同的参数：<br>$$<br>y_i &#x3D; \gamma \hat{x_i} + \beta<br>$$</p></li></ol><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>Batch Normalization 之所以对网络训练产生积极作用，主要有以下几个原因：</p><ol><li><p><strong>减轻内部协变量偏移（Internal Covariate Shift）</strong>： 内部协变量偏移是指在训练过程中，由于前一层参数的变化，后续层的输入分布也发生变化，从而影响训练效率。</p><p>BN 通过标准化每一层的输入，使得每一层的输入分布更加稳定，从而减轻了层间输入分布变化带来的影响。这使得网络在训练时更容易收敛。</p></li><li><p><strong>加速训练</strong>： 由于每一层的输入被标准化，梯度下降算法在训练过程中能够使用较大的学习率，从而加快训练速度。</p></li><li><p><strong>提高模型的稳定性</strong>： BN 在一定程度上起到了正则化的作用，减少了过拟合的风险。这是因为每个批次的数据都被标准化，添加了噪声，从而增强了模型的泛化能力。</p></li><li><p><strong>缓解梯度消失和梯度爆炸</strong>： 标准化后的输入使得数据的尺度更加一致，从而缓解了梯度消失和梯度爆炸问题，特别是在深层神经网络中。</p></li></ol><h4 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-comment"># 定义一个简单的神经网络</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(SimpleNN, self).__init__()<br>        self.fc1 = nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">256</span>)<br>        self.bn1 = nn.BatchNorm1d(<span class="hljs-number">256</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>)<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.fc1(x)<br>        x = self.bn1(x)<br>        x = torch.relu(x)<br>        x = self.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-comment"># 初始化网络、损失函数和优化器</span><br>model = SimpleNN()<br>criterion = nn.CrossEntropyLoss()<br>optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0.9</span>)<br><br><span class="hljs-comment"># 示例训练步骤</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> train_loader:<br>        optimizer.zero_grad()<br>        outputs = model(inputs)<br>        loss = criterion(outputs, labels)<br>        loss.backward()<br>        optimizer.step()<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>, Loss: <span class="hljs-subst">&#123;loss.item()&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>BasicKnowledge</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Deep Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch</title>
    <link href="/2024/05/22/Pytorch/"/>
    <url>/2024/05/22/Pytorch/</url>
    
    <content type="html"><![CDATA[<h3 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h3><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs oxygene"><span class="hljs-keyword">Module</span>作为模块封装的父类，可以是一段逻辑，也可以是模型的一个块「<span class="hljs-keyword">block</span>」或一层。<br>Pytorch中自定义模型只需要继承<span class="hljs-keyword">Module</span>，保存好Param并提供<span class="hljs-keyword">forward</span>方法，backward被tensor的自动微分自动完成。<br></code></pre></td></tr></table></figure><hr><p>以一个简单的MLP的代码示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># Call the constructor of the parent class nn.Module to perform</span><br>        <span class="hljs-comment"># the necessary initialization</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.hidden = nn.LazyLinear(<span class="hljs-number">256</span>)<br>        self.out = nn.LazyLinear(<span class="hljs-number">10</span>)<br>    <span class="hljs-comment"># Define the forward propagation of the model, that is, how to return the</span><br>    <span class="hljs-comment"># required model output based on the input X</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-keyword">return</span> self.out(F.relu(self.hidden(X)))<br></code></pre></td></tr></table></figure><h4 id="1-回调「Hook」函数介绍"><a href="#1-回调「Hook」函数介绍" class="headerlink" title="1. 回调「Hook」函数介绍"></a>1. 回调「Hook」函数介绍</h4><p><strong>hook 函数机制</strong>：不改变主体，实现额外功能，像一个挂件、挂钩 ➡️ hook</p><h5 id="1-1-为什么会有-hook-函数这个机制：参考文章1"><a href="#1-1-为什么会有-hook-函数这个机制：参考文章1" class="headerlink" title="1.1 为什么会有 hook 函数这个机制：参考文章1"></a>1.1 <strong>为什么会有 hook 函数这个机制：</strong><a href="https://blog.csdn.net/weixin_44878336/article/details/133859089">参考文章1</a></h5><blockquote><p>这与 <strong>PyTorch 动态图运行机制</strong>有关:</p><p>在动态图运行机制中，当运算结束后，<font color="red">一些中间变量是会被释放掉的，比如特征图、非叶子节点的梯度。</font>但有时候我们又想要继续关注这些中间变量，那么就可以使用 hook 函数在主体代码中提取中间变量。</p><p>主体代码主要是模型的<strong>前向传播「forward」和反向传播「backward」</strong>，额外的功能就是对模型的中间变量进行操作如：</p><ol><li>提取&#x2F;修改张量梯度</li><li>提取&#x2F;保留非叶子张量的梯度</li><li>查看模型的层与层之间的数据传递情况（数据维度、数据大小等）</li><li>在不修改原始模型代码的基础上可视化各个卷积特征图</li><li>……</li></ol></blockquote><h5 id="1-2-演示Hook的作用：参考文章2"><a href="#1-2-演示Hook的作用：参考文章2" class="headerlink" title="1.2 演示Hook的作用：参考文章2"></a>1.2 <strong>演示Hook的作用</strong>：<a href="https://cloud.tencent.com/developer/article/1745455">参考文章2</a></h5><blockquote><p>一般来说，“hook”是在特定事件之后自动执行的函数。</p><p>PyTorch 为nn.Module 对象 &#x2F; 每个张量<font color="red"><strong>注册</strong></font> hook。hook 由对象的向前或向后传播触发。它们具有以下函数签名:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, Tensor<br><br><span class="hljs-comment"># For nn.Module objects only.</span><br>   <span class="hljs-keyword">def</span> <span class="hljs-title function_">module_hook</span>(<span class="hljs-params">module: nn.Module, <span class="hljs-built_in">input</span>: Tensor, output: Tensor</span>):<br>    <br><span class="hljs-comment"># For Tensor objects only.</span><br>   <span class="hljs-comment"># Only executed during the *backward* pass!</span><br>   <span class="hljs-keyword">def</span> <span class="hljs-title function_">tensor_hook</span>(<span class="hljs-params">grad: Tensor</span>):<br></code></pre></td></tr></table></figure></blockquote><ul><li><p><strong>例子1</strong>：假如你想知道每个层输出的形状。我们可以创建一个简单的 wrapper，使用 hook 打印输出形状:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, Tensor<br><span class="hljs-keyword">from</span> torchvision.models <span class="hljs-keyword">import</span> resnet50<br><span class="hljs-keyword">import</span> warnings<br><br>warnings.filterwarnings(<span class="hljs-string">&#x27;ignore&#x27;</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">VerboseExecution</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model: nn.Module</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># 传入resnet50模型</span><br>        self.model = model<br><br>        <span class="hljs-keyword">for</span> name, layer <span class="hljs-keyword">in</span> self.model.named_children():<br>            layer.__name__ = name<br>            <span class="hljs-comment"># Register a hook for each layer</span><br>            layer.register_forward_hook(<br>                <span class="hljs-keyword">lambda</span> layer, _, output: <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;layer.__name__&#125;</span>: <span class="hljs-subst">&#123;output.shape&#125;</span>&quot;</span>)<br>            )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: Tensor</span>) -&gt; Tensor:<br>        <span class="hljs-keyword">return</span> self.model(x)<br><br><br>verbose_resnet = VerboseExecution(resnet50())<br>dummy_input = torch.ones(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br><br>_ = verbose_resnet(dummy_input)<br><br><span class="hljs-comment"># --------输出</span><br><span class="hljs-comment"># conv1: torch.Size([10, 64, 112, 112])</span><br><span class="hljs-comment"># bn1: torch.Size([10, 64, 112, 112])</span><br><span class="hljs-comment"># relu: torch.Size([10, 64, 112, 112])</span><br><span class="hljs-comment"># maxpool: torch.Size([10, 64, 56, 56])</span><br><span class="hljs-comment"># layer1: torch.Size([10, 256, 56, 56])</span><br><span class="hljs-comment"># layer2: torch.Size([10, 512, 28, 28])</span><br><span class="hljs-comment"># layer3: torch.Size([10, 1024, 14, 14])</span><br><span class="hljs-comment"># layer4: torch.Size([10, 2048, 7, 7])</span><br><span class="hljs-comment"># avgpool: torch.Size([10, 2048, 1, 1])</span><br><span class="hljs-comment"># fc: torch.Size([10, 1000])</span><br></code></pre></td></tr></table></figure></li><li><p><strong>例子2</strong>：<strong>特征提取</strong>：通常，我们希望从一个预先训练好的网络中生成特性，然后用它们来完成另一个任务(例如分类等)。使用 hook，我们可以提取特征，而不需要重新创建现有模型或以任何方式修改它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, Tensor<br><span class="hljs-keyword">from</span> torchvision.models <span class="hljs-keyword">import</span> resnet50<br><span class="hljs-keyword">import</span> warnings<br><br>warnings.filterwarnings(<span class="hljs-string">&#x27;ignore&#x27;</span>)<br><br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Dict</span>, Iterable, <span class="hljs-type">Callable</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeatureExtractor</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model: nn.Module, layers: Iterable[<span class="hljs-built_in">str</span>]</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.model = model<br>        self.layers = layers<br>        self._features = &#123;layer: torch.empty(<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> layers&#125;<br><br>        <span class="hljs-keyword">for</span> layer_id <span class="hljs-keyword">in</span> layers:<br>            layer = <span class="hljs-built_in">dict</span>([*self.model.named_modules()])[layer_id]<br>            <span class="hljs-comment"># Register a hook</span><br>            layer.register_forward_hook(self.save_outputs_hook(layer_id))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">save_outputs_hook</span>(<span class="hljs-params">self, layer_id: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">Callable</span>:<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">fn</span>(<span class="hljs-params">_, __, output</span>):<br>            self._features[layer_id] = output<br>        <span class="hljs-keyword">return</span> fn<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: Tensor</span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, Tensor]:<br>        _ = self.model(x)<br>        <span class="hljs-keyword">return</span> self._features<br><br>resnet_features = FeatureExtractor(resnet50(), layers=[<span class="hljs-string">&quot;layer4&quot;</span>, <span class="hljs-string">&quot;avgpool&quot;</span>])<br>dummy_input = torch.ones(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br>features = resnet_features(dummy_input)<br><br><span class="hljs-built_in">print</span>(&#123;name: output.shape <span class="hljs-keyword">for</span> name, output <span class="hljs-keyword">in</span> features.items()&#125;)<br><br><span class="hljs-comment"># 输出</span><br><span class="hljs-comment"># &#123;&#x27;layer4&#x27;: torch.Size([10, 2048, 7, 7]), &#x27;avgpool&#x27;: torch.Size([10, 2048, 1, 1])&#125;</span><br></code></pre></td></tr></table></figure></li><li><p><strong>例子3：梯度裁剪</strong>：梯度裁剪是处理梯度爆炸的一种著名方法。PyTorch 已经提供了梯度裁剪的工具方法，但是我们也可以很容易地使用 hook 来实现它。其他任何用于梯度裁剪&#x2F;归一化&#x2F;修改的方法都可以用同样的方式实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient_clipper</span>(<span class="hljs-params">model: nn.Module, val: <span class="hljs-built_in">float</span></span>) -&gt; nn.Module:<br>    <span class="hljs-keyword">for</span> parameter <span class="hljs-keyword">in</span> model.parameters():<br>      <span class="hljs-comment"># Register a hook for each parameter</span><br>        <br>        <span class="hljs-comment"># register_hook 方法的主要作用是允许用户在张量的梯度计算中注册一个自定义函数</span><br>        <span class="hljs-comment"># 以便在反向传播期间对梯度进行操作或记录信息。</span><br>        <span class="hljs-comment"># 这对于实现自定义梯度处理、梯度剪裁、可视化梯度信息以及梯度的修改等任务非常有用。</span><br>        parameter.register_hook(<span class="hljs-keyword">lambda</span> grad: grad.clamp_(-val, val))<br>    <br>    <span class="hljs-keyword">return</span> model<br><br>clipped_resnet = gradient_clipper(resnet50(), <span class="hljs-number">0.01</span>)<br>pred = clipped_resnet(dummy_input)<br>loss = pred.log().mean()<br>loss.backward()<br><br><span class="hljs-built_in">print</span>(clipped_resnet.fc.bias.grad[:<span class="hljs-number">25</span>])<br><br><span class="hljs-comment"># 输出</span><br><span class="hljs-comment"># tensor([-0.0010, -0.0047, -0.0010, -0.0009, -0.0015,  0.0027,  0.0017, -0.0023,</span><br><span class="hljs-comment">#          0.0051, -0.0007, -0.0057, -0.0010, -0.0039, -0.0100, -0.0018,  0.0062,</span><br><span class="hljs-comment">#          0.0034, -0.0010,  0.0052,  0.0021,  0.0010,  0.0017, -0.0100,  0.0021,</span><br><span class="hljs-comment">#          0.0020])</span><br></code></pre></td></tr></table></figure></li></ul><h5 id="1-3一些常见的Hook函数："><a href="#1-3一些常见的Hook函数：" class="headerlink" title="1.3一些常见的Hook函数："></a>1.3<strong>一些常见的Hook函数</strong>：</h5><ul><li><p><code>register_forward_hook</code> 是 PyTorch 中用于在神经网络的<strong>前向传播过程中</strong>注册钩子的一个函数。这个钩子函数会在模块执行其 <code>forward</code> 方法时被调用，可以用来检查或修改中间输出。</p><p><code>module.register_forward_hook(hook)</code>:</p><p><img src="/2024/05/22/Pytorch/image-20240522161226987.png" alt="register_forward_hook"></p></li><li><p><code>register_hook</code> 是 PyTorch 中用于在神经网络的<strong>反向传播过程中</strong>注册钩子的函数。这个钩子函数会在张量的梯度计算过程中被调用，主要用于调试和修改梯度。</p><p><code>tensor.register_hook(hook)</code>:</p><p><img src="/2024/05/22/Pytorch/image-20240522161159145.png" alt="register_hook"></p></li><li><p>回调「Hook」函数注册</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 三个全局变量，dict类型，存储回调函数（即hook），用于net中的所有module</span><br><span class="hljs-comment"># 用于输入输出tensor</span><br>_global_buffer_registration_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br><span class="hljs-comment"># 用于module定义</span><br>_global_module_registration_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br><span class="hljs-comment"># 用于模型参数</span><br>_global_parameter_registration_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br><br><br><span class="hljs-string">r&quot;&quot;&quot;This tracks hooks common to all modules that are executed before/after</span><br><span class="hljs-string">calling forward and backward. This is global state used for debugging/profiling</span><br><span class="hljs-string">purposes&quot;&quot;&quot;</span> <br><span class="hljs-comment"># 用于在module的forward和backward接口前后注册回调函数，例如dump出每个op的输入输出结果</span><br>_global_backward_pre_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br>_global_backward_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br>_global_is_full_backward_hook: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">None</span><br>_global_forward_pre_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br>_global_forward_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br><br><span class="hljs-comment"># 提供reg接口在完成回调函数注册</span><br>register_module_buffer_registration_hook()<br>register_module_module_registration_hook()<br>register_module_parameter_registration_hook()<br><br>register_module_forward_pre_hook()<br>register_module_forward_hook()<br>register_module_backward_hook()<br>register_module_full_backward_pre_hook()<br>register_module_full_backward_hook()<br></code></pre></td></tr></table></figure></li></ul><h5 id="1-4-Module成员变量分析"><a href="#1-4-Module成员变量分析" class="headerlink" title="1.4 Module成员变量分析"></a>1.4 Module成员变量分析</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 版本号，一个内部使用的属性，用于跟踪模块的版本。这一机制主要用于在序列化（serialization）和反序列化（deserialization）过程中管理模型的兼容性。</span><br>_version: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span> <br><span class="hljs-comment"># 一个布尔值，表示模块是否处于训练模式。可以通过 model.train() 和 model.eval() 方法切换。</span><br>training: <span class="hljs-built_in">bool</span> <br><span class="hljs-comment"># 存储模块的所有参数（Parameter 对象），类型为 OrderedDict，如conv的weight、bias等</span><br>_parameters: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Optional</span>[Parameter]] <br><span class="hljs-comment"># 存储模块中的所有缓冲区（Tensor 对象），类型为 OrderedDict。缓冲区是模型状态的一部分，但不是参数，比如 BatchNorm 的running mean 和 running variance。</span><br>_buffers: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Optional</span>[Tensor]] <br><span class="hljs-comment"># 存储模块的子模块，类型为 OrderedDict。每个子模块在模型中都有一个唯一的名称。</span><br>_modules: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Optional</span>[<span class="hljs-string">&#x27;Module&#x27;</span>]]<br><br><br><span class="hljs-comment"># 存储反向传播前的钩子，类型为 OrderedDict。这些钩子在反向传播前的过程中被调用。</span><br>_backward_pre_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] <br><span class="hljs-comment"># 存储反向传播钩子，类型为 OrderedDict。这些钩子在反向传播过程中被调用。</span><br>_backward_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]<br><span class="hljs-comment"># 存储前向传播钩子，类型为 OrderedDict。这些钩子在前向传播过程中被调用。</span><br>_forward_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]<br><br><br><span class="hljs-comment"># 存储 state_dict 钩子，类型为 OrderedDict。这些钩子在调用 state_dict 时被调用。</span><br>_state_dict_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]  // 模型加载时，op的参数加载相关的回调函数<br>_load_state_dict_pre_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]<br>_state_dict_pre_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]<br>_load_state_dict_post_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]<br><br></code></pre></td></tr></table></figure><h5 id="1-5-Module方法分析"><a href="#1-5-Module方法分析" class="headerlink" title="1.5 Module方法分析"></a>1.5 Module方法分析</h5>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Fatser R-CNN Source Code</title>
    <link href="/2024/05/21/Faster-RCNN_SourceCode/"/>
    <url>/2024/05/21/Faster-RCNN_SourceCode/</url>
    
    <content type="html"><![CDATA[<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/2024/05/21/Faster-RCNN_SourceCode/v2-4c23436f431a535e2cc2e9919b3ca10f_r.jpg" alt="Faster RCNN model"></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1. </p><h3 id="PyTorch代码学习"><a href="#PyTorch代码学习" class="headerlink" title="PyTorch代码学习"></a>PyTorch代码学习</h3><ol><li><p><code>torch._assert(False, &quot;XXX&quot;)</code></p><blockquote><p>assert函数叫做断言函数，它可以用于判断某个表达式的值，若是该值为真，那么程序就能够继续往下执行; 反之，会报出AssertionError错误。</p></blockquote></li><li><p><code>if isinstance(boxes, torch.Tensor)</code></p><blockquote><p>判断两个类型是否相同</p></blockquote></li></ol>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Object Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RCNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLO Series</title>
    <link href="/2024/05/20/Yolo/"/>
    <url>/2024/05/20/Yolo/</url>
    
    <content type="html"><![CDATA[<h3 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h3>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Object Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PaddlePaddle-CPPD</title>
    <link href="/2024/05/19/PaddlePaddle_CPPD/"/>
    <url>/2024/05/19/PaddlePaddle_CPPD/</url>
    
    <content type="html"><![CDATA[<ul><li><h4 id="准备好训练数据集"><a href="#准备好训练数据集" class="headerlink" title="准备好训练数据集"></a>准备好训练数据集</h4><p>以PARSeq（lmdb数据格式）为例，在项目文件中如下：</p><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519204701863.png" alt="image-20240519204701863"></p></li><li><h4 id="报错解决"><a href="#报错解决" class="headerlink" title="报错解决"></a>报错解决</h4><ol><li><p>CUDA和CUDNN的配置问题</p><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519174249876.png" alt="image-20240519174249876"></p><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519202939423.png" alt="image-20240519202939423">解决办法：</p><blockquote><ol><li>下载正确CUDA版本的CUDA Toolkit</li><li>下载正确CUDA版本的cuDNN，将dll动态链接库文件复制到CUDA Toolkit中</li></ol></blockquote></li><li><p>其他报错解决</p></li></ol></li><li><h4 id="成功训练"><a href="#成功训练" class="headerlink" title="成功训练"></a>成功训练</h4><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519204959939.png" alt="image-20240519204959939"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Optical Character Recognition</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CPPD</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker</title>
    <link href="/2024/05/15/Docker/"/>
    <url>/2024/05/15/Docker/</url>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><hr><p>Docker是一个用于<strong>构建(build)</strong>,<strong>运行(run)</strong>,<strong>传送(share)</strong> 应用程序的平台</p><ol><li><strong>将应用程序打包为一个个的集装箱</strong>，小鲸鱼(Docker)就会帮我们将它们运送到任何需要的地方</li></ol><p><img src="/2024/05/15/Docker/docker.png" alt="集装箱"></p><ol start="2"><li><strong>每个集装箱将下列文件打包在一起</strong>（应用程序和它运行时所需要的各种依赖包、第三方软件库、配置文件等），以便在任何环境中都可以正确的运行</li></ol><p><img src="/2024/05/15/Docker/image-20240515112551349.png" alt="集装箱内文件"></p><h3 id="为什么要使用Docker"><a href="#为什么要使用Docker" class="headerlink" title="为什么要使用Docker"></a>为什么要使用Docker</h3><hr><p>比如我们写了一个网站：</p><ol><li><p>前端使用Vue搭建界面</p></li><li><p>后端使用SpringBoot微服务框架来提供各种服务和接口</p></li><li><p>使用MySQL数据库来存储数据</p></li></ol><ul><li><strong>如果没有使用Docker</strong>，我们在生产环境和测试环境中都需要进行各种配置：</li></ul><p><img src="/2024/05/15/Docker/image-20240515113511454.png" alt="开发环境和测试环境"></p><ul><li><strong>如果有了Docker</strong>，我们可以将这些（前端、后端、数据库等）打包成一个个的集装箱，只要在开发环境中运行成功了，在其他环境中也一定可以成功。</li></ul><p><img src="/2024/05/15/Docker/image-20240515113744151.png" alt="开发环境和测试环境"></p><h3 id="Docker和虚拟机的区别"><a href="#Docker和虚拟机的区别" class="headerlink" title="Docker和虚拟机的区别"></a>Docker和虚拟机的区别</h3><hr><ol><li>架构差异：虚拟机是基于<strong>虚拟化技术</strong>（<strong>hypervisor</strong>）实现的，创建一个完整的虚拟硬件环境，模拟一台计算机，包括处理器、内存、硬盘等设备。而Docker则是基于<strong>容器化技术</strong>（<strong>Containerization</strong>），使用Docker引擎访问宿主机操作系统，将应用程序打包到容器中。因此，Docker的架构更加轻量级，启动速度也更快。</li><li>隔离原理：虚拟机通常隔离整个操作系统，进程无法直接访问宿主机资源和数据，需要通过网络或共享文件夹等方式交互。Docker使用Linux内核的namespace和cgroups功能，实现对不同容器中进程的隔离，允许它们共享宿主机资源同时独立运行。</li></ol><h3 id="基本原理和概念"><a href="#基本原理和概念" class="headerlink" title="基本原理和概念"></a>基本原理和概念</h3><hr><p><strong>Docker中的镜像、容器和仓库</strong></p><ul><li><p>镜像和容器的关系就像Java中的类和实例的关系一样：</p><ol><li><strong>镜像是一个只读的模版</strong>，它可以用来创建容器</li><li><strong>容器是Docker的运行实例</strong>，它提供了一个独立的可移植的环境，可以在这个环境中运行应用程序</li></ol></li><li><p>Docker仓库是用来存储Docker镜像的地方，最流行和最常用的仓库就是Dockerhub，实现镜像的共享和复用</p></li></ul><h3 id="Docker的安装"><a href="#Docker的安装" class="headerlink" title="Docker的安装"></a>Docker的安装</h3><hr><p><img src="/2024/05/15/Docker/image-20240515122544372.png" alt="Docker Daemon"></p><ol><li><p>Docker采用Client-Server架构模式</p><ul><li>Docker Client和Docker Daemon之间通过Socket或者RESTful API进行通信</li><li>Docker Daemon就是服务端的守护进程，他负责管理Docker的各种资源</li><li>Docker Client负责向Docker Daemon发送请求，Docker Daemon接收到请求后进行处理，然后将结果返回给Client。因此我们在终端中输入的各种命令，都是Client发送给Docker Daemon的</li></ul></li><li><p>容器化和Dockerfile</p><p><strong>容器化</strong>：顾名思义就是将应用程序打包为容器，在容器中运行应用程序的过程</p><p><strong>Dockerfile</strong>：是一个文本文件，里面包含了一条条的指令，用来告诉Docker如何来构建镜像，这个镜像中包含了我们应用程序执行的所有命令，也就是上边提到的依赖、第三方软件包、配置文件等</p><p>这个过程简单来说可以分成三个步骤:</p><ul><li>首先需要创建一个Dockerfile，来告诉Docker构建应用程序镜像所需要的步骤和配置</li><li>使用Dockerfile来构建镜像</li><li>使用镜像创建和运行容器</li></ul></li></ol><h3 id="实践环节"><a href="#实践环节" class="headerlink" title="实践环节"></a>实践环节</h3><hr><p><img src="/2024/05/15/Docker/image-20240515164517046.png" alt="测试程序_python: 在这里使用默认的ENTRYPOINT[&quot;top&quot;, &quot;-b&quot;]在build时会报错，先删除做测试"></p><hr><p><img src="/2024/05/15/Docker/image-20240515164536314.png" alt="打包为hello-docker镜像"></p><hr><p><img src="/2024/05/15/Docker/image-20240515164551800.png" alt="docker 镜像创建成功"></p>]]></content>
    
    
    <categories>
      
      <category>Develop</category>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R-CNN Series</title>
    <link href="/2024/05/15/RCNN/"/>
    <url>/2024/05/15/RCNN/</url>
    
    <content type="html"><![CDATA[<h3 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h3><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs arcade">R-CNN源于<span class="hljs-number">2014</span>年伯克利大学的这篇论文<br>《Rich <span class="hljs-built_in">feature</span> hierarchies <span class="hljs-keyword">for</span> accurate object detection and semantic segmentation》<br>其架构和模型训练参数等借鉴了AlexNet，也和同时期的Overfeat也有很多共同之处。成为目标检测领域尤其是two stage模式的开山鼻祖。<br></code></pre></td></tr></table></figure><hr><p><img src="/2024/05/15/RCNN/R-CNN.png" alt="R-CNN网络结构"></p><ul><li><h4 id="R-CNN-算法流程分四个步骤："><a href="#R-CNN-算法流程分四个步骤：" class="headerlink" title="R-CNN 算法流程分四个步骤："></a>R-CNN 算法流程分四个步骤：</h4><ol><li><p>一张图像生成1k～2k个候选区域（使用 <strong><u>Selective Search</u></strong> 方法)[<a href="https://zhuanlan.zhihu.com/p/485727819]">https://zhuanlan.zhihu.com/p/485727819]</a></p><blockquote><p>候选区域生成 (Selective Search) 的主要思想：图像中物体可能存在的区域应该是有某些相似性或者连续性区域的。</p><ol><li>首先，对输入图像进行<strong>分割算法</strong>产生许多小的子区域。</li><li>其次，根据这些子区域之间相似性(相似性标准主要有颜色、纹理、大小等等)进行<strong>区域合并</strong>，不断的进行区域迭代合并。每次迭代过程中对这些合并的子区域做bounding boxes(外切矩形)，这些子区域外切矩形就是通常所说的候选框。</li></ol><p><img src="/2024/05/15/RCNN/SS%E7%AE%97%E6%B3%95.png" alt="SS算法"></p></blockquote></li><li><p>对每个候选区域，使用深度网络（图片分类网络）提取特征</p><blockquote><ol><li>通过SS算法可以在一张图片中生成大概2000个候选区域，将候选区域送到CNN网络之前先进行<strong>resize处理</strong>，将2000候选区域缩放到 227 × 227 (原文是不管候选框多大都resize到 227 × 227)</li><li>接着将候选区域输入事先训练好的AlexNet &#x2F; VGG CNN网络<strong>获取4096维的特征</strong>，得到2000×4096维矩阵。</li></ol></blockquote></li><li><p>特征送入每一类SVM分类器，判断是否属于该类</p><blockquote><ol><li><p>将<code>2000×4096</code>维特征与<code>20</code>个<strong>SVM</strong>组成的权值矩阵<code>4096×20</code>相乘，获得<code>2000×20</code>维矩阵表示每个建议框是某个目标类别的得分</p><p><img src="/2024/05/15/RCNN/SVM.png" alt="SVM分类器计算矩阵"></p></li><li><p>分别对上述<code>2000×20</code>维矩阵中每一列即每一类进行**NSM(非极大值抑制)**剔除重叠建议框，得到该列即该类中得分最高的一些建议框。</p></li></ol></blockquote></li><li><p>使用回归器精细修正候选框位置。（使用 Selective Search 算法得到的候选框并不是框得那么准）</p><blockquote><ol><li>对NMS处理后剩余的建议框进一步筛选</li><li>分别用20个<strong>回归器</strong>对上述20个类别中剩余的建议框进行回归操作，最终得到每个类别的修正后的得分最高的bounding box</li></ol><p>(原文)：</p><ol><li>保留与真实目标比IoU大于某一阈值的预测框，不满足的直接删除</li><li>接着再分别使用20个回归器对剩余的预测框进行回归操作，最终得到每个类别的修正后得分最高的预测框。这里的实现方法跟上面的SVM分类差不多，依旧是对卷积神经网络输出的特征向量进行预测，利用每个边界框得到4096维特征向量来预测的。通过回归分类器之后会得到四个参数分别对应着目标建议框的中心点的x,y偏移量和目标边界框的宽高缩放因子。通过预测的四个值对得到的建议框进行调整得到最终的预测边界框。</li></ol></blockquote></li></ol></li><li><h4 id="RCNN存在的问题"><a href="#RCNN存在的问题" class="headerlink" title="RCNN存在的问题"></a>RCNN存在的问题</h4><ol><li>检测速度慢，测试一张图片约53s (CPU)。用Selective Search算法提取候选框用时约2秒，一张图像内候选框之间存在大量重叠，提取特征操作冗余。</li><li>训练速度慢，并且训练过程极其复杂。</li><li>训练所需空间大，对于SVM和bbox回归训练，需要从每个图像中的每个目标候选框提取特征，并写入磁盘。对于非常深的网络，如VGG16，从VOC07训练集上的5k图像上提取的特征需要数百GB的存储空间。</li></ol></li></ul><h3 id="SPPNet"><a href="#SPPNet" class="headerlink" title="SPPNet"></a>SPPNet</h3><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mathematica">由提出<span class="hljs-variable">ResNet</span>的何凯明在论文《<span class="hljs-variable">Spatial</span> <span class="hljs-built_in">Pyramid</span> <span class="hljs-variable">Pooling</span> <span class="hljs-variable">in</span> <span class="hljs-variable">Deep</span> <span class="hljs-variable">Convolutional</span> <span class="hljs-variable">Networks</span> <span class="hljs-variable">for</span> <span class="hljs-variable">Visual</span> <span class="hljs-variable">Recognition</span>》中提出<br>主要就是可以解决<span class="hljs-variable">CNN</span>输入需要固定尺寸的问题，而且在分类和目标检测中都可以得到比较好的效果<br></code></pre></td></tr></table></figure><hr><p><img src="/2024/05/15/RCNN/SPPNet.png" alt="SPPNet网络结构"></p><ul><li><h4 id="针对R-CNN的缺点："><a href="#针对R-CNN的缺点：" class="headerlink" title="针对R-CNN的缺点："></a>针对R-CNN的缺点：</h4><p>1).对每个候选区域提取特征。2).输入CNN的候选区域大小固定，要经过Resize。SPPNet做出了以下改进，<strong>具体内容看表格</strong>：</p><ol><li><p>SPPNet让SS算法得到<strong>候选区域与feature map直接映射</strong>，得到候选区域的映射特征向量（这是映射来的，不需要每个候选区域都再经过CNN的计算，极大的减少了计算量）。</p></li><li><p>SPPNet引入一种空间<u><strong>金字塔池化( spatial pyramid pooling，SPP)层</strong></u>以移除网络对固定尺寸的限制（不需要候选区域经过crop&#x2F;wrap等操作变换成固定大小的图像）。</p><p><img src="/2024/05/15/RCNN/feature_map_regions.png" alt="image regions vs feature map regions"></p><table><thead><tr><th>R-CNN模型</th><th>SPPNet模型</th></tr></thead><tbody><tr><td>1.R-CNN让每个候选区域经过crop&#x2F;wrap等操作变换成固定大小的图像.  2. 固定大小的每个候选区域塞给CNN 传给后面的层做训练回归、分类操作</td><td>1.SPPNet把全图塞给CNN得到全图的feature map.  2.让SS算法得到候选区域与feature map直接映射，得到候选区域的映射特征向量(这是映射来的，不需要过CNN). 3.映射过来的特征向量大小不固定，所以这些特征向量塞给SPP层(空间金字塔变换层)，SPP层接收任何大小的输入，输出固定大小的特征向量，再塞给FC层. 4.经过映射+SPP转换，简化了计算，速度&#x2F;精确度也上去了</td></tr></tbody></table></li></ol></li><li><h4 id="两个关键问题："><a href="#两个关键问题：" class="headerlink" title="两个关键问题："></a>两个关键问题：</h4><ul><li><p><input checked disabled type="checkbox"> <strong>SPP层怎么可以接收任意大小的输入，输出固定的向量？</strong></p><p>spp layer会将<strong>每个候选区域分成1x1，2x2，4x4三张子图</strong>，对每个子图的每个区域作<strong>max pooling</strong>，得出的特征再<strong>连接</strong>到一起就是(16+4+1)x256&#x3D;21x256&#x3D;5376维向量，接着给全连接层做进一步处理。</p></li></ul><ul><li><p><input checked disabled type="checkbox"> <strong>SPPNet怎么就能把候选区域从全图的feature map 直接得到特征向量？</strong></p><p><img src="/2024/05/15/RCNN/Feature_map.png" alt="feature map">整个映射过程有具体的公式：$(x,y)&#x3D;(S<em>x’,S</em>y’)$ $(x’,y’)&#x3D;([x&#x2F;S]+1,[y&#x2F;S]+1)$（左上角+，右下角-)</p><p>其中 S 就是CNN中<strong>所有的strides的乘积</strong>，包含了池化、卷积的stride。论文中使用S的计算出来为2x2x2x2&#x3D;16,在ZF-5结构中。</p></li></ul></li></ul><h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs objectivec">Fast R-<span class="hljs-built_in">CNN</span> 是作者Ross Girshick继 R-<span class="hljs-built_in">CNN</span> 后的又一力作，论文名就叫做 Fast R-<span class="hljs-built_in">CNN</span>，<span class="hljs-number">2015</span>年发表。<br>同样使用VGG16作为网络的backbone，与 R-<span class="hljs-built_in">CNN</span> 相比训练时间快了 <span class="hljs-number">9</span> 倍，测试推理时间快了 <span class="hljs-number">213</span> 倍，准确率从 <span class="hljs-number">62</span>% 提升至了 <span class="hljs-number">66</span>%（在 Pascal VOC 数据集上）<br></code></pre></td></tr></table></figure><p>参考文章：</p><p><a href="https://zhuanlan.zhihu.com/p/165324194">Fast R-CNN</a></p><p><a href="https://www.cnblogs.com/yymn/articles/13629478.html">ROI Pooling</a></p><p><a href="https://www.jianshu.com/p/670a3e42107d">RoI Pooling及其改进</a></p><hr><p><img src="/2024/05/15/RCNN/Fast_R-CNN.png" alt="Fast R-CNN网络结构"></p><ul><li><h4 id="Fast-R-CNN-算法流程分四个步骤："><a href="#Fast-R-CNN-算法流程分四个步骤：" class="headerlink" title="Fast R-CNN 算法流程分四个步骤："></a>Fast R-CNN 算法流程分四个步骤：</h4><ol><li><p>一张图像生成1k～2k个候选区域（使用 Selective Search 方法）</p></li><li><p>将图像输入网络得到相应的特征图，将 Selective Search 算法生成的候选框投影到特征图上获得相应的特征矩阵</p></li><li><p>将每个特征矩阵通过 ROI pooling层缩放为$ 7 \times 7$大小的特征图  </p><blockquote><p>ROI「region of interests」：指的是矩形框框出的区域，可能是有目标的也可能没目标，概念上等价于proposal region。</p><p>ROI Pooling层的具体做法是：</p><p>对候选框所对应的特征矩阵，将其划分为7*7，也就是49等份。划分之后，对每一个区域做一个最大池化下采样操作，也就是MaxPooling操作。如此对49等分的候选区域操作，便得到了一个7*7的特征矩阵。</p><p>也就是说，无论候选框的特征矩阵是怎么样的尺寸，都被缩放到一个7*7的大小，这样就可以不去限制输入图像的尺寸了。</p></blockquote></li><li><p>接着将特征图展平通过一系列全连接层获得预测结果</p><blockquote><p>最后并联了两个全连接层分别对分类和bbox进行预测。</p><p>分类结点数为 N+1，因为需要增加上背景。bbox预测的全连接层则是$4*(N+1)$个结点，对每一类都要预测出来边界框回归参数。</p><p><img src="/2024/05/15/RCNN/%E8%BE%B9%E7%95%8C%E6%A1%86%E5%9B%9E%E5%BD%92%E5%99%A8.png" alt="边界框回归器"></p><p><img src="/2024/05/15/RCNN/image-20240519120214206.png" alt="边界框回归器"></p></blockquote></li></ol></li><li><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>Fast RCNN将分类与回归做到了一个网络里面，因此损失函数必定是多任务的：<br>$$<br>L(p,u,t^u,v)&#x3D;L_{cls}(p,u)+\lambda[u\geq1]L_{loc}(t^u,v)<br>$$</p><ol><li><p><strong>分类损失</strong>：$L_{cls}(p,u) $ </p><blockquote><p>使用交叉熵损失，<code>p</code>为预测结果的向量表示，<code>u</code>为真实类别的标签数据。</p></blockquote></li><li><p><strong>bbox回归器损失</strong>：$\lambda[u&gt;&#x3D;1]L_{loc}(t^u,v)$ ：</p><blockquote><ul><li><p>$\lambda$: 用于调节两部分损失函数的比例，一般取1</p></li><li><p>$[u\geq1]$: 是因为将<code>u</code>定义成了真实类别的索引，而且将background这一类定义成了0。所以如果标签是0的时候，这部分是不需要计算bbox的损失函数的，因为background不需要bbox。</p></li><li><p>$L_{loc}(t^u,v)$<br>$$<br>L_{loc}(t^u,v)&#x3D;\sum_{i\in{x,y,w,h}}smooth_{L1}(t_i^u-v_i)<br>$$</p><p>$$<br>smooth_{L1}(x)&#x3D;<br>\begin{cases}<br>0.5x^2 &amp;if\space|x|&lt;1\<br>|x|-0.5 &amp;otherwise<br>\end{cases}<br>$$</p><p>这一部分就是把预测框与groud truth中的x, y, w, h都单独拿出来进行相减（实际上就是L1的损失函数），然后计算smooth函数($Smooth_{L1}$)，最后把这四个的smooth进行相加就是bbox回归器的损失函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">smooth_l1</span>(<span class="hljs-params">y_true, y_pred</span>):<br>    <span class="hljs-comment"># y_true和y_pred是特征位置的真实值和预测值</span><br>    abs_diff = K.<span class="hljs-built_in">abs</span>(y_true - y_pred)<br>    less_than_one = K.cast(K.less(abs_diff, <span class="hljs-number">1.0</span>), <span class="hljs-string">&quot;float32&quot;</span>)<br>    loss = (<span class="hljs-number">0.5</span> * abs_diff**<span class="hljs-number">2</span>) * less_than_one + (abs_diff - <span class="hljs-number">0.5</span>) * (<span class="hljs-number">1</span> - less_than_one)<br>    <span class="hljs-keyword">return</span> loss<br></code></pre></td></tr></table></figure></li></ul></blockquote></li></ol></li></ul><h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs objectivec">Faster R-<span class="hljs-built_in">CNN</span> 是作者 Ross Girshick 继 Fast R-<span class="hljs-built_in">CNN</span> 后的又一力作，<br>同样使用 VGG16 作为 backbone，推理速度在 GPU 上达到 <span class="hljs-number">5</span>fps（每秒检测五张图，包括候选区域生成），准确度也有一定的进步。核心在于 RPN 区域生成网络（Region Proposal Network）。<br></code></pre></td></tr></table></figure><p><a href="https://www.zhihu.com/tardis/bd/art/31426458">这篇文章</a>介绍Faster R-CNN写的非常非常详细！</p><hr><p><img src="/2024/05/15/RCNN/ff2cd606a307b927701694ec05d0f599.png" alt="Faster R-CNN网络结构"></p><ul><li><h4 id="Faster-R-CNN-算法流程分三个步骤："><a href="#Faster-R-CNN-算法流程分三个步骤：" class="headerlink" title="Faster R-CNN 算法流程分三个步骤："></a>Faster R-CNN 算法流程分三个步骤：</h4><ol><li>将图像输入网络得到相应的特征图-feature map</li><li>使用RPN网络（Region Proposal Network）生成候选框，将 RPN 生成的候选框投影到特征图上获得相应的特征矩阵</li><li>将每个特征矩阵通过 ROI pooling 层缩放为$7 \times 7$大小的特征图，接着将特征图展平通过一系列全连接层获得预测结果</li></ol></li><li><h4 id="RPN-网络结构"><a href="#RPN-网络结构" class="headerlink" title="RPN 网络结构"></a><font color="red">RPN 网络结构</font></h4><blockquote><p><strong>滑动窗口生成anchors -&gt; softmax分类器提取positvie anchors -&gt; bbox reg回归positive anchors -&gt; Proposal Layer生成proposals</strong></p></blockquote><p><img src="/2024/05/15/RCNN/RPN.png" alt="Faster R-CNN细节"></p><p>流程细节：</p><ol><li><p>在经过backbone之后生成Feature Map大小为：<strong>H*W*N</strong></p><blockquote><p>N是根据使用backbone的通道数来定的，比如VGG16为512个通道，而使用ZF网络则是256个通道。</p></blockquote></li><li><p>对特征图做了3x3卷积，但输出层数保持不变（<strong>N</strong>），相当于每个点又融合了周围3x3的空间信息（猜测这样做也许更鲁棒？反正我没测试）</p></li><li><p>在上一步的结果上使用滑动窗口，每滑动到一个位置生成一个一维的向量， 在向量的基础上通过两个全连接层去输出目标概率（背景&#x2F;非背景）和边界框回归参数。</p><blockquote><p>256-d是指使用ZF model作为backbone，最终每个点都用一个256维的向量表示，即<code>N=256</code>。</p></blockquote><p>1*1卷积+Cls layer + Reg layer：</p><blockquote><p>在<strong>分类任务「Cls layer」</strong>中，经过1*1卷积后，输出图像大小为：<strong>H*W*18</strong>，正好对应9个anchor boxes的2分类结果。为何要在softmax前后都接一个reshape layer？其实只是为了便于softmax分类，具体原因这就要从caffe的实现形式说起。</p><p>在<strong>回归任务「Reg layer」</strong>，经过1*1卷积后，输出图像大小为：<strong>H*W*36</strong>，正好对应9个anchor boxes的边界框。</p><p>2k 中的 k 指的是 k 个 anchor boxes，<strong>2是指为背景的概率和为前景的概率</strong>。</p><p>4k 中的 k 指的是 k 个 anchor boxes，<strong>4是指每个 anchor 有 4 个<font color="red">边界框回归参数</font>。</strong></p></blockquote><p><img src="/2024/05/15/RCNN/u=1361402012,3659437005&fm=253&fmt=auto&app=138&f=JPEG-20240520150557582.jpeg" alt="RPN"></p></li><li><p><font color="red">Proposal层</font></p><p>Proposal层共有三个输入：分类器结果【1，2*9，H，W】、边界框回归参数【1，4*9，H，W】、img_info</p><p>Proposal Layer forward（caffe layer的前向函数）按照以下顺序依次处理：</p><ol><li><p>生成anchors，利用$d_x(A),d_y(A),d_w(A),d_h(a)$对所有的anchors做bbox regression回归（这里的anchors生成和训练时完全一致)</p></li><li><p>按照输入的positive softmax scores由大到小排序anchors，提取前pre_nms_topN(e.g. 6000)个anchors，即提取修正位置后的positive anchors</p></li><li><p>判定超出图像边界的positive anchors为图像边界，防止后续roi pooling时proposal超出图像边界</p></li><li><p>剔除尺寸非常小的positive anchors</p></li><li><p>对剩余的positive anchors进行NMS（nonmaximum suppression）</p></li><li><p>对应的bbox reg的结果作为proposal输出</p><blockquote><p>由于在第三步中将anchors映射回原图判断是否超出边界，所以这里输出的proposal是对应MxN输入图像尺度的，这点在后续网络中有用。另外我认为，严格意义上的检测应该到此就结束了，后续部分应该属于识别了。</p></blockquote></li></ol></li></ol></li><li><h4 id="ROI层"><a href="#ROI层" class="headerlink" title="ROI层"></a><font color="red">ROI层</font></h4><p>同Fast R-CNN中的ROI层作用和用法</p></li><li><h4 id="FC层"><a href="#FC层" class="headerlink" title="FC层"></a>FC层</h4><p>同Fast R-CNN中的FC层作用和用法</p></li><li><h4 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h4><p><strong>RPN的损失</strong>也分为两个部分：分类损失和边界框回归损失<br>$$<br>L({p_i},{t_i})&#x3D;\frac{1}{N_{cls}}\sum_{i}L_{cls}(p_i,p_i^*)+\lambda\frac{1}{N_{reg}}\sum_{i}{p_i^*}L_{reg}(t_i,t_i^*)<br>$$</p></li></ul><h3 id="补充材料"><a href="#补充材料" class="headerlink" title="补充材料"></a>补充材料</h3><ul><li><p>Faster R-CNN</p><ol><li><p>实际上生成的那么多 anchors 并不是每个都用来训练 RPN 网络。对于每张图片我们从上万个 anchor 当中采样 256 个 anchor，这些 anchor 由正样本和负样本 1:1 组成的。如果正样本不足 128，就用负样本进行填充。两种定义正样本的方式：（1）anchor 与 ground-truth 的 iou 超过 0.7，（2）某个 anchor 与 ground-truth 拥有最大的 iou。负样本是与所有的 ground-truth 的 iou 都小于 0.3 的。</p></li><li><p>感受野</p><p><img src="/2024/05/15/RCNN/v2-6193e85eb99c691c051ef55840154f9e_r.jpg" alt="感受野"></p></li></ol></li></ul><p>​</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Object Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RCNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
