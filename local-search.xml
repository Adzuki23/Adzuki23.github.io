<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Pytorch学习</title>
    <link href="/2024/05/22/Pytorch/"/>
    <url>/2024/05/22/Pytorch/</url>
    
    <content type="html"><![CDATA[<h3 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h3><figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs oxygene"><span class="hljs-keyword">Module</span>作为模块封装的父类，可以是一段逻辑，也可以是模型的一个块「<span class="hljs-keyword">block</span>」或一层。<br>Pytorch中自定义模型只需要继承<span class="hljs-keyword">Module</span>，保存好Param并提供<span class="hljs-keyword">forward</span>方法，backward被tensor的自动微分自动完成。<br></code></pre></td></tr></table></figure><hr><p>以一个简单的MLP的代码示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># Call the constructor of the parent class nn.Module to perform</span><br>        <span class="hljs-comment"># the necessary initialization</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.hidden = nn.LazyLinear(<span class="hljs-number">256</span>)<br>        self.out = nn.LazyLinear(<span class="hljs-number">10</span>)<br>    <span class="hljs-comment"># Define the forward propagation of the model, that is, how to return the</span><br>    <span class="hljs-comment"># required model output based on the input X</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-keyword">return</span> self.out(F.relu(self.hidden(X)))<br></code></pre></td></tr></table></figure><ul><li><h4 id="回调「Hook」函数介绍"><a href="#回调「Hook」函数介绍" class="headerlink" title="回调「Hook」函数介绍"></a>回调「Hook」函数介绍</h4><blockquote><p><strong>hook 函数机制</strong>：不改变主体，实现额外功能，像一个挂件、挂钩 ➡️ hook</p></blockquote><ol><li><p><strong>为什么会有 hook 函数这个机制:</strong><a href="https://blog.csdn.net/weixin_44878336/article/details/133859089">参考文章1</a></p><blockquote><p>这与 <strong>PyTorch 动态图运行机制</strong>有关:</p><p>在动态图运行机制中，当运算结束后，<font color="red">一些中间变量是会被释放掉的，比如特征图、非叶子节点的梯度。</font>但有时候我们又想要继续关注这些中间变量，那么就可以使用 hook 函数在主体代码中提取中间变量。</p><p>主体代码主要是模型的<strong>前向传播「forward」和反向传播「backward」</strong>，额外的功能就是对模型的中间变量进行操作如：</p><ol><li>提取&#x2F;修改张量梯度</li><li>提取&#x2F;保留非叶子张量的梯度</li><li>查看模型的层与层之间的数据传递情况（数据维度、数据大小等）</li><li>在不修改原始模型代码的基础上可视化各个卷积特征图</li><li>……</li></ol></blockquote></li><li><p><strong>演示Hook的作用</strong>：<a href="https://cloud.tencent.com/developer/article/1745455">参考文章2</a></p><blockquote><p>一般来说，“hook”是在特定事件之后自动执行的函数。</p><p>PyTorch 为nn.Module 对象 &#x2F; 每个张量<font color="red"><strong>注册</strong></font> hook。hook 由对象的向前或向后传播触发。它们具有以下函数签名:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, Tensor<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">module_hook</span>(<span class="hljs-params">module: nn.Module, <span class="hljs-built_in">input</span>: Tensor, output: Tensor</span>):<br>    <span class="hljs-comment"># For nn.Module objects only.</span><br>    <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tensor_hook</span>(<span class="hljs-params">grad: Tensor</span>):<br>    <span class="hljs-comment"># For Tensor objects only.</span><br>    <span class="hljs-comment"># Only executed during the *backward* pass!</span><br></code></pre></td></tr></table></figure></blockquote><ul><li><p><strong>例子1</strong>：假如你想知道每个层输出的形状。我们可以创建一个简单的 wrapper，使用 hook 打印输出形状:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, Tensor<br><span class="hljs-keyword">from</span> torchvision.models <span class="hljs-keyword">import</span> resnet50<br><span class="hljs-keyword">import</span> warnings<br><br>warnings.filterwarnings(<span class="hljs-string">&#x27;ignore&#x27;</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">VerboseExecution</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model: nn.Module</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment"># 传入resnet50模型</span><br>        self.model = model<br><br>        <span class="hljs-keyword">for</span> name, layer <span class="hljs-keyword">in</span> self.model.named_children():<br>            layer.__name__ = name<br>            <span class="hljs-comment"># Register a hook for each layer</span><br>            layer.register_forward_hook(<br>                <span class="hljs-keyword">lambda</span> layer, _, output: <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;layer.__name__&#125;</span>: <span class="hljs-subst">&#123;output.shape&#125;</span>&quot;</span>)<br>            )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: Tensor</span>) -&gt; Tensor:<br>        <span class="hljs-keyword">return</span> self.model(x)<br><br><br>verbose_resnet = VerboseExecution(resnet50())<br>dummy_input = torch.ones(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br><br>_ = verbose_resnet(dummy_input)<br><br><span class="hljs-comment"># --------输出</span><br><span class="hljs-comment"># conv1: torch.Size([10, 64, 112, 112])</span><br><span class="hljs-comment"># bn1: torch.Size([10, 64, 112, 112])</span><br><span class="hljs-comment"># relu: torch.Size([10, 64, 112, 112])</span><br><span class="hljs-comment"># maxpool: torch.Size([10, 64, 56, 56])</span><br><span class="hljs-comment"># layer1: torch.Size([10, 256, 56, 56])</span><br><span class="hljs-comment"># layer2: torch.Size([10, 512, 28, 28])</span><br><span class="hljs-comment"># layer3: torch.Size([10, 1024, 14, 14])</span><br><span class="hljs-comment"># layer4: torch.Size([10, 2048, 7, 7])</span><br><span class="hljs-comment"># avgpool: torch.Size([10, 2048, 1, 1])</span><br><span class="hljs-comment"># fc: torch.Size([10, 1000])</span><br></code></pre></td></tr></table></figure></li><li><p><strong>例子2</strong>：<strong>特征提取</strong>：通常，我们希望从一个预先训练好的网络中生成特性，然后用它们来完成另一个任务(例如分类等)。使用 hook，我们可以提取特征，而不需要重新创建现有模型或以任何方式修改它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, Tensor<br><span class="hljs-keyword">from</span> torchvision.models <span class="hljs-keyword">import</span> resnet50<br><span class="hljs-keyword">import</span> warnings<br><br>warnings.filterwarnings(<span class="hljs-string">&#x27;ignore&#x27;</span>)<br><br><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Dict</span>, Iterable, <span class="hljs-type">Callable</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeatureExtractor</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model: nn.Module, layers: Iterable[<span class="hljs-built_in">str</span>]</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.model = model<br>        self.layers = layers<br>        self._features = &#123;layer: torch.empty(<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> layers&#125;<br><br>        <span class="hljs-keyword">for</span> layer_id <span class="hljs-keyword">in</span> layers:<br>            layer = <span class="hljs-built_in">dict</span>([*self.model.named_modules()])[layer_id]<br>            <span class="hljs-comment"># Register a hook</span><br>            layer.register_forward_hook(self.save_outputs_hook(layer_id))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">save_outputs_hook</span>(<span class="hljs-params">self, layer_id: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">Callable</span>:<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">fn</span>(<span class="hljs-params">_, __, output</span>):<br>            self._features[layer_id] = output<br>        <span class="hljs-keyword">return</span> fn<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: Tensor</span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, Tensor]:<br>        _ = self.model(x)<br>        <span class="hljs-keyword">return</span> self._features<br><br>resnet_features = FeatureExtractor(resnet50(), layers=[<span class="hljs-string">&quot;layer4&quot;</span>, <span class="hljs-string">&quot;avgpool&quot;</span>])<br>dummy_input = torch.ones(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br>features = resnet_features(dummy_input)<br><br><span class="hljs-built_in">print</span>(&#123;name: output.shape <span class="hljs-keyword">for</span> name, output <span class="hljs-keyword">in</span> features.items()&#125;)<br><br><span class="hljs-comment"># 输出</span><br><span class="hljs-comment"># &#123;&#x27;layer4&#x27;: torch.Size([10, 2048, 7, 7]), &#x27;avgpool&#x27;: torch.Size([10, 2048, 1, 1])&#125;</span><br></code></pre></td></tr></table></figure></li><li><p><strong>例子3：梯度裁剪</strong>：梯度裁剪是处理梯度爆炸的一种著名方法。PyTorch 已经提供了梯度裁剪的工具方法，但是我们也可以很容易地使用 hook 来实现它。其他任何用于梯度裁剪&#x2F;归一化&#x2F;修改的方法都可以用同样的方式实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">gradient_clipper</span>(<span class="hljs-params">model: nn.Module, val: <span class="hljs-built_in">float</span></span>) -&gt; nn.Module:<br>    <span class="hljs-keyword">for</span> parameter <span class="hljs-keyword">in</span> model.parameters():<br>      <span class="hljs-comment"># Register a hook for each parameter</span><br>        <br>        <span class="hljs-comment"># register_hook 方法的主要作用是允许用户在张量的梯度计算中注册一个自定义函数</span><br>        <span class="hljs-comment"># 以便在反向传播期间对梯度进行操作或记录信息。</span><br>        <span class="hljs-comment"># 这对于实现自定义梯度处理、梯度剪裁、可视化梯度信息以及梯度的修改等任务非常有用。</span><br>        parameter.register_hook(<span class="hljs-keyword">lambda</span> grad: grad.clamp_(-val, val))<br>    <br>    <span class="hljs-keyword">return</span> model<br><br>clipped_resnet = gradient_clipper(resnet50(), <span class="hljs-number">0.01</span>)<br>pred = clipped_resnet(dummy_input)<br>loss = pred.log().mean()<br>loss.backward()<br><br><span class="hljs-built_in">print</span>(clipped_resnet.fc.bias.grad[:<span class="hljs-number">25</span>])<br><br><span class="hljs-comment"># 输出</span><br><span class="hljs-comment"># tensor([-0.0010, -0.0047, -0.0010, -0.0009, -0.0015,  0.0027,  0.0017, -0.0023,</span><br><span class="hljs-comment">#          0.0051, -0.0007, -0.0057, -0.0010, -0.0039, -0.0100, -0.0018,  0.0062,</span><br><span class="hljs-comment">#          0.0034, -0.0010,  0.0052,  0.0021,  0.0010,  0.0017, -0.0100,  0.0021,</span><br><span class="hljs-comment">#          0.0020])</span><br></code></pre></td></tr></table></figure></li></ul></li><li><p><strong>一些常见的Hook函数</strong>：</p><ul><li><p><code>register_forward_hook</code> 是 PyTorch 中用于在神经网络的<strong>前向传播过程中</strong>注册钩子的一个函数。这个钩子函数会在模块执行其 <code>forward</code> 方法时被调用，可以用来检查或修改中间输出。</p><p><code>module.register_forward_hook(hook)</code>:</p><p><img src="/2024/05/22/Pytorch/image-20240522161226987.png" alt="register_forward_hook"></p></li><li><p><code>register_hook</code> 是 PyTorch 中用于在神经网络的<strong>反向传播过程中</strong>注册钩子的函数。这个钩子函数会在张量的梯度计算过程中被调用，主要用于调试和修改梯度。</p><p><code>tensor.register_hook(hook)</code>:</p><p><img src="/2024/05/22/Pytorch/image-20240522161159145.png" alt="register_hook"></p></li></ul></li></ol></li><li><h4 id="回调「Hook」函数注册"><a href="#回调「Hook」函数注册" class="headerlink" title="回调「Hook」函数注册"></a>回调「Hook」函数注册</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 三个全局变量，dict类型，存储回调函数（即hook），用于net中的所有module</span><br><span class="hljs-comment"># 用于输入输出tensor</span><br>_global_buffer_registration_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br><span class="hljs-comment"># 用于module定义</span><br>_global_module_registration_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br><span class="hljs-comment"># 用于模型参数</span><br>_global_parameter_registration_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br><br><br><span class="hljs-string">r&quot;&quot;&quot;This tracks hooks common to all modules that are executed before/after</span><br><span class="hljs-string">calling forward and backward. This is global state used for debugging/profiling</span><br><span class="hljs-string">purposes&quot;&quot;&quot;</span> <br><span class="hljs-comment"># 用于在module的forward和backward接口前后注册回调函数，例如dump出每个op的输入输出结果</span><br>_global_backward_pre_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br>_global_backward_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br>_global_is_full_backward_hook: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">bool</span>] = <span class="hljs-literal">None</span><br>_global_forward_pre_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br>_global_forward_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] = OrderedDict()<br><br><span class="hljs-comment"># 提供reg接口在完成回调函数注册</span><br>register_module_buffer_registration_hook()<br>register_module_module_registration_hook()<br>register_module_parameter_registration_hook()<br><br>register_module_forward_pre_hook()<br>register_module_forward_hook()<br>register_module_backward_hook()<br>register_module_full_backward_pre_hook()<br>register_module_full_backward_hook()<br></code></pre></td></tr></table></figure></li><li><h4 id="Module成员变量分析"><a href="#Module成员变量分析" class="headerlink" title="Module成员变量分析"></a>Module成员变量分析</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 版本号，一个内部使用的属性，用于跟踪模块的版本。这一机制主要用于在序列化（serialization）和反序列化（deserialization）过程中管理模型的兼容性。</span><br>_version: <span class="hljs-built_in">int</span> = <span class="hljs-number">1</span> <br><span class="hljs-comment"># 一个布尔值，表示模块是否处于训练模式。可以通过 model.train() 和 model.eval() 方法切换。</span><br>training: <span class="hljs-built_in">bool</span> <br><span class="hljs-comment"># 存储模块的所有参数（Parameter 对象），类型为 OrderedDict，如conv的weight、bias等</span><br>_parameters: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Optional</span>[Parameter]] <br><span class="hljs-comment"># 存储模块中的所有缓冲区（Tensor 对象），类型为 OrderedDict。缓冲区是模型状态的一部分，但不是参数，比如 BatchNorm 的running mean 和 running variance。</span><br>_buffers: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Optional</span>[Tensor]] <br><span class="hljs-comment"># 存储模块的子模块，类型为 OrderedDict。每个子模块在模型中都有一个唯一的名称。</span><br>_modules: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Optional</span>[<span class="hljs-string">&#x27;Module&#x27;</span>]]<br><span class="hljs-comment"># 存储反向传播前的钩子，类型为 OrderedDict。这些钩子在反向传播前的过程中被调用。</span><br><br><br>_backward_pre_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>] <br><span class="hljs-comment"># 存储反向传播钩子，类型为 OrderedDict。这些钩子在反向传播过程中被调用。</span><br>_backward_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]<br><span class="hljs-comment"># 存储前向传播钩子，类型为 OrderedDict。这些钩子在前向传播过程中被调用。</span><br>_forward_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]<br><br><br><span class="hljs-comment"># 存储 state_dict 钩子，类型为 OrderedDict。这些钩子在调用 state_dict 时被调用。</span><br>_state_dict_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]  // 模型加载时，op的参数加载相关的回调函数<br>_load_state_dict_pre_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]<br>_state_dict_pre_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]<br>_load_state_dict_post_hooks: <span class="hljs-type">Dict</span>[<span class="hljs-built_in">int</span>, <span class="hljs-type">Callable</span>]<br><br></code></pre></td></tr></table></figure></li><li><h4 id="Module方法分析"><a href="#Module方法分析" class="headerlink" title="Module方法分析"></a>Module方法分析</h4></li></ul>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Pytorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Fatser R-CNN源码学习</title>
    <link href="/2024/05/21/Faster-RCNN_SourceCode/"/>
    <url>/2024/05/21/Faster-RCNN_SourceCode/</url>
    
    <content type="html"><![CDATA[<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/2024/05/21/Faster-RCNN_SourceCode/v2-4c23436f431a535e2cc2e9919b3ca10f_r.jpg" alt="Faster RCNN model"></p><h3 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h3><p>1. </p><h3 id="PyTorch代码学习"><a href="#PyTorch代码学习" class="headerlink" title="PyTorch代码学习"></a>PyTorch代码学习</h3><ol><li><p><code>torch._assert(False, &quot;XXX&quot;)</code></p><blockquote><p>assert函数叫做断言函数，它可以用于判断某个表达式的值，若是该值为真，那么程序就能够继续往下执行; 反之，会报出AssertionError错误。</p></blockquote></li><li><p><code>if isinstance(boxes, torch.Tensor)</code></p><blockquote><p>判断两个类型是否相同</p></blockquote></li></ol>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Object Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RCNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>YOLO系列</title>
    <link href="/2024/05/20/Yolo/"/>
    <url>/2024/05/20/Yolo/</url>
    
    <content type="html"><![CDATA[<h3 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h3>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Object Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>YOLO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PaddlePaddle训练CPPD文字识别模型</title>
    <link href="/2024/05/19/PaddlePaddle_CPPD/"/>
    <url>/2024/05/19/PaddlePaddle_CPPD/</url>
    
    <content type="html"><![CDATA[<ul><li><h4 id="准备好训练数据集"><a href="#准备好训练数据集" class="headerlink" title="准备好训练数据集"></a>准备好训练数据集</h4><p>以PARSeq（lmdb数据格式）为例，在项目文件中如下：</p><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519204701863.png" alt="image-20240519204701863"></p></li><li><h4 id="报错解决"><a href="#报错解决" class="headerlink" title="报错解决"></a>报错解决</h4><ol><li><p>CUDA和CUDNN的配置问题</p><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519174249876.png" alt="image-20240519174249876"></p><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519202939423.png" alt="image-20240519202939423">解决办法：</p><blockquote><ol><li>下载正确CUDA版本的CUDA Toolkit</li><li>下载正确CUDA版本的cuDNN，将dll动态链接库文件复制到CUDA Toolkit中</li></ol></blockquote></li><li><p>其他报错解决</p></li></ol></li><li><h4 id="成功训练"><a href="#成功训练" class="headerlink" title="成功训练"></a>成功训练</h4><p><img src="/2024/05/19/PaddlePaddle_CPPD/image-20240519204959939.png" alt="image-20240519204959939"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Optical Character Recognition</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CPPD</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Docker入门</title>
    <link href="/2024/05/15/Docker/"/>
    <url>/2024/05/15/Docker/</url>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><hr><p>Docker是一个用于<strong>构建(build)</strong>,<strong>运行(run)</strong>,<strong>传送(share)</strong> 应用程序的平台</p><ol><li><strong>将应用程序打包为一个个的集装箱</strong>，小鲸鱼(Docker)就会帮我们将它们运送到任何需要的地方</li></ol><p><img src="/2024/05/15/Docker/docker.png" alt="集装箱"></p><ol start="2"><li><strong>每个集装箱将下列文件打包在一起</strong>（应用程序和它运行时所需要的各种依赖包、第三方软件库、配置文件等），以便在任何环境中都可以正确的运行</li></ol><p><img src="/2024/05/15/Docker/image-20240515112551349.png" alt="集装箱内文件"></p><h3 id="为什么要使用Docker"><a href="#为什么要使用Docker" class="headerlink" title="为什么要使用Docker"></a>为什么要使用Docker</h3><hr><p>比如我们写了一个网站：</p><ol><li><p>前端使用Vue搭建界面</p></li><li><p>后端使用SpringBoot微服务框架来提供各种服务和接口</p></li><li><p>使用MySQL数据库来存储数据</p></li></ol><ul><li><strong>如果没有使用Docker</strong>，我们在生产环境和测试环境中都需要进行各种配置：</li></ul><p><img src="/2024/05/15/Docker/image-20240515113511454.png" alt="开发环境和测试环境"></p><ul><li><strong>如果有了Docker</strong>，我们可以将这些（前端、后端、数据库等）打包成一个个的集装箱，只要在开发环境中运行成功了，在其他环境中也一定可以成功。</li></ul><p><img src="/2024/05/15/Docker/image-20240515113744151.png" alt="开发环境和测试环境"></p><h3 id="Docker和虚拟机的区别"><a href="#Docker和虚拟机的区别" class="headerlink" title="Docker和虚拟机的区别"></a>Docker和虚拟机的区别</h3><hr><ol><li>架构差异：虚拟机是基于<strong>虚拟化技术</strong>（<strong>hypervisor</strong>）实现的，创建一个完整的虚拟硬件环境，模拟一台计算机，包括处理器、内存、硬盘等设备。而Docker则是基于<strong>容器化技术</strong>（<strong>Containerization</strong>），使用Docker引擎访问宿主机操作系统，将应用程序打包到容器中。因此，Docker的架构更加轻量级，启动速度也更快。</li><li>隔离原理：虚拟机通常隔离整个操作系统，进程无法直接访问宿主机资源和数据，需要通过网络或共享文件夹等方式交互。Docker使用Linux内核的namespace和cgroups功能，实现对不同容器中进程的隔离，允许它们共享宿主机资源同时独立运行。</li></ol><h3 id="基本原理和概念"><a href="#基本原理和概念" class="headerlink" title="基本原理和概念"></a>基本原理和概念</h3><hr><p><strong>Docker中的镜像、容器和仓库</strong></p><ul><li><p>镜像和容器的关系就像Java中的类和实例的关系一样：</p><ol><li><strong>镜像是一个只读的模版</strong>，它可以用来创建容器</li><li><strong>容器是Docker的运行实例</strong>，它提供了一个独立的可移植的环境，可以在这个环境中运行应用程序</li></ol></li><li><p>Docker仓库是用来存储Docker镜像的地方，最流行和最常用的仓库就是Dockerhub，实现镜像的共享和复用</p></li></ul><h3 id="Docker的安装"><a href="#Docker的安装" class="headerlink" title="Docker的安装"></a>Docker的安装</h3><hr><p><img src="/2024/05/15/Docker/image-20240515122544372.png" alt="Docker Daemon"></p><ol><li><p>Docker采用Client-Server架构模式</p><ul><li>Docker Client和Docker Daemon之间通过Socket或者RESTful API进行通信</li><li>Docker Daemon就是服务端的守护进程，他负责管理Docker的各种资源</li><li>Docker Client负责向Docker Daemon发送请求，Docker Daemon接收到请求后进行处理，然后将结果返回给Client。因此我们在终端中输入的各种命令，都是Client发送给Docker Daemon的</li></ul></li><li><p>容器化和Dockerfile</p><p><strong>容器化</strong>：顾名思义就是将应用程序打包为容器，在容器中运行应用程序的过程</p><p><strong>Dockerfile</strong>：是一个文本文件，里面包含了一条条的指令，用来告诉Docker如何来构建镜像，这个镜像中包含了我们应用程序执行的所有命令，也就是上边提到的依赖、第三方软件包、配置文件等</p><p>这个过程简单来说可以分成三个步骤:</p><ul><li>首先需要创建一个Dockerfile，来告诉Docker构建应用程序镜像所需要的步骤和配置</li><li>使用Dockerfile来构建镜像</li><li>使用镜像创建和运行容器</li></ul></li></ol><h3 id="实践环节"><a href="#实践环节" class="headerlink" title="实践环节"></a>实践环节</h3><hr><p><img src="/2024/05/15/Docker/image-20240515164517046.png" alt="测试程序_python: 在这里使用默认的ENTRYPOINT[&quot;top&quot;, &quot;-b&quot;]在build时会报错，先删除做测试"></p><hr><p><img src="/2024/05/15/Docker/image-20240515164536314.png" alt="打包为hello-docker镜像"></p><hr><p><img src="/2024/05/15/Docker/image-20240515164551800.png" alt="docker 镜像创建成功"></p>]]></content>
    
    
    <categories>
      
      <category>Develop</category>
      
      <category>Docker</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Docker</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>R-CNN系列</title>
    <link href="/2024/05/15/RCNN/"/>
    <url>/2024/05/15/RCNN/</url>
    
    <content type="html"><![CDATA[<h3 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h3><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs arcade">R-CNN源于<span class="hljs-number">2014</span>年伯克利大学的这篇论文<br>《Rich <span class="hljs-built_in">feature</span> hierarchies <span class="hljs-keyword">for</span> accurate object detection and semantic segmentation》<br>其架构和模型训练参数等借鉴了AlexNet，也和同时期的Overfeat也有很多共同之处。成为目标检测领域尤其是two stage模式的开山鼻祖。<br></code></pre></td></tr></table></figure><hr><p><img src="/2024/05/15/RCNN/R-CNN.png" alt="R-CNN网络结构"></p><ul><li><h4 id="R-CNN-算法流程分四个步骤："><a href="#R-CNN-算法流程分四个步骤：" class="headerlink" title="R-CNN 算法流程分四个步骤："></a>R-CNN 算法流程分四个步骤：</h4><ol><li><p>一张图像生成1k～2k个候选区域（使用 <strong><u>Selective Search</u></strong> 方法)[<a href="https://zhuanlan.zhihu.com/p/485727819]">https://zhuanlan.zhihu.com/p/485727819]</a></p><blockquote><p>候选区域生成 (Selective Search) 的主要思想：图像中物体可能存在的区域应该是有某些相似性或者连续性区域的。</p><ol><li>首先，对输入图像进行<strong>分割算法</strong>产生许多小的子区域。</li><li>其次，根据这些子区域之间相似性(相似性标准主要有颜色、纹理、大小等等)进行<strong>区域合并</strong>，不断的进行区域迭代合并。每次迭代过程中对这些合并的子区域做bounding boxes(外切矩形)，这些子区域外切矩形就是通常所说的候选框。</li></ol><p><img src="/2024/05/15/RCNN/SS%E7%AE%97%E6%B3%95.png" alt="SS算法"></p></blockquote></li><li><p>对每个候选区域，使用深度网络（图片分类网络）提取特征</p><blockquote><ol><li>通过SS算法可以在一张图片中生成大概2000个候选区域，将候选区域送到CNN网络之前先进行<strong>resize处理</strong>，将2000候选区域缩放到 227 × 227 (原文是不管候选框多大都resize到 227 × 227)</li><li>接着将候选区域输入事先训练好的AlexNet &#x2F; VGG CNN网络<strong>获取4096维的特征</strong>&#x3D;&#x3D;，得到2000×4096维矩阵。</li></ol></blockquote></li><li><p>特征送入每一类SVM分类器，判断是否属于该类</p><blockquote><ol><li><p>将<code>2000×4096</code>维特征与<code>20</code>个<strong>SVM</strong>组成的权值矩阵<code>4096×20</code>相乘，获得<code>2000×20</code>维矩阵表示每个建议框是某个目标类别的得分</p><p><img src="/2024/05/15/RCNN/SVM.png" alt="SVM分类器计算矩阵"></p></li><li><p>分别对上述<code>2000×20</code>维矩阵中每一列即每一类进行**NSM(非极大值抑制)**剔除重叠建议框，得到该列即该类中得分最高的一些建议框。</p></li></ol></blockquote></li><li><p>使用回归器精细修正候选框位置。（使用 Selective Search 算法得到的候选框并不是框得那么准）</p><blockquote><ol><li>对NMS处理后剩余的建议框进一步筛选</li><li>分别用20个<strong>回归器</strong>对上述20个类别中剩余的建议框进行回归操作，最终得到每个类别的修正后的得分最高的bounding box</li></ol><p>(原文)：</p><ol><li>保留与真实目标比IoU大于某一阈值的预测框，不满足的直接删除</li><li>接着再分别使用20个回归器对剩余的预测框进行回归操作，最终得到每个类别的修正后得分最高的预测框。这里的实现方法跟上面的SVM分类差不多，依旧是对卷积神经网络输出的特征向量进行预测，利用每个边界框得到4096维特征向量来预测的。通过回归分类器之后会得到四个参数分别对应着目标建议框的中心点的x,y偏移量和目标边界框的宽高缩放因子。通过预测的四个值对得到的建议框进行调整得到最终的预测边界框。</li></ol></blockquote></li></ol></li><li><h4 id="RCNN存在的问题"><a href="#RCNN存在的问题" class="headerlink" title="RCNN存在的问题"></a>RCNN存在的问题</h4><ol><li>检测速度慢，测试一张图片约53s (CPU)。用Selective Search算法提取候选框用时约2秒，一张图像内候选框之间存在大量重叠，提取特征操作冗余。</li><li>训练速度慢，并且训练过程极其复杂。</li><li>训练所需空间大，对于SVM和bbox回归训练，需要从每个图像中的每个目标候选框提取特征，并写入磁盘。对于非常深的网络，如VGG16，从VOC07训练集上的5k图像上提取的特征需要数百GB的存储空间。</li></ol></li></ul><h3 id="SPPNet"><a href="#SPPNet" class="headerlink" title="SPPNet"></a>SPPNet</h3><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mathematica">由提出<span class="hljs-variable">ResNet</span>的何凯明在论文《<span class="hljs-variable">Spatial</span> <span class="hljs-built_in">Pyramid</span> <span class="hljs-variable">Pooling</span> <span class="hljs-variable">in</span> <span class="hljs-variable">Deep</span> <span class="hljs-variable">Convolutional</span> <span class="hljs-variable">Networks</span> <span class="hljs-variable">for</span> <span class="hljs-variable">Visual</span> <span class="hljs-variable">Recognition</span>》中提出<br>主要就是可以解决<span class="hljs-variable">CNN</span>输入需要固定尺寸的问题，而且在分类和目标检测中都可以得到比较好的效果<br></code></pre></td></tr></table></figure><hr><p><img src="/2024/05/15/RCNN/SPPNet.png" alt="SPPNet网络结构"></p><ul><li><h4 id="针对R-CNN的缺点："><a href="#针对R-CNN的缺点：" class="headerlink" title="针对R-CNN的缺点："></a>针对R-CNN的缺点：</h4><p>1).对每个候选区域提取特征。2).输入CNN的候选区域大小固定，要经过Resize。SPPNet做出了以下改进，<strong>具体内容看表格</strong>：</p><ol><li><p>SPPNet让SS算法得到<strong>候选区域与feature map直接映射</strong>，得到候选区域的映射特征向量（这是映射来的，不需要每个候选区域都再经过CNN的计算，极大的减少了计算量）。</p></li><li><p>SPPNet引入一种空间<u><strong>金字塔池化( spatial pyramid pooling，SPP)层</strong></u>以移除网络对固定尺寸的限制（不需要候选区域经过crop&#x2F;wrap等操作变换成固定大小的图像）。</p><p><img src="/2024/05/15/RCNN/feature_map_regions.png" alt="image regions vs feature map regions"></p><table><thead><tr><th>R-CNN模型</th><th>SPPNet模型</th></tr></thead><tbody><tr><td>1.R-CNN让每个候选区域经过crop&#x2F;wrap等操作变换成固定大小的图像.  2. 固定大小的每个候选区域塞给CNN 传给后面的层做训练回归、分类操作</td><td>1.SPPNet把全图塞给CNN得到全图的feature map.  2.让SS算法得到候选区域与feature map直接映射，得到候选区域的映射特征向量(这是映射来的，不需要过CNN). 3.映射过来的特征向量大小不固定，所以这些特征向量塞给SPP层(空间金字塔变换层)，SPP层接收任何大小的输入，输出固定大小的特征向量，再塞给FC层. 4.经过映射+SPP转换，简化了计算，速度&#x2F;精确度也上去了</td></tr></tbody></table></li></ol></li><li><h4 id="两个关键问题："><a href="#两个关键问题：" class="headerlink" title="两个关键问题："></a>两个关键问题：</h4><ul><li><p><input checked disabled type="checkbox"> <strong>SPP层怎么可以接收任意大小的输入，输出固定的向量？</strong></p><p>spp layer会将<strong>每个候选区域分成1x1，2x2，4x4三张子图</strong>，对每个子图的每个区域作<strong>max pooling</strong>，得出的特征再<strong>连接</strong>到一起就是(16+4+1)x256&#x3D;21x256&#x3D;5376维向量，接着给全连接层做进一步处理。</p></li></ul><ul><li><p><input checked disabled type="checkbox"> <strong>SPPNet怎么就能把候选区域从全图的feature map 直接得到特征向量？</strong></p><p><img src="/2024/05/15/RCNN/Feature_map.png" alt="feature map">整个映射过程有具体的公式：$(x,y)&#x3D;(S<em>x’,S</em>y’)$ $(x’,y’)&#x3D;([x&#x2F;S]+1,[y&#x2F;S]+1)$（左上角+，右下角-)</p><p>其中 S 就是CNN中<strong>所有的strides的乘积</strong>，包含了池化、卷积的stride。论文中使用S的计算出来为2x2x2x2&#x3D;16,在ZF-5结构中。</p></li></ul></li></ul><h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs objectivec">Fast R-<span class="hljs-built_in">CNN</span> 是作者Ross Girshick继 R-<span class="hljs-built_in">CNN</span> 后的又一力作，论文名就叫做 Fast R-<span class="hljs-built_in">CNN</span>，<span class="hljs-number">2015</span>年发表。<br>同样使用VGG16作为网络的backbone，与 R-<span class="hljs-built_in">CNN</span> 相比训练时间快了 <span class="hljs-number">9</span> 倍，测试推理时间快了 <span class="hljs-number">213</span> 倍，准确率从 <span class="hljs-number">62</span>% 提升至了 <span class="hljs-number">66</span>%（在 Pascal VOC 数据集上）<br></code></pre></td></tr></table></figure><p><a href="https://zhuanlan.zhihu.com/p/165324194">Fast R-CNN</a></p><p><a href="https://www.cnblogs.com/yymn/articles/13629478.html">ROI Pooling</a></p><p><a href="https://www.jianshu.com/p/670a3e42107d">RoI Pooling及其改进</a></p><hr><p><img src="/2024/05/15/RCNN/Fast_R-CNN.png" alt="Fast R-CNN网络结构"></p><ul><li><h4 id="Fast-R-CNN-算法流程分四个步骤："><a href="#Fast-R-CNN-算法流程分四个步骤：" class="headerlink" title="Fast R-CNN 算法流程分四个步骤："></a>Fast R-CNN 算法流程分四个步骤：</h4><ol><li><p>一张图像生成1k～2k个候选区域（使用 Selective Search 方法）</p></li><li><p>将图像输入网络得到相应的特征图，将 Selective Search 算法生成的候选框投影到特征图上获得相应的特征矩阵</p></li><li><p>将每个特征矩阵通过 ROI pooling层缩放为$ 7 \times 7$大小的特征图  </p><blockquote><p>ROI「region of interests」：指的是矩形框框出的区域，可能是有目标的也可能没目标，概念上等价于proposal region。</p><p>ROI Pooling层的具体做法是：</p><p>对候选框所对应的特征矩阵，将其划分为7*7，也就是49等份。划分之后，对每一个区域做一个最大池化下采样操作，也就是MaxPooling操作。如此对49等分的候选区域操作，便得到了一个7*7的特征矩阵。</p><p>也就是说，无论候选框的特征矩阵是怎么样的尺寸，都被缩放到一个7*7的大小，这样就可以不去限制输入图像的尺寸了。</p></blockquote></li><li><p>接着将特征图展平通过一系列全连接层获得预测结果</p><blockquote><p>最后并联了两个全连接层分别对分类和bbox进行预测。</p><p>分类结点数为 N+1，因为需要增加上背景。bbox预测的全连接层则是$4*(N+1)$个结点，对每一类都要预测出来边界框回归参数。</p><p><img src="/2024/05/15/RCNN/%E8%BE%B9%E7%95%8C%E6%A1%86%E5%9B%9E%E5%BD%92%E5%99%A8.png" alt="边界框回归器"></p><p><img src="/2024/05/15/RCNN/image-20240519120214206.png" alt="边界框回归器"></p></blockquote></li></ol></li><li><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>Fast RCNN将分类与回归做到了一个网络里面，因此损失函数必定是多任务的：<br>$$<br>L(p,u,t^u,v)&#x3D;L_{cls}(p,u)+\lambda[u\geq1]L_{loc}(t^u,v)<br>$$</p><ol><li><p><strong>分类损失</strong>：$L_{cls}(p,u) $ </p><blockquote><p>使用交叉熵损失，<code>p</code>为预测结果的向量表示，<code>u</code>为真实类别的标签数据。</p></blockquote></li><li><p><strong>bbox回归器损失</strong>：$\lambda[u&gt;&#x3D;1]L_{loc}(t^u,v)$ ：</p><blockquote><ul><li><p>$\lambda$: 用于调节两部分损失函数的比例，一般取1</p></li><li><p>$[u\geq1]$: 是因为将<code>u</code>定义成了真实类别的索引，而且将background这一类定义成了0。所以如果标签是0的时候，这部分是不需要计算bbox的损失函数的，因为background不需要bbox。</p></li><li><p>$L_{loc}(t^u,v)$<br>$$<br>L_{loc}(t^u,v)&#x3D;\sum_{i\in{x,y,w,h}}smooth_{L1}(t_i^u-v_i)<br>$$</p><p>$$<br>smooth_{L1}(x)&#x3D;<br>\begin{cases}<br>0.5x^2 &amp;if\space|x|&lt;1\<br>|x|-0.5 &amp;otherwise<br>\end{cases}<br>$$</p><p>这一部分就是把预测框与groud truth中的x, y, w, h都单独拿出来进行相减（实际上就是L1的损失函数），然后计算smooth函数($Smooth_{L1}$)，最后把这四个的smooth进行相加就是bbox回归器的损失函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">smooth_l1</span>(<span class="hljs-params">y_true, y_pred</span>):<br>    <span class="hljs-comment"># y_true和y_pred是特征位置的真实值和预测值</span><br>    abs_diff = K.<span class="hljs-built_in">abs</span>(y_true - y_pred)<br>    less_than_one = K.cast(K.less(abs_diff, <span class="hljs-number">1.0</span>), <span class="hljs-string">&quot;float32&quot;</span>)<br>    loss = (<span class="hljs-number">0.5</span> * abs_diff**<span class="hljs-number">2</span>) * less_than_one + (abs_diff - <span class="hljs-number">0.5</span>) * (<span class="hljs-number">1</span> - less_than_one)<br>    <span class="hljs-keyword">return</span> loss<br></code></pre></td></tr></table></figure></li></ul></blockquote></li></ol></li></ul><h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><figure class="highlight objectivec"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs objectivec">Faster R-<span class="hljs-built_in">CNN</span> 是作者 Ross Girshick 继 Fast R-<span class="hljs-built_in">CNN</span> 后的又一力作，<br>同样使用 VGG16 作为 backbone，推理速度在 GPU 上达到 <span class="hljs-number">5</span>fps（每秒检测五张图，包括候选区域生成），准确度也有一定的进步。核心在于 RPN 区域生成网络（Region Proposal Network）。<br></code></pre></td></tr></table></figure><p><a href="https://www.zhihu.com/tardis/bd/art/31426458">这篇文章</a>介绍Faster R-CNN写的非常非常详细！</p><hr><p><img src="/2024/05/15/RCNN/ff2cd606a307b927701694ec05d0f599.png" alt="Faster R-CNN网络结构"></p><ul><li><h4 id="Faster-R-CNN-算法流程分三个步骤："><a href="#Faster-R-CNN-算法流程分三个步骤：" class="headerlink" title="Faster R-CNN 算法流程分三个步骤："></a>Faster R-CNN 算法流程分三个步骤：</h4><ol><li>将图像输入网络得到相应的特征图-feature map</li><li>使用RPN网络（Region Proposal Network）生成候选框，将 RPN 生成的候选框投影到特征图上获得相应的特征矩阵</li><li>将每个特征矩阵通过 ROI pooling 层缩放为$7 \times 7$大小的特征图，接着将特征图展平通过一系列全连接层获得预测结果</li></ol></li><li><h4 id="RPN-网络结构"><a href="#RPN-网络结构" class="headerlink" title="RPN 网络结构"></a><font color="red">RPN 网络结构</font></h4><blockquote><p><strong>滑动窗口生成anchors -&gt; softmax分类器提取positvie anchors -&gt; bbox reg回归positive anchors -&gt; Proposal Layer生成proposals</strong></p></blockquote><p><img src="/2024/05/15/RCNN/RPN.png" alt="Faster R-CNN细节"></p><p>流程细节：</p><ol><li><p>在经过backbone之后生成Feature Map大小为：<strong>H*W*N</strong></p><blockquote><p>N是根据使用backbone的通道数来定的，比如VGG16为512个通道，而使用ZF网络则是256个通道。</p></blockquote></li><li><p>对特征图做了3x3卷积，但输出层数保持不变（<strong>N</strong>），相当于每个点又融合了周围3x3的空间信息（猜测这样做也许更鲁棒？反正我没测试）</p></li><li><p>在上一步的结果上使用滑动窗口，每滑动到一个位置生成一个一维的向量， 在向量的基础上通过两个全连接层去输出目标概率（背景&#x2F;非背景）和边界框回归参数。</p><blockquote><p>256-d是指使用ZF model作为backbone，最终每个点都用一个256维的向量表示。</p><p>2k 中的 k 指的是 k 个 anchor boxes，<strong>2是指为背景的概率和为前景的概率</strong>。</p><p>4k 中的 k 指的是 k 个 anchor boxes，<strong>4是指每个 anchor 有 4 个<font color="red">边界框回归参数</font>。</strong></p></blockquote><p>1*1卷积+Cls layer + Reg layer：</p><blockquote><p>在<strong>分类任务「Cls layer」</strong>中，经过1*1卷积后，输出图像大小为：<strong>H*W*18</strong>，正好对应9个anchor boxes的2分类结果。为何要在softmax前后都接一个reshape layer？其实只是为了便于softmax分类，具体原因这就要从caffe的实现形式说起。</p><p>在<strong>回归任务「Reg layer」</strong>，经过1*1卷积后，输出图像大小为：<strong>H*W*36</strong>，正好对应9个anchor boxes的边界框</p></blockquote><p><img src="/2024/05/15/RCNN/u=1361402012,3659437005&fm=253&fmt=auto&app=138&f=JPEG-20240520150557582.jpeg" alt="RPN"></p></li><li><p><font color="red">Proposal层</font></p><p>Proposal层共有三个输入：分类器结果【1，2*9，H，W】、边界框回归参数【1，4*9，H，W】、img_info</p><p>Proposal Layer forward（caffe layer的前向函数）按照以下顺序依次处理：</p><ol><li><p>生成anchors，利用$d_x(A),d_y(A),d_w(A),d_h(a)$对所有的anchors做bbox regression回归（这里的anchors生成和训练时完全一致)</p></li><li><p>按照输入的positive softmax scores由大到小排序anchors，提取前pre_nms_topN(e.g. 6000)个anchors，即提取修正位置后的positive anchors</p></li><li><p>判定超出图像边界的positive anchors为图像边界，防止后续roi pooling时proposal超出图像边界</p></li><li><p>剔除尺寸非常小的positive anchors</p></li><li><p>对剩余的positive anchors进行NMS（nonmaximum suppression）</p></li><li><p>对应的bbox reg的结果作为proposal输出</p><blockquote><p>由于在第三步中将anchors映射回原图判断是否超出边界，所以这里输出的proposal是对应MxN输入图像尺度的，这点在后续网络中有用。另外我认为，严格意义上的检测应该到此就结束了，后续部分应该属于识别了。</p></blockquote></li></ol></li></ol></li><li><h4 id="ROI层"><a href="#ROI层" class="headerlink" title="ROI层"></a><font color="red">ROI层</font></h4><p>同Fast R-CNN中的ROI层作用和用法</p></li><li><h4 id="FC层"><a href="#FC层" class="headerlink" title="FC层"></a>FC层</h4><p>同Fast R-CNN中的FC层作用和用法</p></li><li><h4 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h4><p><strong>RPN的损失</strong>也分为两个部分：分类损失和边界框回归损失<br>$$<br>L({p_i},{t_i})&#x3D;\frac{1}{N_{cls}}\sum_{i}L_{cls}(p_i,p_i^*)+\lambda\frac{1}{N_{reg}}\sum_{i}{p_i^*}L_{reg}(t_i,t_i^*)<br>$$</p></li></ul><h3 id="补充材料"><a href="#补充材料" class="headerlink" title="补充材料"></a>补充材料</h3><ul><li><p>Faster R-CNN</p><ol><li><p>实际上生成的那么多 anchors 并不是每个都用来训练 RPN 网络。对于每张图片我们从上万个 anchor 当中采样 256 个 anchor，这些 anchor 由正样本和负样本 1:1 组成的。如果正样本不足 128，就用负样本进行填充。两种定义正样本的方式：（1）anchor 与 ground-truth 的 iou 超过 0.7，（2）某个 anchor 与 ground-truth 拥有最大的 iou。负样本是与所有的 ground-truth 的 iou 都小于 0.3 的。</p></li><li><p>感受野</p><p><img src="/2024/05/15/RCNN/v2-6193e85eb99c691c051ef55840154f9e_r.jpg" alt="感受野"></p></li></ol></li></ul><p>​</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>Object Detection</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RCNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
